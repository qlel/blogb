[{"content":"从路径获取目录部分或文件名部分可以分别使用dirname和basename命令。\ndirname dirname 命令主要作用是去除路径中的非目录部分，删除最后一个/后面的路径，显示父目录。\n如果所给路径中没有包含/，会输出.表示当前目录。\n所给的路径名参数不要求是真实存在的路径，dirname 只是对所给的路径名字符串进行处理。\n选项：\n -z, --zero 不换行打印  示例：\n# 去除最后一个 `/` 的路径 $ dirname /usr/local/src/ /usr/local $ dirname dir1/str dir2/str dir1 dir2 # 不换行 $ dirname -z dir1/str dir2/str dir1dir2 # 路径中没有 `/` ，返回 . $ dirname stdio.h .  basename basename命令用于打印目录或者文件的基本名称，显示最后的目录名或文件名。如果指定后缀，则可以删除相应的文件后缀。\n选项：\n -a, --multiple 指定多个路径或文件 -s, --suffix=SUFFIX 指定用于删除的后缀 -z, --zero 不换行打印  示例：\n# 打印最后的目录名 $ basename /usr/bin/sort sort $ basename /usr/bin/sort/ sort $ basename include/stdio.h stdio.h $ basename stdio.h stdio.h # 两种方式去掉后缀 $ basename include/stdio.h .h stdio $ basename -s .h include/stdio.h stdio # 指定多个路径或文件 $ basename -a any/str1 any/str2 str1 str2 # 不换行打印 $ basename -az any/str1 any/str2 str1str2 # 混合使用，只能去一个后缀 $ basename -a -s .h any/str1.js any/str2.h str1.js str2  其它 以上操作其实可以使用bash的字符串截取操作。详见 Linux Shell Bash 的字符串操作。\n","date":"2021-07-10","permalink":"/post/dirname%E5%92%8Cbasename/","tags":["linux","shell"],"title":"dirname和basename"},{"content":"进程替换是一种重定向形式，其中进程的输入或输出（某些命令序列）作为临时文件出现。\n概念 \u0026lt;(list) # 或者 \u0026gt;(list)  进程列表list异步运行，其输入或输出显示为文件名。这个文件名作为参数传递给当前命令。\n \u0026lt;(list)作为标准输出文件描述符 \u0026gt;(list)作为标准输入文件描述符  以上文件描述符连接到命名管道FIFO 或 /dev/fd/ 中的文件。然后将文件名（文件描述符连接的地方）用作 \u0026lt;(...) 结构的替代。\n进程替换的效果是使每个列表都像一个文件。 这是通过在文件系统中为列表指定一个名称，然后在命令行中替换该名称来完成的。 通过将列表连接到命名管道FIFO或使用 /dev/fd 中的文件，可以为列表命名。 通过这样做，命令只会看到一个文件名，而不会意识到它正在从命令管道读取或写入命令管道。\n实现机制： 进程替换有两种实现方式，在支持/dev/fd的系统中，他通过调用pipe()系统调用来实现，这个系统调用将为新的匿名管道返回一个文件描述符，然后创建字串/dev/fd/$fd，再替换命令行。在不支持/dev/fd的系统中，它将调用mkfifo命令后跟一个临时文件名来创建一个命名管道FIFO,之后在命令行中替换为这个文件名。\n 注意的\u0026lt;或\u0026gt;和左括号之间是没有空格的，否则将被解释为重定向。\n 使用进程替换时，根据shell设置，可能会收到类似于以下内容的错误消息：\nsyntax error near unexpected token `('  进程替换不是 POSIX 兼容功能，因此可能必须通过以下方式启用：\nset +o posix  示例 # 这段代码没有用，但它演示了它是如何工作的 # 可以通过读取文件 /dev/fd/63 来访问 ls 程序的输出。 $ echo \u0026lt;(ls) /dev/fd/63  比较每个目录的内容:\n$ diff \u0026lt;(ls \u0026quot;$first_directory\u0026quot;) \u0026lt;(ls \u0026quot;$second_directory\u0026quot;)  在这个命令中，每个进程都替换了一个文件，diff没有看到\u0026lt;(bla)，它看到了两个文件，所以有效的命令是这样的:\n$ diff /dev/fd/63 /dev/fd/64  这些文件会被自动写入并销毁。\n避免子shell counter=0 find /etc -print0 | while IFS= read -rd '' _; do ((counter++)) done echo \u0026quot;$counter files\u0026quot; # 打印 \u0026quot;0 files\u0026quot;  由于管道的原因，while语句是执行在子shell中的。这意味着计数器只在子shell中递增。当管道完成时，子shell终止，打印计数器仍处于“0”！\n进程替换帮助我们避免管道操作符（子shell的原因）：\ncounter=0 while IFS= read -rN1 _; do ((counter++)) done \u0026lt; \u0026lt;(find /etc -printf ' ') echo \u0026quot;$counter files\u0026quot;  exec中使用 # 将shell脚本中标准输出和错误输出都写入日志文件中同时在屏幕上显示。 exec \u0026amp;\u0026gt; \u0026gt;(tee \u0026quot;$log_file\u0026quot;) ","date":"2021-07-10","permalink":"/post/process-substitution-%E8%BF%9B%E7%A8%8B%E6%9B%BF%E6%8D%A2/","tags":["linux","shell"],"title":"Process Substitution 进程替换"},{"content":"重定向其实是通过操作文件描述符来完成的，这样会更容易理解。\n0_概述 当 Bash 启动时，会自动创建三个标准的文件描述符，它们分别是 stdin（标准输入，文件描述符为0），stdout（标准输出，文件描述符为1）和 stderr（标准错误输出，文件描述符为2）。你也可以创建更多的文件描述符，例如3，4，5等等，或者关闭它们，又或者拷贝它们。你可以从对应的文件中读取或者写入内容。\n文件描述符总是指向某个文件（除非它们被关闭）。通常情况下，Bash 启动的三个文件描述符 —— stdin，stdout 和 stderr 都是指向你的终端，从终端输入中读取内容，并且把标准输出和标准错误都送到终端上。\n重定向符号：\n \u0026gt; 输出重定向到一个文件或设备 覆盖原来的文件 \u0026gt;! 输出重定向到一个文件或设备 强制覆盖原来的文件 \u0026gt;\u0026gt; 输出重定向到一个文件或设备 追加原来的文件 \u0026lt; 输入重定向到一个程序  \u0026gt;\u0026amp;、\u0026amp;\u0026gt;、2\u0026gt;\u0026amp;1 将标准输出和标准错误重定向到覆盖文件 |\u0026amp; 将一个进程的 stdout 和 stderr 发送到另一个进程的 stdin   这是记住这个结构的一种方法（尽管它并不完全准确）：起初，2\u0026gt;1 可能看起来是将 stderr 重定向到 stdout 的好方法。 但是，它实际上会被解释为“将 stderr 重定向到名为 1 的文件”。 \u0026amp; 表示后面和前面的是文件描述符而不是文件名。 所以构造变成：2\u0026gt;\u0026amp;1。\n 假设你的终端对应的设备文件是 /dev/tty0，下面是 Bash 启动时文件描述符表的样子：\n当 Bash 执行一个命令时，他会 fork 一个子进程（查看man 2 fork）。子进程会从父进程继承所有的文件描述符，设置好指定的重定向，最后执行该命令（查看man 3 exec）。\n以下尝试用图表来可视化展现，重定向发生时文件描述符表的变化过程，这种方法可以帮助你更好的理解重定向功能。\n1_将命令的标准输出stdout重定向到文件 $ command \u0026gt;file  \u0026gt;是输出重定向操作符。Bash 首先会打开文件准备写入，如果文件打开成功，则将命令command的 stdout 指向之前打开的文件。如果打开失败，则不会继续执行命令。\ncommand \u0026gt;file的写法和command 1\u0026gt;file的写法是一样的，1是 stdout 对应的文件描述符。\n下面的图片描述了上述命令执行时文件描述符表的变化过程。Bash 打开文件并将文件描述符 1 重定向由/dev/tty0替换为指向文件file的文件描述符。 因此，从现在开始写入文件描述符 1 的所有输出最终都会写入文件：\n2_将命令的标准错误stderr重定向到文件 $ command 2\u0026gt; file  Bash 打开文件进行写入，获取该文件的文件描述符，并将文件描述符 2 替换为该文件的文件描述符。 所以现在任何写入 stderr 的内容都会写入文件。\n3_将stdout和stderr都重定向到一个文件 $ command \u0026amp;\u0026gt;file # 或者 $ command \u0026gt;\u0026amp;file  这一行命令使用了\u0026amp;\u0026gt;操作符，它将命令command的 stdout 和 stderr 都重定向到文件file中。\n以下是 bash 重定向两个流后文件描述符表的样子：\n如图所示，stdout 和 stderr 现在都指向文件。 因此，任何写入stdout和stderr的内容都会写入文件。\n除此之外，还有几种方法可以将 stdout 和 stderr 同时重定向到同一个文件中。\n$ command \u0026gt;file 2\u0026gt;\u0026amp;1  这是将两个流重定向到文件的更常见的方法。 首先将 stdout 重定向到文件file，然后将 stderr 复制为与 stdout 相同。 所以两个流最终都指向文件。\n当 Bash 在命令中遇到多个重定向操作时，它会从左到右依次处理。我们通过图表来依次推导这整个过程。初始时文件描述符表的样子：\n现在 Bash 处理第一个重定向\u0026gt;file，之前已经解释过，它将使得 stdout 指向文件file：\n接下来，Bash 开始处理第二个重定向2\u0026gt;\u0026amp;1，它会把 stderr 重定向到 stdout 所指向的文件：\n两个流都已重定向到文件。\n 这里要注意不要错误的写成：\n# 错误！ $ command 2\u0026gt;\u0026amp;1 \u0026gt;file  在bash中重定向的顺序很重要！此命令仅将 stdout 重定向到文件。stderr 仍将打印到终端。为了理解为什么会发生这种情况，让我们再看一遍这些步骤。因此，在运行命令之前，文件描述符表如下所示：\n现在 bash 从左到右处理重定向。 它首先看到 2\u0026gt;\u0026amp;1 所以它复制 stderr 到 stdout。 文件描述符表变为：\n现在 bash 看到第二个重定向 \u0026gt;file 并将stdout重定向到文件file：\n如同所示，stdout 指向了文件 file，但是 stderr 依然指向终端屏幕。所以，一定要注意重定向的书写顺序。\n4_丢弃命令的 stdout 输出 $ command \u0026gt; /dev/null  特殊文件 /dev/null 会丢弃所有写入其中的数据。 所以我们在这里做的是将标准输出重定向到这个特殊文件，它会被丢弃。 从文件描述符表的角度来看，它是这样的：\n类似的，基于前一条命令，我们可以做到把输出到 stdout 和 stderr 的内容都丢弃：\n$ command \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 # 或者 $ command \u0026amp;\u0026gt;/dev/null  此时的文件描述符表为：\n5_将文件内容重定向到命令的stdin $ command \u0026lt;file  这里 bash 尝试在运行任何命令之前打开文件进行读取。 如果打开文件失败，bash 会错误退出并且不运行命令。 如果打开文件成功，bash 使用打开文件的文件描述符作为命令的标准输入文件描述符。\n完成后，文件描述符表如下所示：\n下面是一个例子，假如你想把文件的第一行读入到变量中：\n$ read -r line \u0026lt; file  Bash 的内置读取命令从标准输入中读取一行。 通过使用输入重定向运算符 \u0026lt;，我们将其设置为从文件中读取行。\n6_重定向一堆字符串到命令的 stdin $ command \u0026lt;\u0026lt;EOL your multi-line text goes here EOL  这里用到了 here document 的语法\u0026lt;\u0026lt;MARKER。当 Bash 遇到该操作符是，它会从标准输入读取每一行，直到遇到一行以MARKER开头为止。这个例子中，Bash 读取到所有内容并传给command的 stdin。\n假设你想去除一堆 URL 地址中的http://部分，可以用下面的一行命令：\n$ sed 's|http://||' \u0026lt;\u0026lt;EOF http://url1.com http://url2.com http://url3.com EOF  输出结果：\nurl1.com url2.com url3.com  7_重定向一行文本到命令的 stdin $ command \u0026lt;\u0026lt;\u0026lt; \u0026quot;foo bar baz\u0026quot; # 等价于 $ echo \u0026quot;foo bar baz\u0026quot; | command  8_将所有命令的 stderr 永久重定向到一个文件 $ exec 2\u0026gt;file $ command1 $ command2 $ ...  这一行命令中使用了 Bash 的内置命令exec。如果你在它之后指定重定向操作，重定向的效果为一直持续到退出脚本或者shell为止。\n在这个例子中，2\u0026gt;file处理之后，随后所有命令的 stderr 都会重定向到文件file中。通过这种方法，你可以很方便的把脚本中所有命令的 stderr 都汇总到一个文件，同时又不用每一个命令之后都指定2\u0026gt;file。\n一般情况下，exec可以接受命令的可选参数。如果指定了它，bash将使用该命令替换自身。因此，您得到的只是运行那个命令，没有创建更多的shell。\n9_使用自定义文件描述符打开文件进行读取 $ exec 3\u0026lt;file  这里我们再次使用 exec 命令并指定 3\u0026lt;file 重定向到它。 它的作用是打开文件进行读取，并将打开的文件描述符分配给 shell 的文件描述符编号 3。文件描述符表现在看起来像这样：\n现在可以从文件描述符3中读取，如下所示：\n$ read -u 3 line  这是从文件描述符3中读取一行。\n一些常规的命令，例如 grep，还可以这么用：\n$ grep \u0026quot;foo\u0026quot; \u0026lt;\u0026amp;3  这里发生的是文件描述符 3 被复制到文件描述符 1，也就是 grep 的 stdin 。 请记住，一旦读取了文件描述符，它就会被耗尽，需要关闭它并再次打开它才能使用它。 （不能在 bash 中倒带文件描述符 fd。）\n使用完文件描述符 fd 3 后，您可以通过以下方式关闭它：\n$ exec 3\u0026gt;\u0026amp;-  这里的文件描述符3被欺骗到-，这是bash关闭这个文件描述符的特殊方式。\n10_使用自定义文件描述符打开文件进行写入 $ exec 4\u0026gt;file  在这里，我们只需告诉bash打开文件进行写入，并为其分配编号4。文件描述符表如下所示：\n如您所见，文件描述符不必按顺序使用，您可以打开任何您喜欢的文件描述符编号，从 0 到 255。\n现在我们可以简单地写入文件描述符4：\n$ echo \u0026quot;foo\u0026quot; \u0026gt;\u0026amp;4  可以关闭文件描述符 4：\n$ exec 4\u0026gt;\u0026amp;-  11_打开一个文件进行写入和读取 $ exec 3\u0026lt;\u0026gt;file  这里我们使用菱形操作符 \u0026lt;\u0026gt;。 菱形操作符打开一个文件描述符用于读取和写入。\n例如：\n$ echo \u0026quot;foo bar\u0026quot; \u0026gt; file # 写入字符串 \u0026quot;foo bar\u0026quot; 到文件 \u0026quot;file\u0026quot;. $ exec 5\u0026lt;\u0026gt; file # 以读写方式打开 \u0026quot;file\u0026quot; 到文件描述符 5 $ read -n 3 var \u0026lt;\u0026amp;5 # 从 fd 5 读取3个字符 $ echo $var  现在我们可以向文件中写入一些内容：\n$ echo -n + \u0026gt;\u0026amp;5 # 在第4个位置写入 '+' $ exec 5\u0026gt;\u0026amp;- # 关闭 fd 5. $ cat file  这将输出 foo+bar，因为我们在文件的第 4 个位置写了 + 字符。\n12_将多个命令的输出发送到一个文件 $ (command1; command2) \u0026gt;file  这一行命令使用(commands)语法，commands 会在一个子 shell 中执行。所以在这里，command1和command2会在子 shell 中运行，然后 Bash 将子 shell 的 stdout 重定向到文件中。\n13_通过文件在shell中执行命令 打开两个 shell，在shell_1中执行以下命令：\nmkfifo fifo exec \u0026lt; fifo  而在shell_2中，执行：\nexec 3\u0026gt; fifo; echo 'echo test' \u0026gt;\u0026amp;3  现在看看shell_1。它会执行echo test。 可以继续向 fifo 写入命令，shell_1 将继续执行它们。\n以下是原理：\n在 shell_1 中，我们使用 mkfifo 命令创建一个名为 fifo 的命名管道。 命名管道（也称为 FIFO）类似于常规管道，不同之处在于它作为文件系统的一部分进行访问。 它可以被多个进程打开以进行读取或写入。 当进程通过 FIFO 交换数据时，内核会在内部传递所有数据，而不会将其写入文件系统。 因此，FIFO 特殊文件在文件系统上没有内容； 文件系统条目仅用作参考点，以便进程可以使用文件系统中的名称访问管道。\n接下来，我们通过exec \u0026lt; fifo命令，使用 fifo 作为当前 shell 的标准输入stdin。\n现在在 shell_2 中，我们打开命名管道进行写入，并为其分配一个自定义文件描述符 3。接下来我们简单地将 echo test 写入文件描述符 3，该文件将转到 fifo。\n由于 shell_1 的 stdin 连接到这个管道，它会执行它！\n14_通过bash访问一个网站 $ exec 3\u0026lt;\u0026gt;/dev/tcp/www.baidu.com/80 $ echo -e \u0026quot;GET / HTTP/1.1\\n\\n\u0026quot; \u0026gt;\u0026amp;3 $ cat \u0026lt;\u0026amp;3  Bash 将 /dev/tcp/host/port 视为特殊文件。 它不需要存在于您的系统中。 这个特殊文件用于通过 bash 打开 tcp 连接。\n在本例中，我们首先打开文件描述符 3 进行读写，并将其指向 /dev/tcp/www.baidu.com/80 特殊文件，该文件是通过端口 80 连接到 www.baidu.com。\n接下来我们将 GET / HTTP/1.1\\n\\n 写入文件描述符 3。然后我们使用 cat 从相同的文件描述符读取响应。\n同样，您可以通过 /dev/udp/host/port 特殊文件创建 UDP 连接。\n使用 /dev/tcp/host/port，您甚至可以在 bash 中编写诸如端口扫描器之类的东西！\n15_重定向输出时防止覆盖文件内容 $ set -o noclobber  这将打开当前 shell 的 noclobber 选项。 noclobber 选项可防止您使用 \u0026gt; 运算符覆盖现有文件。\n如果你尝试将输出重定向到一个存在的文件，你会得到一个错误：\n$ program \u0026gt; file bash: file: cannot overwrite existing file  如果100%确定要覆盖文件，请使用\u0026gt;|重定向操作符：\n$ program \u0026gt;| file  这会成功，因为它覆盖了 noclobber 选项。\n16_将标准输入重定向到文件并将其打印到标准输出 $ command | tee file  tee 命令非常方便。 它不是 bash 的一部分，但您会经常使用它。 它接受一个输入流并将其打印到标准输出和文件中\n在这个例子中，它接受命令的标准输出，把它放在文件中，然后把它打印到标准输出。\n以下是其工作原理的图示：\n17_将一个进程的标准输出发送到另一个进程的标准输入 $ command1 | command2  一个管道|将 command1 的 stdout 与 command2 的 stdin 连接起来。\n可以用图形来说明：\n18_将一个进程的 stdout 和 stderr 发送到另一个进程的 stdin $ command1 |\u0026amp; command2  这适用于从 4.0 开始的 bash 版本。 |\u0026amp; 重定向操作符通过管道将 command1 的 stdout 和 stderr 发送到 command2 的 stdin。\n由于 bash 4.0 的新特性没有被广泛使用，旧的、更便携的方法是：\n$ command1 2\u0026gt;\u0026amp;1 | command2  下图显示了文件描述符发生的情况：\n19_给出文件描述符名称 $ exec {filew}\u0026gt;output_file  命名文件描述符是 bash 4.1 的一个特性。 命名文件描述符看起来像 {varname}。 您可以像使用常规的数字文件描述符一样使用它们。 Bash 在内部选择一个空闲的文件描述符并为其分配一个名称。\n20_重定向顺序 可以把重定向放在你想要的任何地方。看看这3个例子，它们都是一样的：\n$ echo hello \u0026gt;/tmp/example $ echo \u0026gt;/tmp/example hello $ \u0026gt;/tmp/example echo hello  21_交换stdout和stderr $ command 3\u0026gt;\u0026amp;1 1\u0026gt;\u0026amp;2 2\u0026gt;\u0026amp;3  这里我们首先复制文件描述符 3 作为 stdout 的副本。 然后我们复制stdout 为stderr 的副本，最后我们复制stderr 为文件描述符3 的副本，即stdout。 因此，我们交换了 stdout 和 stderr。\n让我们通过插图来了解每个重定向。 在运行命令之前，我们有指向终端的文件描述符：\n接下来 bash 设置 3\u0026gt;\u0026amp;1 重定向。 这将创建文件描述符 3 作为文件描述符 1 的副本：\n接下来 bash 设置 1\u0026gt;\u0026amp;2 重定向。 这使得文件描述符 1 成为文件描述符 2 的副本：\n接下来 bash 设置 2\u0026gt;\u0026amp;3 重定向。 这使得文件描述符 2 成为文件描述符 3 的副本：\n如果你是一个追求完美的人，可以将文件描述符3关闭：\n$ command 3\u0026gt;\u0026amp;1 1\u0026gt;\u0026amp;2 2\u0026gt;\u0026amp;3 3\u0026gt;\u0026amp;-  最终的文件描述符图会是这样的：\n22_将 stdout 发送到一个进程并将 stderr 发送到另一个进程 $ command \u0026gt; \u0026gt;(stdout_cmd) 2\u0026gt; \u0026gt;(stderr_cmd)  这一行命令用到了进程替换（Process Substitution）语法。\u0026gt;(...)操作符的执行过程是，运行里面的命令，同时将命令的标准输入连接到一个命名管道的读取部分。Bash 随后会用命名管道的实际文件名替换这个操作符。\n例如，第一个替换 \u0026gt;(stdout_cmd) 可能返回 /dev/fd/60，第二个替换可能返回 /dev/fd/61。 这两个文件都是 bash 即时创建的命名管道。 两个命名管道都有作为读取器的命令。 命令等待某人写入管道，以便他们可以读取数据。\n替换后，最初的命令变成以下形式：\n$ command \u0026gt; /dev/fd/60 2\u0026gt; /dev/fd/61  以上，标准输出被重定向到 /dev/fd/60，标准错误被重定向到 /dev/fd/61。\n当命令执行是输出内容到 stdout，则管道/dev/fd/60后面的进程（stdout_cmd）会从另外一侧读取到数据。同样的，进程 stderr_cmd 也能从命令的 stderr 输出中读取。\n23_查找所有管道命令的退出代码 假设您运行了几个通过管道连接在一起的命令：\n$ cmd1 | cmd2 | cmd3 | cmd4  然后你想获取所有命令的退出码，但是这里并没有一种简单的做法可以实现，因为 Bash 只会返回最后一个命令的退出码。\nBash 开发人员考虑到了这一点，他们添加了一个特殊的 PIPESTATUS 数组，用于保存管道流中所有命令的退出代码。\nPIPESTATUS 数组的元素对应于命令的退出代码。 下面是一个例子：\n$ echo 'pants are cool' | grep 'moo' | sed 's/o/x/' | awk '{ print $1 }' $ echo ${PIPESTATUS[@]} 0 1 0 0 ","date":"2021-07-10","permalink":"/post/bash-one-liners-3-%E9%87%8D%E5%AE%9A%E5%90%91%E7%9B%B8%E5%85%B3%E7%BF%BB%E8%AF%91%E4%B8%8E%E7%90%86%E8%A7%A3/","tags":["linux","shell","bash"],"title":"Bash One Liners 3 重定向相关翻译与理解"},{"content":"sftp采用的是ssh加密隧道，安装性方面较ftp强，而且依赖的是系统自带的ssh服务，不像ftp还需要额外的进行安装\n切换到root用户执行：\n$ su - root  1 给 sftp 创建一个组 $ groupadd mysftp $ tail -1 /etc/group mysftp❌1001:  2 创建一个新用户加入到此组中 也可以指定现有用户到此组中。\n# 创建一个不能登陆的用户asftp $ useradd -g mysftp -s /bin/false asftp $ passwd asftp # 密码设置为了：asftp_2021  3 指定新用户的home目录和设置权限 感觉此步骤可有可无。\n$ mkdir -p /home/asftp $ usermod -d /home/asftp asftp $ chown root:mysftp /home/asftp $ chmod 755 /home/asftp  4 在用户的home目录中创建一个上传目录 目录所有者为asftp，所有组为mysftp，所有者有写入权限，所有组无写入权限。\n$ mkdir -p /home/asftp/upload $ chown asftp:mysftp /home/asftp/upload $ chmod 755 /home/asftp/upload  5 修改sshd的配置文件 编辑配置文件/etc/ssh/sshd_config\n#Subsystem sftp /usr/lib/openssh/sftp-server Subsystem sftp internal-sftp Match Group mysftp X11Forwarding no AllowTcpForwarding no ChrootDirectory %h ForceCommand internal-sftp  注释掉默认指定的sftp程序，另起一行修改为internal-sftp，表示使用内部sftp，性能比较高。\n Match Group mysftp 如果用户是 mysftp 组中的一员，那么将应用下面提到的规则到这个条目。 ChrootDirectory %h 意味着用户只能在他们自己各自的家目录中更改目录，而不能超出他们各自的家目录。 ForceCommand internal-sftp 用户被限制到只能使用内部 sftp 命令。  6 重启ssh服务 $ systemctl restart ssh.service # 查看状态 $ systemctl status ssh.service ● ssh.service - OpenBSD Secure Shell server Loaded: loaded (/lib/systemd/system/ssh.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2021-04-10 16:18:02 CST; 4h 55min ago Docs: man:sshd(8) man:sshd_config(5) Process: 2460 ExecStartPre=/usr/sbin/sshd -t (code=exited, status=0/SUCCESS) Main PID: 2461 (sshd) Tasks: 1 (limit: 1147) Memory: 2.4M CGroup: /system.slice/ssh.service └─2461 /usr/sbin/sshd -D  7 测试sftp 登录到 sftp 服务器的同一个网络上的任何其它主机上进行连接测试。\n$ sftp -P 2222 asftp@192.168.56.1 asftp@192.168.56.1's password: Connected to asftp@192.168.56.1. sftp\u0026gt; ls -l drwxr-xr-x 2 1001 1001 4096 Apr 10 08:16 upload sftp\u0026gt; put ./rd.txt /upload Uploading ./rd.txt to /upload/rd.txt ./rd.txt 100% 957 478.6KB/s 00:00   ls [directory]：列出一个远程目录的内容。如果没有指定目标目录，则默认列出当前目录。 lls [directory]：列出一个本地目录的内容。如果没有指定目标目录，则默认列出当前目录。 pwd：查看远程当前目录 lpwd：查看本地当前目录 cd directory：从当前目录改到指定目录。 mkdir directory：创建一个远程目录。 rmdir path：删除一个远程目录。 put localfile [remotefile]：本地文件传输到远程主机。 get remotefile [localfile]：远程文件传输到本地。 help：显示帮助信息。 bye：退出 sftp。 quit：退出 sftp。 exit：退出 sftp。  由于之前qlel用户配置了ssh公钥连接远程主机， 所以可以直接连接。\n$ sftp -P 2222 qlel@192.168.56.1 Connected to qlel@192.168.56.1. sftp\u0026gt;  也可以用ftp客户端连接，比如FileZilla客户端： ","date":"2021-04-11","permalink":"/post/%E9%85%8D%E7%BD%AEsftp/","tags":["linux","ssh","sftp"],"title":"配置sftp"},{"content":"mysqldump 是 MySQL 自带的逻辑备份工具。\n它的备份原理是通过协议连接到 MySQL 数据库，将需要备份的数据查询出来，将查询出的数据转换成对应的 insert 语句，当我们需要还原这些数据时，只要执行这些 insert 语句，即可将对应的数据还原。\n备份命令格式 mysqldump [选项] 数据库名 [表名] \u0026gt; 脚本名.sql # 或者, 在powershell终端中必须用 --result-file mysqldump [选项] 数据库名 [表名] --result-file=脚本名.sql # 或者, --databases 后面所有名字参量都被看作数据库名 mysqldump [选项] --databases 数据库名1 数据库名2 ... \u0026gt; 脚本名.sql # 或者, --tables 覆盖 --databases mysqldump [选项] --databases 数据库名1 --tables 表名1 \u0026gt; 脚本名.sql # 或者, 备份所有数据库 mysqldump [选项] --all-databases [选项] \u0026gt; 脚本名.sql   注意: 在win10的powershell终端中使用mysqldump备份会出现中文乱码, 原因是mysqldump不允许将UTF-16作为连接字符集 \u0026lsquo;\u0026gt;\u0026rsquo;, 在powershell终端中的 \u0026lsquo;\u0026gt;\u0026rsquo; 是属于UTF-16, 可以使用--result-file解决, 该选项以ASCII格式创建输出.\n 实例 # 备份test1数据库 mysqldump -u qlel -p test1 --result-file=test1.sql # 加上-d只备份表结构, 不备份数据 mysqldump -u qlel -p -d test1 --result-file=test1.sql # 如果设置了gtid主从复制, 加上--set-gtid-purged=OFF备份binlog mysqldump --set-gtid-purged=OFF -u qlel -p test1 --result-file=test1.sql ","date":"2021-04-11","permalink":"/post/mysqldump/","tags":["mysql"],"title":"Mysqldump"},{"content":"为了解决MySQL的单点故障以及提高MySQL的整体服务性能，一般都会采用「主从复制」。\n主从复制的简介与原理 主从复制中分为主服务器（master）和从服务器（slave），主服务器负责写，而从服务器负责读，Mysql的主从复制的过程是一个「异步的过程」。\n主从复制原理:  当Master节点进行insert、update、delete操作时，会按顺序写入到binlog中。 salve从库连接master主库，Master有多少个slave就会创建多少个binlog dump线程。 当Master节点的binlog发生变化时，binlog dump 线程会通知所有的salve节点，并将相应的binlog内容推送给slave节点。 I/O线程接收到 binlog 内容后，将内容写入到本地的 relay-log。 SQL线程读取I/O线程写入的relay-log，并且根据 relay-log 的内容对从数据库做对应的操作。  GTID 简介 从 MySQL 5.6.5 版本新增了一种主从复制方式：GTID，其全称是Global Transaction Identifier，即全局事务标识。通过GTID保证每个主库提交的事务在集群中都有唯一的一个事务ID。强化了数据库主从的一致性和故障恢复数据的容错能力。在主库宕机发生主从切换的情况下。GTID方式可以让其他从库自动找到新主库复制的位置，而且GTID可以忽略已经执行过的事务，减少了数据发生错误的概率。\nGTID 组成 GTID是对一个已经提交事务的编号，并且是全局唯一的。GTID是由UUID和TID组成的。UUID是MySQL实例的唯一标识，TID代表该实例上已经提交的事务数量，随着事务提交数量递增。\n举个例子：3E11FA47-71CA-11E1-9E33-C80AA9429562:23，冒号前面是UUID，后面是TID。\nGTID 工作原理  主库 master 提交一个事务时会产生 GTID，并且记录在 binlog 日志中 从库 salve I/O 线程读取 master 的 binlog 日志文件，并存储在 slave 的 relay log 中。slave 将 master 的 GTID 这个值，设置到 gtid_next 中，即下一个要读取的 GTID 值。 slave 读取这个 gtid_next，然后对比 slave 自己的 binlog 日志中是否有这个 GTID 如果有这个记录，说明这个 GTID 的事务已经执行过了，可以忽略掉 如果没有这个记录，slave 就会执行该 GTID 事务，并记录到 slave 自己的 binlog 日志中。在读取执行事务前会先检查其他 session 持有该 GTID，确保不被重复执行。 在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。  GTID使用中的限制条件 GTID复制是针对事务来说的，一个事务只对应一个GTID，好多的限制就在于此。\n 不能使用create table table_name select * from table_name。 在一个事务中既包含事务表的操作又包含非事务表。 不支持CREATE TEMPORARY TABLE or DROP TEMPORARY TABLE语句操作。 使用GTID复制从库跳过错误时，不支持执行该sql_slave_skip_counter参数的语法。  GTID实现主从复制 环境 两个操作系统: win10主机, Debian虚拟机.\n win10的ip地址为: 192.168.1.101 Debian虚拟机的ip地址为: 10.0.2.15 虚拟机网关ip地址: 192.168.56.1 win10设置的端口转发: 10.0.2.15:3306 -\u0026gt; 192.168.56.1:3333  MySQL8数据库地址:\n 主库: 192.168.1.101:3306 从库: 10.0.2.15:3306  win10主机访问远程虚拟机MySQL的qlel用户:\nmysql -h 192.168.56.1 -P 3333 -u qlel -p  Debian虚拟机访问远程win10主机MySQL的main用户:\nmysql -h 192.168.56.1 -P 3306 -u qlel -p  两主机皆克利用网关来正常访问.\nmaster主库配置 win10安装目录有个配置文件my.ini, 在内容[mysqld]下添加配置, 配置完需要重启.\n[mysqld] # 主从复制设置 # gtid # 服务器id, 唯一值 server_id=111 # 开启gtid模式 gtid_mode=on # 强制gtid一致性，开启后对于特定的create table不被支持 enforce_gtid_consistency=on # 指定用于二进制日志文件的基本名称, 默认binlog log_bin=binlog # 使从库也保存binlog日志, 默认on log_slave_updates=on # binlog格式, 默认值ROW binlog_format=ROW # 设置二进制日志的有效期限（以秒为单位）, 默认2592000, 为30天 binlog_expire_logs_seconds=2592000  重启, 以管理员身份打开powershell:\n\u0026gt; Get-Service -Name '*mysql*' Status Name DisplayName ------ ---- ----------- Running MySQL MySQL \u0026gt; Stop-Service -Name 'MySQL' WARNING: Waiting for service 'MySQL (MySQL)' to stop... \u0026gt; Get-Service -Name '*mysql*' Status Name DisplayName ------ ---- ----------- Stopped MySQL MySQL \u0026gt; Start-Service -Name 'MySQL' WARNING: Waiting for service 'MySQL (MySQL)' to start... WARNING: Waiting for service 'MySQL (MySQL)' to start... WARNING: Waiting for service 'MySQL (MySQL)' to start... WARNING: Waiting for service 'MySQL (MySQL)' to start... \u0026gt; Get-Service -Name '*mysql*' Status Name DisplayName ------ ---- ----------- Running MySQL MySQL  slave从库配置 Debian安装MySQL后, 配置文件为/etc/mysql/my.cnf, 在内容[mysqld]下添加配置, 配置完需要重启.\n[mysqld] # 服务器id, 唯一值 server_id=222 # 开启gtid模式 gtid_mode=on # 强制gtid一致性，开启后对于特定的create table不被支持 enforce_gtid_consistency=on # 指定用于二进制日志文件的基本名称, 默认binlog log_bin=binlog # 使从库也保存binlog日志, 默认on log_slave_updates=on # binlog格式, 默认值ROW binlog_format=ROW # 设置二进制日志的有效期限（以秒为单位）, 默认2592000, 为30天 binlog_expire_logs_seconds=2592000 # 过滤器, 可以都不设置, 复制所有数据库和表的操作 # 只复制数据库test1下的所有表, 和replicate-wild-ignore-table互斥 replicate-wild-do-table=test1.% # 忽略以下数据库的表, 和replicate-wild-do-table互斥, 可以不设置 replicate-wild-ignore-table=mysql.% replicate-wild-ignore-table=sys.% replicate-wild-ignore-table=information_schema.% replicate-wild-ignore-table=performance_schema.%  配置完成后重启:\n# 重启 $ sudo systemctl restart mysql.service # 查看状态 $ systemctl status mysql.service  检查GTID是否开启 mysql\u0026gt; show variables like '%gtid%'; +----------------------------------+-------------------------------------------+ | Variable_name | Value | +----------------------------------+-------------------------------------------+ | binlog_gtid_simple_recovery | ON | | enforce_gtid_consistency | ON | | gtid_executed | ed3b6e48-9b04-11e9-8c96-f0761c2c3242:1-20 | | gtid_executed_compression_period | 1000 | | gtid_mode | ON | | gtid_next | AUTOMATIC | | gtid_owned | | | gtid_purged | | | session_track_gtids | OFF | +----------------------------------+-------------------------------------------+  保持数据一致 备份主库需要复制的数据, 导入到从库, 必须保持数据一致.\n# 设置了gtid, 必须加上--set-gtid-purged=OFF备份binlog mysqldump --set-gtid-purged=OFF -u qlel -p test1 --result-file=test1.sql # 传输到远程虚拟机 scp -P 2222 .\\test1.sql qlel@192.168.56.1:~  导入数据到从库中:\nmysql -u qlel -p test1 \u0026lt; ~/test1.sql  主库建立授权用户 -- 创建用户 create user 'main'@'%' identified by 'main_1995'; -- 授权, 使从库能够从主库读取binlog日志 grant replication slave on *.* to 'main'@'%'; -- 刷新权限表 flush privileges;  也可以使用现有被授予所有权限的用户.\n主从复制搭建完成后, 主库任何用户的操作修改都会异步复制到从库当中.\nsalve连接到master change master to master_host='192.168.56.1', master_user='main', master_password='main_1995', master_port=3306, master_auto_position=1;  master_auto_position:\n 1 代表采用GTID协议复制; 0 代表采用老的binlog复制.  启动从库线程 在MySQL 8.0.22版本之前的版本使用:\nstart slave;  在MySQL 8.0.22版本之后的版本使用:\nstart replica;  查看从库状态 在MySQL 8.0.22版本之前的版本使用:\nshow slave status\\G;  在MySQL 8.0.22版本之后的版本使用:\nshow replica status\\G;  几个需要注意的字段:\n 含有以下信息表示GTID模式主从复制搭建成功.  Slave_IO_Running: Yes Slave_SQL_Running: Yes Master_UUID: ed3b6e48-9b04-11e9-8c96-f0761c2c3242 Executed_Gtid_Set: ad1b6c0f-8b1c-11eb-8f10-0800279be4fb:1-116 Auto_Position: 1   如果Slave_SQL_Running: No查看最后出现的错误, 一般都是数据不一致导致, 这时从主库备份一下导入到从库即可.  Slave_IO_Running: Yes Slave_SQL_Running: No Last_Error: ... Can't find record in 't2', Error_code: 1032; ...  在master上查看salve信息 在MySQL 8.0.22版本之前的版本使用:\nshow slave hosts;  在MySQL 8.0.22版本之后的版本建议使用别名:\nshow replicas;  从库设置只读 从库设置只读模式, 防止数据出现不一致, 以及实现读写分离, 主库进行写操作, 从库只进行读操作, 提高性能.\n-- 锁定所有表为只读模式, 设置全局只读 mysql\u0026gt; FLUSH TABLES WITH READ LOCK; mysql\u0026gt; SET GLOBAL read_only = ON; -- 关闭全局只读模式, 解锁表的只读模式 mysql\u0026gt; SET GLOBAL read_only = OFF; mysql\u0026gt; UNLOCK TABLES;  取消GTID主从复制 部署环境有时需要更换取消主从机制或者更换备机，需要将之前的主备关系解除.\n从库流程 停止从库进程:\nmysql\u0026gt;stop slave; -- MySQL 8.0.22版本之后使用replica mysql\u0026gt;stop replica;  清除所有元信息和中继日志:\nmysql\u0026gt;reset slave; -- MySQL 8.0.22版本之后使用replica mysql\u0026gt;reset replica; # 可以通过以下命令查看当前状态 mysql\u0026gt; show slave status\\G Emptyset (0,00 sec)  之后从库可以直接关闭下线.\n如果之后不设置主从了, 可以修改配置文件后重启数据库.\n主库流程 mysql\u0026gt; reset master;  次命令会删除所有现有的二进制日志文件并重置二进制日志索引文件，将服务器重置为二进制日志记录启动前的状态。将创建一个新的空二进制日志文件，以便可以重新启动二进制日志记录。\n如果想彻底清除主从的机制，可以修改配置文件，删除主从相关的配置项，然后重启mysql即可。\n 请谨慎使用此语句，以确保您不会丢失任何想要的二进制日志文件数据和GTID执行历史记录。\n","date":"2021-04-11","permalink":"/post/mysql%E5%9F%BA%E4%BA%8Egtid%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","tags":["mysql"],"title":"MySQL基于GTID主从复制"},{"content":"Linux+Nginx+MySQL+PHP\nphp8.0.3编译安装 下载解压后得到:\n$ ls -l /opt/php/src/php-8.0.3 total 2908 drwxrwxr-x 2 root root 4096 Mar 3 00:37 appveyor drwxrwxr-x 4 root root 4096 Mar 3 00:37 azure -rw-rw-r-- 1 root root 3558 Mar 3 00:37 azure-pipelines.yml drwxrwxr-x 2 root root 4096 Mar 3 00:37 build -rwxrwxr-x 1 root root 4012 Mar 3 00:37 buildconf -rw-rw-r-- 1 root root 346 Mar 3 00:37 buildconf.bat -rw-rw-r-- 1 root root 11745 Mar 3 00:37 CODING_STANDARDS.md -rwxr-xr-x 1 root root 2367696 Mar 3 00:37 configure -rw-rw-r-- 1 root root 43448 Mar 3 00:37 configure.ac -rw-rw-r-- 1 root root 20008 Mar 3 00:37 CONTRIBUTING.md drwxrwxr-x 2 root root 4096 Mar 3 00:37 docs drwxrwxr-x 73 root root 4096 Mar 3 00:37 ext -rw-rw-r-- 1 root root 23894 Mar 3 00:37 EXTENSIONS -rw-rw-r-- 1 root root 3204 Mar 3 00:37 LICENSE drwxrwxr-x 3 root root 4096 Mar 3 00:37 main -rw-rw-r-- 1 root root 24067 Mar 3 00:37 NEWS drwxrwxr-x 2 root root 4096 Mar 3 00:37 pear -rw-rw-r-- 1 root root 72382 Mar 3 00:37 php.ini-development -rw-rw-r-- 1 root root 72528 Mar 3 00:37 php.ini-production -rw-rw-r-- 1 root root 5228 Mar 3 00:37 README.md -rw-rw-r-- 1 root root 28525 Mar 3 00:37 README.REDIST.BINS -rwxrwxr-x 1 root root 131379 Mar 3 00:37 run-tests.php drwxrwxr-x 10 root root 4096 Mar 3 00:37 sapi drwxrwxr-x 4 root root 4096 Mar 3 00:37 scripts drwxrwxr-x 10 root root 4096 Mar 3 00:37 tests drwxrwxr-x 2 root root 4096 Mar 3 00:37 travis drwxrwxr-x 2 root root 4096 Mar 3 00:37 TSRM -rw-rw-r-- 1 root root 53691 Mar 3 00:37 UPGRADING -rw-rw-r-- 1 root root 18376 Mar 3 00:37 UPGRADING.INTERNALS drwxrwxr-x 3 root root 4096 Mar 3 00:37 win32 drwxrwxr-x 3 root root 12288 Mar 3 00:37 Zend  ./configure --help可以看到编译选项.\n安装编译时的前提需要:\n$ sudo apt install autoconf automake libtool re2c bison \\ pkg-config libxml2-dev libsqlite3-dev libpng-dev \\ libcurl4-openssl-dev libssl-dev libonig-dev libtidy-dev zlib1g-dev  指定配置, 生成预编译文件 Makefile :\n$ sudo ./configure \\ --prefix=/opt/php/php8 \\ --with-config-file-path=/opt/php/php8/etc \\ --enable-fpm \\ --with-curl \\ --enable-soap \\ --enable-mysqlnd \\ --enable-mbstring \\ --with-pdo-mysql \\ --enable-opcache \\ --enable-pcntl \\ --enable-calendar \\ --enable-bcmath \\ --enable-exif \\ --enable-ftp \\ --enable-intl \\ --with-openssl \\ --enable-gd \\ --with-gettext \\ --with-mhash \\ --with-tidy \\ --with-zlib \\ --enable-sockets  相关错误:\nconfigure: error: C++ preprocessor \u0026quot;/lib/cpp\u0026quot; fails sanity check  解决:\nsudo apt install build-essential  编译安装 $ sudo make $ sudo make install  测试:\n$ /opt/php/php8/bin/php -v PHP 8.0.3 (cli) (built: Mar 21 2021 17:24:17) ( NTS ) Copyright (c) The PHP Group Zend Engine v4.0.3, Copyright (c) Zend Technologies  生成一个软链接到环境变量中的目录:\n$ sudo ln -s /opt/php/php8/bin/php /usr/local/bin/php $ php -v PHP 8.0.3 (cli) (built: Mar 21 2021 17:24:17) ( NTS ) Copyright (c) The PHP Group Zend Engine v4.0.3, Copyright (c) Zend Technologies  配置文件  从源码目录复制配置文件到编译后的目录:  # 查看配置文件路径 $ php -ini | grep Path Configuration File (php.ini) Path =\u0026gt; /opt/php/php8/etc XPath Support =\u0026gt; enabled Path to sendmail =\u0026gt; /usr/sbin/sendmail -t -i # 从源码目录复制配置文件到此目录 $ sudo cp /opt/php/src/php-8.0.3/php.ini-production /opt/php/php8/etc/php.ini $ cd /opt/php/php8/etc/ $ sudo vi php.ini   启用并配置 opcache 和 jit opcache 配置参数参考: https://www.php.net/manual/zh/opcache.configuration.php JIT 配置参数参考: https://www.laruence.com/2020/06/27/5963.html 修改配置文件php.ini:  # zend_extension 的路径替换为编译后opcache.so的路径 zend_extension=/opt/php/php8/lib/php/extensions/no-debug-non-zts-20200930/opcache.so [opcache] opcache.enable=1 opcache.enable_cli=0 ; OPcache 的共享内存大小，以兆字节为单位 opcache.memory_consumption=128 ; 用来存储预留字符串的内存大小，以兆字节为单位 opcache.interned_strings_buffer=8 # OPcache 哈希表中可存储的脚本文件数量上限 opcache.max_accelerated_files=10000 # jit配置 opcache.jit=1205 opcache.jit_buffer_size=64M  配置php-fpm 复制php配置文件目录下的 php-fpm.conf.default，并重命名为 php-fpm.conf\n$ sudo cp /opt/php/php8/etc/php-fpm.conf.default /opt/php/php8/etc/php-fpm.conf  复制php配置文件目录下的 php-fpm.d/www.conf.default，并重命名为 php-fpm.d/www.conf\n$ sudo cp /opt/php/php8/etc/php-fpm.d/www.conf.default /opt/php/php8/etc/php-fpm.d/www.conf  启动php-fpm 编译完成后, 会自动生成php-fpm的service文件:\n$ find /opt/php/src/php-8.0.3 -name *service* /opt/php/src/php-8.0.3/sapi/fpm/php-fpm.service /opt/php/src/php-8.0.3/sapi/fpm/php-fpm.service.in  将php-fpm.service文件放到/etc/systemd/system目录即可完成systemd的配置:\n$ sudo cp /opt/php/src/php-8.0.3/sapi/fpm/php-fpm.service /etc/systemd/system # 查看是否存在 $ systemctl list-unit-files --type=service | grep php php-fpm.service disabled  配置完成后, 尝试启动:\n$ sudo systemctl start php-fpm.service # 查看状态 $ systemctl status php-fpm.service ● php-fpm.service - The PHP FastCGI Process Manager Loaded: loaded (/etc/systemd/system/php-fpm.service; disabled; vendor preset: enabled) Active: failed (Result: exit-code) since Sun 2021-03-21 22:22:36 CST; 14s ago Process: 26775 ExecStart=/opt/php/php8/sbin/php-fpm --nodaemonize --fpm-config /opt/php/php8/etc/php-fpm.conf (code=ex Main PID: 26775 (code=exited, status=78)  启动失败, 查看日志\n$ sudo journalctl -u php-fpm.service -- Logs begin at Sat 2021-03-20 22:27:24 CST, end at Sun 2021-03-21 22:24:54 CST. -- Mar 21 22:22:35 debianqlel systemd[1]: Started The PHP FastCGI Process Manager. Mar 21 22:22:36 debianqlel php-fpm[26775]: [21-Mar-2021 22:22:36] ERROR: [pool www] cannot get gid for group 'nobody' Mar 21 22:22:36 debianqlel php-fpm[26775]: [21-Mar-2021 22:22:36] ERROR: FPM initialization failed Mar 21 22:22:36 debianqlel systemd[1]: php-fpm.service: Main process exited, code=exited, status=78/CONFIG Mar 21 22:22:36 debianqlel systemd[1]: php-fpm.service: Failed with result 'exit-code'.  由日志得知没有nobody用户组, 修改php-fpm的扩展配置文件/opt/php/php8/etc/php-fpm.d/www.conf:\n# 改成当前现有用户即可 user = qlel group = qlel  重启:\n$ sudo systemctl restart php-fpm.service # 查看状态 $ systemctl status php-fpm.service ● php-fpm.service - The PHP FastCGI Process Manager Loaded: loaded (/etc/systemd/system/php-fpm.service; disabled; vendor preset: enabled) Active: active (running) since Sun 2021-03-21 22:33:40 CST; 4s ago Main PID: 26798 (php-fpm) Tasks: 3 (limit: 1147) Memory: 15.0M CGroup: /system.slice/php-fpm.service ├─26798 php-fpm: master process (/opt/php/php8/etc/php-fpm.conf) ├─26799 php-fpm: pool www └─26800 php-fpm: pool www  如果需要开机自启:\n$ sudo systemctl enable php-fpm.service  nginx安装 Debian根据官网安装nginx.\n安装前提:\nsudo apt install curl gnupg2 ca-certificates lsb-release  生成稳定版nginx的仓库源:\n$ echo \u0026quot;deb http://nginx.org/packages/debian `lsb_release -cs` nginx\u0026quot; \\ | sudo tee /etc/apt/sources.list.d/nginx.list # 查看 $ cat /etc/apt/sources.list.d/nginx.list deb http://nginx.org/packages/debian buster nginx  设置此仓库源的优先级高于发行版仓库的优先级:\n$ echo -e \u0026quot;Package: *\\nPin: origin nginx.org\\nPin: release o=nginx\\nPin-Priority: 900\\n\u0026quot; \\ | sudo tee /etc/apt/preferences.d/99nginx # 查看 $ cat /etc/apt/preferences.d/99nginx Package: * Pin: origin nginx.org Pin: release o=nginx Pin-Priority: 900  导入一个官方的nginx签名密钥，以便apt可以验证包的真实性:\n$ curl -o /tmp/nginx_signing.key https://nginx.org/keys/nginx_signing.key  验证下载的文件包含正确的密钥：\n$ gpg --dry-run --quiet --import --import-options import-show /tmp/nginx_signing.key  输出应包含完整指纹:\npub rsa2048 2011-08-19 [SC] [expires: 2024-06-14] 573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 uid nginx signing key \u0026lt;signing-key@nginx.com\u0026gt;  然后，将密钥移动到apt可信密钥存储, 并改名为nginx_signing.asc:\n$ sudo mv /tmp/nginx_signing.key /etc/apt/trusted.gpg.d/nginx_signing.asc  最后, 安装nginx:\n$ sudo apt update $ sudo apt install nginx  测试nginx # 启动 $ sudo systemctl start nginx # 查看状态 $ systemctl status nginx ● nginx.service - nginx - high performance web server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2021-03-21 23:32:52 CST; 14s ago Docs: http://nginx.org/en/docs/ Process: 27493 ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf (code=exited, status=0/SUCCESS) Main PID: 27494 (nginx) Tasks: 2 (limit: 1147) Memory: 1.8M CGroup: /system.slice/nginx.service ├─27494 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf └─27495 nginx: worker process  查看配置/etc/nginx/conf.d/default.conf得到默认地址和端口为127.0.0.1:80, 访问此端口:\n$ curl 127.0.0.1:80 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026quot;http://nginx.org/\u0026quot;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026quot;http://nginx.com/\u0026quot;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  成功.\n配合php 在nginx扩展配置目录/etc/nginx/conf.d/添加一个自定义的配置php.conf:\nserver { listen 8888; access_log /tmp/test8888.log main; root /opt/web/www; index index.php index.html index.htm; location / { try_files $uri $uri/ /index.php?$query_string; } location ~ \\.php { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_split_path_info ^(.+\\.php)(.*)$; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } }  创建文件/opt/web/www/index.php:\n\u0026lt;?php phpinfo();  重启nginx:\n$ sudo systemctl restart nginx $ systemctl status nginx.service ● nginx.service - nginx - high performance web server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2021-03-22 01:04:00 CST; 4s ago Docs: http://nginx.org/en/docs/ Process: 27590 ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf (code=exited, status=0/SUCCESS) Main PID: 27591 (nginx) Tasks: 2 (limit: 1147) Memory: 2.0M CGroup: /system.slice/nginx.service ├─27591 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf └─27592 nginx: worker process  在虚拟机设置好端口转发, 可在宿主机浏览器上访问127.0.0.1:8888/index.php: mysql8安装 MySQL8有二进制安装和官方APT存储库安装. 此处从官方MySQL APT存储库安装MySQL8.\n1.添加MySQL软件仓库 要安装最新版本的MySQL ，需要下载并安装MySQL APT存储库.deb包含管理在Debian系统上配置和安装MySQL软件存储库的软件包 。\n下载并安装deb:\n$ sudo wget https://dev.mysql.com/get/mysql-apt-config_0.8.16-1_all.deb # 安装 $ sudo dpkg -i mysql-apt-config_0.8.16-1_all.deb  在程序包安装期间，系统将提示您配置MySQL APT存储库以选择要安装的MySQL服务器和其他组件的版本。选择后按Enter即可. 2.安装 添加MySQL APT存储库后，更新APT包缓存并安装MySQL服务器包.\n$ sudo apt update $ sudo apt install mysql-server  在安装程序包期间，将显示程序包配置对话框窗口，要求为MySQL设置数据库root用户密码。输入安全且强密码，然后重新输入密码进行确认。 然后阅读有关基于SHA256的密码方法的新认证系统，并选择要使用的默认身份验证插件（保留默认选项以使用推荐的插件），然后按Enter按钮完成安装过程。 查看MySQL的service状态以验证安装:\n$ systemctl status mysql.service ● mysql.service - MySQL Community Server Loaded: loaded (/lib/systemd/system/mysql.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2021-03-22 22:41:44 CST; 2min 27s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 29782 ExecStartPre=/usr/share/mysql-8.0/mysql-systemd-start pre (code=exited, status=0/SUCCESS) Main PID: 29831 (mysqld) Status: \u0026quot;Server is operational\u0026quot; Tasks: 37 (limit: 1147) Memory: 334.4M CGroup: /system.slice/mysql.service └─29831 /usr/sbin/mysqld  3.MySQL安全配置向导 默认情况下，任何新的MySQL服务器部署都是不安全的，为了提高MySQL服务器实例的安全性，需要运行mysql_secure_installation安全配置向导.\n运行mysql_secure_installation会执行几个设置：\n 为root用户设置密码 删除匿名账号 取消root用户远程登录 删除test库和对test库的访问权限 刷新授权表使修改生效  $ sudo mysql_secure_installation  4.测试MySQL $ mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 10 Server version: 8.0.23 MySQL Community Server - GPL Copyright (c) 2000, 2021, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.01 sec)  5.设置远程登陆 如果要使root用户可以被远程登录:\n# 切换到mysql库 use mysql; # %表示任意ip可登陆 update user set host='%' where user='root'; # 刷新权限表 flush privileges;  开启远程登录最好不要对root用户开启, 这里创建一个用户qlel, 密码是qlel1995, 对qlel用户开启远程登录：\n# %表示任意ip可登陆 create user 'qlel'@'%' identified by 'qlel1995';  默认创建用户之后是没有权限的, 只能登录.\n授予权限:\ngrant all on *.* to 'qlel'@'%';   all: 表示授予所有权限, 还能写select，insert，update等 *.*：前面的星号表示数据库, 后面的星号表示数据表. 授权之后, qlel用户需要重新登录权限才会生效.  撤销用户权限:\nrevoke 权限 on 数据库名.表名 from '用户名'@'主机地址';  删除用户:\ndrop user '用户名'@'主机地址';  本地登陆qlel用户:\n$ mysql -uqlel -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 11 Server version: 8.0.23 MySQL Community Server - GPL Copyright (c) 2000, 2021, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.  远程登陆qlel用户:\n$ mysql -h 192.168.56.1 -P 3333 -u qlel -p Enter password: ******** Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 12 Server version: 8.0.23 MySQL Community Server - GPL Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.   -h: 指定主机地址 -P: 指定端口号   注意, 以上我设置了端口转发3306到3333\n 6.修改密码 修改root密码, 如果当前root用户authentication_string字段下有内容，先将其设置为空:\nuse mysql; # 更新user表的authentication_string字段为空 update user set authentication_string='' where user='root' # 将新密码修改为`root1995` alter user 'root'@'localhost' identified by 'root1995'; # 刷新权限表 FLUSH PRIVILEGES;  如果连接navicat，账号密码都正确，连接报错1251, 在MySQL 8.04前，执行：SET PASSWORD=PASSWORD('[新密码]');但是MySQL8.0.4开始，这样默认是不行的。因为之前，MySQL的密码认证插件是“mysql_native_password”，而现在使用的是“caching_sha2_password”。\n使用旧的密码认证插件再一次设置密码:\nuse mysql； ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '新密码'; FLUSH PRIVILEGES;  7.配置文件读取顺序 可以用命令查看:\n$ mysql --help --verbose | grep -A 1 'Default options' Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf  官方文档也有说明: https://dev.mysql.com/doc/refman/8.0/en/option-files.html\n在Unix和类Unix系统上读取的配置文件:\n   配置文件 说明     /etc/my.cnf 全局配置   /etc/mysql/my.cnf 全局配置   SYSCONFDIR/my.cnf 全局配置   $MYSQL_HOME/my.cnf 服务指定配置(仅服务端)   defaults-extra-file 用--defaults-extra-file指定的文件   ~/.my.cnf 用户指定配置   ~/.mylogin.cnf 用户指定的登录路径选项(仅客户端)    在Windows上:\n   配置文件 说明     %WINDIR%\\my.ini, %WINDIR%\\my.cnf 全局配置   C:\\my.ini, C:\\my.cnf 全局配置   BASEDIR\\my.ini, BASEDIR\\my.cnf 全局配置   defaults-extra-file 用--defaults-extra-file指定的文件   %APPDATA%\\MySQL\\.mylogin.cnf 登陆路径配置(仅客户端)   ","date":"2021-04-11","permalink":"/post/lnmp%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","tags":["linux","nginx","mysql","php"],"title":"LNMP环境搭建"},{"content":"awk有多个不同版本的演化：awk-\u0026gt;nawk-\u0026gt;mawk-\u0026gt;gawk\nawk选项  -F value 设置字段分隔符 -f file 从file文件中读取模式动作。允许使用多个-f -v var=value 设置变量var的值为value -- 表示选项的明确结尾  快速入门 基本模式：\n awk '匹配 {动作}' 数据文件  示例：数据文件employee.txt\nBeth 4.00 0 Dan 3.75 0 Kathy 4.00 10 Mark 5.00 20 Mary 5.50 22 Susie 4.25 18  操作：\n# 打印第3个字段(列) $ awk '{print $3}' employee.txt 0 0 10 20 22 18 # 匹配第3列大于0的行，然后打印匹配行的第1列和第2，3列的乘积 $ awk '$3 \u0026gt; 0 { print \u0026quot;数据:\u0026quot;$1, $2 * $3 }' employee.txt 数据:Kathy 40 数据:Mark 100 数据:Mary 121 数据:Susie 76.5  模式汇总  BEGIN{statements} 在输入被读取之前, statements 执行一次 END{ statements} 当所有输入被读取完毕之后, statements 执行一次 expression{ statements} 每碰到一个使 expression 为真的输入行, statements 就执行. expression 为真指的是其值非零或非空. /regular expression/ { statements} 可以被 regular expression 正则匹配的输入行执行statements compound pattern { statements} 使用逻辑与\u0026amp;\u0026amp;、逻辑或||、逻辑非!组合的表达式为混合模式 pattern1, pattern2 { statements} 多个输入行的范围匹配。从匹配pattern1的输入行开始，到匹配pattern2的输入行结束(包括匹配的这两行)，对这其中的每一行执行 statements  示例：\n# 在输入被读取前进行的操作，print \u0026quot;\u0026quot; 表示打印一空行 $ awk 'BEGIN{print \u0026quot;AA BB CC\u0026quot;;print \u0026quot;\u0026quot;} {print $0}' employee.txt AA BB CC Beth 4.00 0 Dan 3.75 0 Kathy 4.00 10 Mark 5.00 20 Mary 5.50 22 Susie 4.25 18 # 设置分隔符为'a' $ awk 'BEGIN{FS=\u0026quot;a\u0026quot;} {print $1}' employee.txt Beth 4.00 0 D K M M Susie 4.25 18 # 范围匹配 $ awk '$1==\u0026quot;Dan\u0026quot;, $3==22 {print $0}' employee.txt Dan 3.75 0 Kathy 4.00 10 Mark 5.00 20 Mary 5.50 22 # 正则 $ awk '$1 ~ /Mar/ {print $0}' employee.txt Mark 5.00 20 Mary 5.50 22 # 混合模式，逻辑与 $ awk '$3\u0026gt;0 \u0026amp;\u0026amp; $3==20 {print $0}' employee.txt Mark 5.00 20  输出 print和printf语句可以用于输出。\n输出语句形式汇总：\n print 将 $0 打印到标准输出 print 表达式1,表达式2... 输出表达式之间由内建变量OFS和ORS分隔 print 表达式1,表达式2... \u0026gt; filename 输出至文件 filename print 表达式1,表达式2... \u0026gt;\u0026gt; filename 累加输出到文件 filename, 不覆盖之前的内容 print 表达式1,表达式2... | command 输出至管道，作为命令 command 的输入 printf(格式,表达式1,表达式2,…) printf(格式,表达式1,表达式2,…) \u0026gt; filename printf(格式,表达式1,表达式2,…) \u0026gt;\u0026gt; filename printf(格式,表达式1,表达式2,…) | command printf 类似于 print, 但是第 1 个参数规定了输出的格式 close(filename), close(command) 断开 filename 或 command 与输出语句之间的连接 system(command) 执行 command; 函数的返回值是 command 的退出状态  print 语句形式还可以有：print(表达式1,表达式2...)\nprintf 的格式与C语言的格式一致：\n   格式字符 意义     d 以十进制形式输出带符号整数(正数不输出符号)   o 以八进制形式输出无符号整数(不输出前缀0)   x,X 以十六进制形式输出无符号整数(不输出前缀Ox)   u 以十进制形式输出无符号整数   f 以小数形式输出单、双精度实数   e,E 以指数形式输出单、双精度实数   g,G 以%f或%e中较短的输出宽度输出单、双精度实数   c 输出单个字符   s 输出字符串     -标识符表示左对齐，默认右对齐 width.prec：width表示宽度，prec表示精度。为了达到规定的宽度, 必要时填充空格; 前导的 0 表示用零填充。  printf格式示例：\n   格式 示例数据 printf输出     %c 97 a   %d 97.5 97   %5d 97.5 此处有3个空格97   %e 97.5 9.750000e+01   %f 97.5 97.500000   %7.2f 97.5 此处有2个空格97.50   %g 97.5 97.5   %.6g 97.5 97.5   %o 97 141   %06o 97 000141   %x 97 61   %s January January   %10s January 此处有3个空格January   %-10s January January此处有3个空格   %.3s January Jan   %10.3s January 此处有7个空格Jan   %-10.3s January Jan此处有7个空格    示例：\n$ awk '$3==20 {printf(\u0026quot;%s\\n\u0026quot;,$1)}' ../employee.txt Mark # 输出到文件 $ awk '$3==20 {printf(\u0026quot;%s\\n\u0026quot;,$1) \u0026gt; \u0026quot;../aa.txt\u0026quot;}' ../employee.txt $ cat ../aa.txt Mark # 输出到管道 $ awk '$3!=0 {print $3 | \u0026quot;sort -r\u0026quot;}' employee.txt 22 20 18 10  内建变量 只列出mawk的内建变量。\n   变量 说明     $n 当前记录的第n个字段，字段间由FS分隔   $0 完整的输入记录   ARGC 命令行参数的数目   ARGV 包含命令行参数的数组   CONVFMT 数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组   ENVIRON 由环境变量索引的数组。 环境字符串var=value存储为ENVIRON[var]=value。   FILENAME 当前文件名   FNR 各文件分别计数的行号   FS 字段分隔符(默认是任何空格)   NF 一条记录的字段的数目   NR 已经读出的记录数，就是行号，从1开始   OFMT 数字的输出格式(默认值是%.6g)   OFS 输出字段分隔符，默认值与输入字段分隔符一致。   ORS 输出记录分隔符(默认值是一个换行符'\\n')   RLENGTH 由match函数所匹配的字符串的长度   RS 记录分隔符(默认是一个换行符'\\n')   RSTART 由match函数所匹配的字符串的第一个位置索引   SUBSEP 数组下标分隔符(默认值是/034)    示例：\n# 每条记录的字段数量 $ awk '$3==0 {print NF}' employee.txt 3 3 # 当前文件名 $ awk '{print FILENAME}' employee.txt employee.txt employee.txt employee.txt employee.txt employee.txt employee.txt  内置函数 https://www.runoob.com/w3cnote/awk-built-in-functions.html\n运算符 只列出mawk的运算符：\n   运算符 说明     =, +=, -=, *=, /= ,%=, ^= 赋值   ?: 条件，三目运算符   `    \u0026amp;\u0026amp; 逻辑与   ! 逻辑非   in 数组成员操作符   ~ 与 !~ 匹配 与 不匹配 正则表达式   \u0026lt;, \u0026gt;, \u0026lt;=, \u0026gt;=, ==, != 关系运算符   空格 连接符   +, - 加，减   *, /, % 乘，除，求余   +, - 一元加，一元减   ^ 求幂   ++, -- 增加或减少，作为前缀或后缀   $ 字段引用    示例：\n# 赋值 $ awk '$3\u0026gt;0 {print $3*=2}' employee.txt 20 40 44 36 # 三目条件运算 $ awk '$3\u0026gt;0 {print $3==20?$1:$2}' employee.txt 4.00 Mark 5.50 4.25 # 逻辑与 $ awk '$3\u0026gt;0 \u0026amp;\u0026amp; $3==20 {print $0}' employee.txt Mark 5.00 20 # 正则 $ awk '$1 ~ /Mar/ {print $0}' employee.txt Mark 5.00 20 Mary 5.50 22  正则表达式 mawk使用的是egrep同款的扩展正则表达式EREs。\nhttps://www.cnblogs.com/chengmo/archive/2010/10/10/1847287.html\n流程控制语句 Awk 提供了用于决策的 if-else 语句, 以及循环语句, 所有的这些都来源于 C 语言. 它们只能用在动作(Action) 里.\n// if-else if ( expr ) statement if ( expr ) statement else statement // while while ( expr ) statement do statement while ( expr ) // for for ( opt_expr ; opt_expr ; opt_expr ) statement for ( var in array ) statement // 结束单个循环 continue // 结束循环 break  数组 Awk提供一维数组。\n数组元素表示为Array[expr]。expr在内部转换为字符串类型，因此，例如，A[1]和A[\u0026quot;1\u0026quot;]是同一个元素，实际索引是\u0026quot;1\u0026quot;。由字符串索引的数组称为关联数组。如果引用的数组不存在，会自动创建空白数组。\n$ awk 'BEGIN{arr[0]=\u0026quot;a\u0026quot;;arr[1]=\u0026quot;b\u0026quot;;arr[2]=\u0026quot;c\u0026quot;;print arr[2]}' c  遍历数组：\n 如果索引是数字字符串，可以使用for或者for-in循环遍历数组； 如果索引是字符串而不是数字字符串，则只能使用for-in循环，此循环是乱序的；  # for $ awk 'BEGIN{arr[0]=\u0026quot;a\u0026quot;;arr[1]=\u0026quot;b\u0026quot;;arr[2]=\u0026quot;c\u0026quot;;for(i=0;i\u0026lt;3;i++) print i,arr[i]}' 0 a 1 b 2 c # for...in 乱序 $ awk 'BEGIN{arr[0]=\u0026quot;a\u0026quot;;arr[1]=\u0026quot;b\u0026quot;;arr[2]=\u0026quot;c\u0026quot;;for(i in arr) print i,arr[i]}' 0 a 1 b 2 c  删除数组：\n 删除单个数组元素：delete arr[index] 删除所有数组元素：delete arr  # 删除某个数组元素 $ awk 'BEGIN{arr[0]=\u0026quot;a\u0026quot;;arr[1]=\u0026quot;b\u0026quot;;arr[2]=\u0026quot;c\u0026quot;; \\ \u0026gt; delete arr[1];for(i in arr) print i,arr[i]}' 0 a 2 c # 清空数组arr $ awk 'BEGIN{arr[0]=\u0026quot;a\u0026quot;;arr[1]=\u0026quot;b\u0026quot;;arr[2]=\u0026quot;c\u0026quot;; \\ delete arr;for(i in arr) print i,arr[i]}'  自定义函数与脚本 自定义函数：function name( args ) { statements }，可以有返回值：return opt_expr。\n可以像写shell一样写awk脚本，写完后赋予执行权限即可执行，如：\n#!/usr/bin/awk -f function add_salary(num1,num2){ salary_sum=num1+num2 return salary_sum } BEGIN{ print \u0026quot;hello func01\u0026quot; print add_salary(10,20) }  执行结果：\nhello func01 30  脚本也可以与要处理的数据文件一起使用：\n#!/usr/bin/awk -f function add_salary(num1,num2){ salary_sum=num1+num2 return salary_sum } BEGIN{ print \u0026quot;hello func01\u0026quot; print add_salary(10,20) } $1 ~ /Mark/ { print add_salary($2,$3) }  执行：\n$ ./func01.awk employee.txt hello func01 30 25 ","date":"2021-04-11","permalink":"/post/awk/","tags":["linux","shell","awk"],"title":"Awk"},{"content":"shell bash 脚本相关\nbash简介 Bash 是 Unix 系统和 Linux 系统的一种 Shell（命令行环境），是目前绝大多数 Linux 发行版的默认 Shell。\n进入命令行环境以后，一般就已经打开 Bash 了。如果你的 Shell 不是 Bash，可以输入bash命令启动 Bash。\n# 进入 $ bash # 退出 $ exit # 版本 $ bash --version GNU bash, version 5.0.3(1)-release (x86_64-pc-linux-gnu) Copyright (C) 2019 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software; you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. # 或者 $ echo $BASH_VERSION 5.0.3(1)-release  bash基本语法 主要介绍语法和一些常用命令。\n命令语法：\ncommand [ arg1 ... [ argN ]] # 换行 # 命令可以用反斜杠 \\ 换行 command arg1 \\ arg2 arg3 \\ arg4... # 空格 # 数之间有多个空格，Bash 会自动忽略多余的空格 $ echo this is a test this is a test # 分号(;)，结束符 # 使得一行可以放置多个命令 $ clear; ls  \u0026amp;\u0026amp;和|| 命令的组合符\u0026amp;\u0026amp;和||:\n# 如果Command1命令运行成功，则继续运行Command2命令。 Command1 \u0026amp;\u0026amp; Command2 # 如果Command1命令运行失败，则继续运行Command2命令。 Command1 || Command2  快捷键  Ctrl + L：清除屏幕并将当前行移到页面顶部。 Ctrl + C：中止当前正在执行的命令。 Shift + PageUp：向上滚动。 Shift + PageDown：向下滚动。 Ctrl + U：从光标位置删除到行首。 Ctrl + K：从光标位置删除到行尾。 Ctrl + D：关闭 Shell 会话。 ↑，↓：浏览已执行命令的历史记录。  type Bash 本身内置了很多命令，同时也可以执行外部程序。怎么知道一个命令是内置命令，还是外部程序呢？\ntype命令用来判断命令的来源。\n# 内建程序 $ type echo echo is a shell builtin # # 外部程序 $ type ls ls is hashed (/bin/ls)  -a参数查看一个命令的所有定义：\n# echo命令即是内置命令，也有对应的外部程序。 $ type -a echo echo is shell builtin echo is /usr/bin/echo echo is /bin/echo  -t参数返回一个命令的类型：别名（alias），关键词（keyword），函数（function），内置命令（builtin）和文件（file）。\n$ type -t bash file $ type -t if keyword  echo echo命令的作用是在屏幕输出一行文本。\n$ echo hello world hello world  如果想要输出的是多行文本，即包括换行符。这时需要把多行文本放在引号里面。\n$ echo \u0026quot;\u0026lt;HTML\u0026gt; \u0026lt;HEAD\u0026gt; \u0026lt;TITLE\u0026gt;Page Title\u0026lt;/TITLE\u0026gt; \u0026lt;/HEAD\u0026gt; \u0026lt;BODY\u0026gt; Page body. \u0026lt;/BODY\u0026gt; \u0026lt;/HTML\u0026gt;\u0026quot;  参数：\n-n： 输出不换行\n-e： 启用反斜杠转义的解释。如果不使用-e参数，引号会让特殊字符变成普通字符，echo不解释它们，原样输出。例如：\n$ echo \u0026quot;Hello\\nWorld\u0026quot; Hello\\nWorld # 双引号的情况 $ echo -e \u0026quot;Hello\\nWorld\u0026quot; Hello World # 单引号的情况 $ echo -e 'Hello\\nWorld' Hello World  模式扩展 模式扩展类似正则表达式，但早于正则表达式出现。它的功能没有正则那么强大灵活，但是优点是简单和方便。\nBash 一共提供八种扩展：\n 波浪线扩展 ? 字符扩展 * 字符扩展 方括号扩展 大括号扩展 变量扩展 子命令扩展 算术扩展  Bash 允许用户关闭模式扩展：\n$ set -o noglob # 或者 $ set -f  重新打开模式扩展：\n$ set +o noglob # 或者 $ set +f  波浪线扩展 波浪线~会自动扩展成当前用户的主目录。\n$ echo ~ /home/me  ~user表示扩展成用户user的主目录:\n$ echo ~foo /home/foo $ echo ~root /root  ~+会扩展成当前所在的目录，等同于pwd命令:\n$ cd ~/foo $ echo ~+ /home/me/foo  ? 字符扩展 ?字符代表文件路径里面的任意单个字符，不包括空字符。比如，Data???匹配所有Data后面跟着三个字符的文件名。\n# 存在文件 a.txt 和 b.txt $ ls ?.txt a.txt b.txt  ? 字符扩展属于文件名扩展，只有文件确实存在的前提下，才会发生扩展。如果文件不存在，扩展就不会发生。\n# 当前目录有 a.txt 文件 $ echo ?.txt a.txt # 当前目录为空目录 $ echo ?.txt ?.txt  * 字符扩展 *字符代表文件路径里面的任意数量的任意字符，包括零个字符。\n# 存在文件 a.txt、b.txt 和 ab.txt $ ls *.txt a.txt b.txt ab.txt  注意，*不会匹配隐藏文件（以.开头的文件），即ls *不会输出隐藏文件。\n如果要匹配隐藏文件，需要写成.*。\n# 显示所有隐藏文件 $ echo .*  如果要匹配隐藏文件，同时要排除.和..这两个特殊的隐藏文件，可以与方括号扩展结合使用，写成.[!.]*。\n$ echo .[!.]*  注意，*字符扩展属于文件名扩展，只有文件确实存在的前提下才会扩展。如果文件不存在，就会原样输出。\n# 当前目录不存在 c 开头的文件 $ echo c*.txt c*.txt  方括号扩展 方括号扩展的形式是[...]，只有文件确实存在的前提下才会扩展。如果文件不存在，就会原样输出。方括号里面各值类似逻辑或关系。\n括号之中的任意一个字符，比如，[aeiou]可以匹配五个元音字母中的任意一个。\n# 存在文件 a.txt 和 b.txt $ ls [ab].txt a.txt b.txt # 只存在文件 a.txt $ ls [ab].txt a.txt  方括号扩展还有两种变体：[^...]和[!...]。它们表示匹配不在方括号里面的字符，这两种写法是等价的。比如，[^abc]或[!abc]表示匹配除了a、b、c以外的字符。\n# 存在 aaa、bbb、aba 三个文件 $ ls ?[!a]? aba bbb   注意，如果需要匹配[字符，可以放在方括号内，比如[[aeiou]。如果需要匹配连字号-，只能放在方括号内部的开头或结尾，比如[-aeiou]或[aeiou-]。\n 方括号扩展有一个简写形式[start-end]，表示匹配一个连续的范围。比如，[a-c]等同于[abc]，[0-9]匹配[0123456789]。\n# 存在文件 a.txt、b.txt 和 c.txt $ ls [a-c].txt a.txt b.txt c.txt # 存在文件 report1.txt、report2.txt 和 report3.txt $ ls report[0-9].txt report1.txt report2.txt report3.txt ...  下面是一些常用简写的例子:\n [a-z]：所有小写字母。 [a-zA-Z]：所有小写字母与大写字母。 [a-zA-Z0-9]：所有小写字母、大写字母与数字。 [abc]*：所有以a、b、c字符之一开头的文件名。 program.[co]：文件program.c与文件program.o。 BACKUP.[0-9][0-9][0-9]：所有以BACKUP.开头，后面是三个数字的文件名。  大括号扩展 大括号扩展{...}表示分别扩展成大括号里面的所有值，各个值之间使用逗号分隔。比如，{1,2,3}扩展成1 2 3。大括号里面各值类似逻辑与关系。\n$ echo {1,2,3} 1 2 3 $ echo d{a,e,i,u,o}g dag deg dig dug dog $ echo Front-{A,B,C}-Back Front-A-Back Front-B-Back Front-C-Back   注意，大括号扩展不是文件名扩展。它会扩展成所有给定的值，而不管是否有对应的文件存在。\n $ ls {a,b,c}.txt ls: 无法访问'a.txt': 没有那个文件或目录 ls: 无法访问'b.txt': 没有那个文件或目录 ls: 无法访问'c.txt': 没有那个文件或目录   另一个需要注意的地方是，大括号内部的逗号前后不能有空格。否则，大括号扩展会失效。\n $ echo {1 , 2} {1 , 2}  号前面可以没有值，表示扩展的第一项为空。\n$ cp a.log{,.bak} # 等同于 # cp a.log a.log.bak  大括号可以嵌套。\n$ echo {j{p,pe}g,png} jpg jpeg png $ echo a{A{1,2},B{3,4}}b aA1b aA2b aB3b aB4b  大括号也可以与其他模式联用，并且总是先于其他模式进行扩展。\n$ echo /bin/{cat,b*} /bin/cat /bin/b2sum /bin/base32 /bin/base64 ... ... # 基本等同于 $ echo /bin/cat;echo /bin/b*  由于大括号扩展{...}不是文件名扩展，所以它总是会扩展的。这与方括号扩展[...]完全不同，如果匹配的文件不存在，方括号就不会扩展。这一点要注意区分。\n# 不存在 a.txt 和 b.txt $ echo [ab].txt [ab].txt $ echo {a,b}.txt a.txt b.txt  大括号扩展有一个简写形式{start..end}，表示扩展成一个连续序列。比如，{a..z}可以扩展成26个小写英文字母。\n$ echo {a..c} a b c $ echo d{a..d}g dag dbg dcg ddg $ echo {1..4} 1 2 3 4 $ echo Number_{1..5} Number_1 Number_2 Number_3 Number_4 Number_5  这种简写形式支持逆序。\n$ echo {c..a} c b a $ echo {5..1} 5 4 3 2 1  注意，如果遇到无法理解的简写，大括号模式就会原样输出，不会扩展。\n$ echo {a1..3c} {a1..3c}  支持for...in循环：\nfor i in {1..4} do echo $i done  如果整数前面有前导0，扩展输出的每一项都有前导0。\n$ echo {01..5} 01 02 03 04 05 $ echo {001..5} 001 002 003 004 005  这种简写形式还可以使用第二个双点号{start..end..step}，用来指定扩展的步长。\n$ echo {0..8..2} 0 2 4 6 8  多个简写形式连用，会有循环处理的效果。\n$ echo {a..c}{1..3} a1 a2 a3 b1 b2 b3 c1 c2 c3  变量扩展 Bash 将美元符号$开头的词元视为变量，将其扩展成变量值。\n$ echo $SHELL /bin/bash  变量名除了放在美元符号后面，也可以放在${}里面:\n$ echo ${SHELL} /bin/bash  ${!string*}或${!string@}返回所有匹配给定字符串string的变量名。\n$ echo ${!SH*} SHELL SHELLOPTS SHLVL  子命令扩展 $(...)可以扩展成另一个命令的运行结果，该命令的所有输出都会作为返回值。\n$ echo $(date) Tue Jan 28 00:01:13 CST 2020  还有另一种较老的语法，子命令放在反引号之中，也可以扩展成命令的运行结果。\n$ echo `date` Tue Jan 28 00:01:13 CST 2020  $(...)可以嵌套，比如$(ls $(pwd))。\n算术扩展 $((...))可以扩展成整数运算的结果。\n$ echo $((2 + 2)) 4  量词语法 量词语法用来控制模式匹配的次数。它只有在 Bash 的extglob参数打开的情况下才能使用，不过一般是默认打开的。\n下面的命令可以查询:\n$ shopt extglob extglob on  如果extglob参数是关闭的，可以用下面的命令打开:\n$ shopt -s extglob  量词语法有下面几个:\n ?(pattern-list)：匹配零个或一个模式。 *(pattern-list)：匹配零个或多个模式。 +(pattern-list)：匹配一个或多个模式。 @(pattern-list)：只匹配一个模式。 !(pattern-list)：匹配给定模式以外的任何内容。  $ ls abc?(.)txt abctxt abc.txt # 匹配零个或一个def $ ls abc?(def) abc abcdef $ ls abc+(.txt) abc.txt abc.txt.txt  量词语法也属于文件名扩展，如果不存在可匹配的文件，就会原样输出:\n# 没有 abc 开头的文件名 $ ls abc?(def) ls: 无法访问'abc?(def)': 没有那个文件或目录  引号与转义 Bash 只有一种数据类型，就是字符串。不管用户输入什么数据，Bash 都视为字符串。因此，字符串相关的引号和转义，对 Bash 来说就非常重要。\n转义 转义分为 特殊字符转为普通字符 和 普通字符转为特殊字符。\ndigraph G{ rankdir=\u0026quot;LR\u0026quot; node[shape=box,fontname=\u0026quot;微软雅黑\u0026quot;] edge[arrowhead=none,fontname=\u0026quot;微软雅黑\u0026quot;] a00[label=\u0026quot;特殊字符\u0026quot; color=\u0026quot;red\u0026quot;] a01[label=\u0026quot;普通字符\u0026quot; color=\u0026quot;blue\u0026quot;] a00-\u0026gt;a01[label=\u0026quot;转义\\\\\u0026quot; arrowhead=\u0026quot;lvee\u0026quot; color=\u0026quot;red\u0026quot;] a01-\u0026gt;a00[arrowhead=\u0026quot;lvee\u0026quot; color=\u0026quot;blue\u0026quot;] }  特殊字符转为普通字符：如$、\u0026amp;、*、\\等特殊字符转为普通字符：\\$、\\\u0026amp;、\\*、\\\\。\n普通字符转为特殊字符：\n \\a：响铃 \\b：退格 \\n：换行 \\r：回车 \\t：制表符  在bash中，换行符是一个特殊字符，表示命令的结束，Bash 收到这个字符以后，就会对输入的命令进行解释执行。换行符前面加上反斜杠转义，就使得换行符变成一个普通字符，Bash 会将其当作空格处理，从而可以将一行命令写成多行。\n$ mv \\ /path/to/foo \\ /path/to/bar # 等同于 $ mv /path/to/foo /path/to/bar  单引号与双引号 Bash 允许字符串放在单引号或双引号之中，加以引用。\n单引号用于保留字符的字面含义，各种特殊字符在单引号里面，都会变为普通字符，比如星号（*）、美元符号（$）、反斜杠（\\）等。\n$ echo '*' * $ echo '$USER' $USER $ echo '$((2+2))' $((2+2)) $ echo '$(echo foo)' $(echo foo)  由于反斜杠在单引号里面变成了普通字符，所以如果单引号之中，还要使用单引号，不能使用转义，需要在外层的单引号前面加上一个美元符号（$），然后再对里层的单引号转义。\n# 不正确 $ echo it's # 不正确 $ echo 'it\\'s' # 正确 $ echo $'it\\'s'  更合理的方法是改在双引号之中使用单引号。\n$ echo \u0026quot;it's\u0026quot; it's  双引号与单引号的不同在于，双引号会解析三个特殊字符：美元符号（$）、反引号（`）和反斜杠（\\）。\n$ echo \u0026quot;$SHELL\u0026quot; /bin/bash $ echo \u0026quot;`date`\u0026quot; Mon Jan 27 13:33:18 CST 2020 $ echo \u0026quot;\\\\\u0026quot; \\  双引号与单引号都可以使换行符不在解析为结束符，可以在命令行输入多行文本。\n$ echo 'hello \u0026gt; woooo' hello woooo $ echo \u0026quot;hello \u0026gt; world\u0026quot; hello world  双引号还有一个作用，就是保存原始命令的输出格式：\n# 原始输出 $ cal March 2021 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 单行输出 $ echo $(cal) March 2021 Su Mo Tu We Th Fr Sa 1 ... 30 31 # 原始格式输出 $ echo \u0026quot;$(cal)\u0026quot; March 2021 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  Here 文档 Here 文档（here document）是一种输入多行字符串的方法，格式如下：\n\u0026lt;\u0026lt; token text token  组成部分：\n 开始标记：\u0026lt;\u0026lt; 标记。标记可以随意取名，后面必须换行。 内容 结束标记：标记。必须在单独一行。  Here 文档内部会发生变量替换，同时支持反斜杠转义，但是不支持通配符扩展，双引号和单引号也失去语法作用，变成了普通字符。\n$ foo='hello world' $ cat \u0026lt;\u0026lt; _example_ $foo \u0026quot;$foo\u0026quot; '$foo' _example_ hello world \u0026quot;hello world\u0026quot; 'hello world'  如果不希望发生变量替换，可以把 Here 文档的开始标记放在单引号之中。\n$ foo='hello world' $ cat \u0026lt;\u0026lt; '_example_' $foo \u0026quot;$foo\u0026quot; '$foo' _example_ $foo \u0026quot;$foo\u0026quot; '$foo'  Here 文档的本质是重定向，它将字符串重定向输出给某个命令，相当于包含了echo命令。\n$ command \u0026lt;\u0026lt; token string token # 等同于 $ echo string | command  Here 文档还有一个变体，叫做 Here 字符串（Here string），使用三个小于号（\u0026lt;\u0026lt;\u0026lt;）表示。作用是将字符串通过标准输入，传递给命令。\n$ cat \u0026lt;\u0026lt;\u0026lt; 'hi there' # 等同于 $ echo 'hi there' | cat  变量 Bash 变量分成环境变量和自定义变量两类。\n环境变量 环境变量是 Bash 环境自带的变量，进入 Shell 时已经定义好了，可以直接使用。它们通常是系统定义好的，也可以由用户从父 Shell 传入子 Shell。\n显示所有环境变量：\n$ env # 或者 $ printenv # 显示所有变量（包括环境变量和自定义变量），以及所有的 Bash 函数 $ set  查看单个环境变量的值\n$ printenv PATH # 或者 $ echo $PATH  常见的环境变量:\n   环境变量 说明     BASHPID Bash 进程的进程 ID。   BASHOPTS 当前 Shell 的参数，可以用shopt命令修改。   DISPLAY 图形环境的显示器名字，通常是:0，表示 X Server 的第一个显示器。   EDITOR 默认的文本编辑器。   HOME 用户的主目录。   HOST 当前主机的名称。   IFS 词与词之间的分隔符，默认为空格。   LANG 字符集以及语言编码，比如zh_CN.UTF-8。   PATH 由冒号分开的目录列表，当输入可执行程序名后，会搜索这个目录列表。   PS1 Shell 提示符。   PS2 输入多行命令时，次要的 Shell 提示符。   PWD 当前工作目录。   RANDOM 返回一个0到32767之间的随机数。   SHELL Shell 的名字。   SHELLOPTS 启动当前 Shell 的set命令的参数   TERM 终端类型名，即终端仿真器所用的协议。   UID 当前用户的 ID 编号。   USER 当前用户的用户名。    很多环境变量很少发生变化，而且是只读的，可以视为常量。\n 注意：Bash 变量名区分大小写\n 定义变量 用户创建变量的时候，变量名必须遵守下面的规则：\n 字母、数字和下划线字符组成。 第一个字符必须是一个字母或一个下划线，不能是数字。 不允许出现空格和标点符号。  变量声明：\nvariable=value   注意，等号两边不能有空格。\n 如果变量的值包含空格，则必须将值放在引号中:\nmyvar=\u0026quot;hello world\u0026quot;  Bash 没有数据类型的概念，所有的变量值都是字符串。\n变量可以重复赋值，后面的赋值会覆盖前面的赋值:\n$ foo=1 $ foo=2 $ echo $foo 2  如果同一行定义多个变量，必须使用分号（;）分隔:\n$ foo=1;bar=2  读取变量 读取变量的时候，直接在变量名前加上$就可以了:\n$ foo=bar $ echo $foo bar  如果变量不存在，Bash 不会报错，而会输出空字符。\n读取变量的时候，变量名也可以使用花括号{}包围，比如$a也可以写成${a}。这种写法可以用于变量名与其他字符连用的情况。\n$ a=foo $ echo $a_file $ echo ${a}_file foo_file  如果变量的值本身也是变量，可以使用${!varname}的语法，读取最终的值:\n$ myvar=USER $ echo ${!myvar} qlel  如果变量值包含连续空格（或制表符和换行符），最好放在双引号里面读取:\n$ a=\u0026quot;1 2 3\u0026quot; $ echo $a 1 2 3 $ echo \u0026quot;$a\u0026quot; 1 2 3  删除变量 unset命令用来删除一个变量:\nunset NAME  这个命令不是很有用。因为不存在的 Bash 变量一律等于空字符串，所以即使unset命令删除了变量，还是可以读取这个变量，值为空字符串。\n所以，删除一个变量，也可以将这个变量设成空字符串。\nexport 命令 用户创建的变量仅可用于当前 Shell，子 Shell 默认读取不到父 Shell 定义的变量。为了把变量传递给子 Shell，需要使用export命令。这样输出的变量，对于子 Shell 来说就是环境变量。\nexport命令用来向子 Shell 输出变量。\nNAME=foo # 输出 export NAME # 赋值和输出一起 export NAME=value  子 Shell 如果修改继承的变量，不会影响父 Shell：\n# 输出变量 $foo $ export foo=bar # 新建子 Shell $ bash # 读取 $foo $ echo $foo bar # 修改继承的变量 $ foo=baz # 退出子 Shell $ exit # 读取 $foo $ echo $foo bar  特殊变量 Bash 提供一些特殊变量。这些变量的值由 Shell 提供，用户不能进行赋值。\n 01 $?\n $?为上一个命令的退出码，用来判断上一个命令是否执行成功。\n 返回值是0，表示上一个命令执行成功 如果是非零，上一个命令执行失败。  $ ls abc ls: cannot access 'abc': No such file or directory $ echo $? 2   02 $$\n $$为当前 Shell 的进程 ID。\n$ echo $$ 671   03 $_\n $_为上一个命令的最后一个参数。\n$ ls -a $ $ echo $_ -a $ find ~/test -name 'read*' /home/qlel/test/read_0.sh $ echo $_ read_0.sh   04 $!\n $!为最近一个后台执行的异步命令的进程 ID。\n$ firefox \u0026amp; [1] 11064 $ echo $! 11064   05 $0\n $0为当前 Shell 的名称（在命令行直接执行时）或者脚本名（在脚本中执行时）。\n$ echo $0 bash   06 $-\n $-为当前 Shell 的启动参数。\n$ echo $- himBHs   07 $@和$#\n $@和$#表示脚本的参数数量。\n变量的默认值 Bash 提供四个特殊语法，跟变量的默认值有关，目的是保证变量不为空。\n ${varname:-word}  如果变量varname存在且不为空，则返回它的值，否则返回word。 它的目的是返回一个默认值，不设置varname变量的值。   ${varname:=word}  如果变量varname存在且不为空，则返回它的值，否则将它设为word，并且返回word。 它的目的是设置变量的默认值，并将默认值返回。   ${varname:+word}  如果变量varname存在且不为空，则返回word，否则返回空值。 它的目的是测试变量是否存在   ${varname:?message}  如果变量varname存在且不为空，则返回它的值，否则打印出varname: message，并中断脚本的执行。 如果省略了message，则输出默认的信息“parameter null or not set.”。 它的目的是防止变量未定义    上面四种语法如果用在脚本中，变量名的部分可以用数字1到9，表示脚本的参数。\nfilename=${1:?\u0026quot;filename missing.\u0026quot;}  1表示脚本的第一个参数。如果该参数不存在，就退出脚本并报错。\ndeclare 命令 declare命令可以声明一些特殊类型的变量，为变量设置一些限制，比如声明只读类型的变量和整数类型的变量。\n语法：\ndeclare OPTION VARIABLE=value  选项：\n   选项 说明     -a 声明数组变量。   -f 输出所有函数定义。   -F 输出所有函数名。   -i 声明整数变量。   -l 声明变量为小写字母。   -p 查看变量信息。   -r 声明只读变量。   -u 声明变量为大写字母。   -x 该变量输出为环境变量。     注意，declare命令如果用在函数中，声明的变量只在函数内部有效，等同于local命令。\n (1) -i -i参数声明整数变量以后，可以直接进行数学运算。\n$ declare -i val1=12 val2=5 $ declare -i result $ result=val1*val2 $ echo $result 60  注意，一个变量声明为整数以后，依然可以被改写为字符串。\n$ declare -i var=12 $ var=foo $ echo $var 0  (2) -x -x参数等同于export命令，可以输出一个变量为子 Shell 的环境变量。\n$ declare -x foo # 等同于 $ export foo  (3) -r -r参数可以声明只读变量，无法改变变量值，也不能unset变量。\n$ declare -r bar=1 $ bar=2 bash: bar：只读变量 $ echo $? 1 $ unset bar bash: bar：只读变量 $ echo $? 1  readonly 命令 readonly命令等同于declare -r，用来声明只读变量，不能改变变量值，也不能unset变量。\n$ readonly foo=1 $ foo=2 bash: foo：只读变量 $ echo $? 1     选项 说明     -f 声明的变量为函数名。   -p 打印出所有的只读变量。   -a 声明的变量为数组。    let 命令 let命令声明变量时，可以直接执行算术表达式。\n$ let foo=1+2 $ echo $foo 3  let命令的参数表达式如果包含空格，就需要使用引号:\n$ let \u0026quot;foo = 1 + 2\u0026quot;  可以同时对多个变量赋值，赋值表达式之间使用空格分隔:\n$ let \u0026quot;v1 = 1\u0026quot; \u0026quot;v2 = v1++\u0026quot; $ echo $v1,$v2 2,1  字符串操作 字符串长度 获取字符串长度的语法：\n${#varname} # 示例 $ myPath=/home/cam/book/long.file.name $ echo ${#myPath} 29  子字符串 字符串提取子串的语法：\n${varname:offset:length}  从offset(从0开始计算)位置开始，返回长度为length的变量varname的子串，原变量varname不变。\n$ aa=helloworld $ echo ${aa:2:5} llowo # 省略length $ echo ${aa:3} loworld $ echo $aa helloworld  如果offset为负值，表示从字符串的末尾开始算起。注意，负数前面必须有一个空格， 以防止与${variable:-word}的变量的设置默认值语法混淆。这时还可以指定length，length可以是正值，也可以是负值（负值不能超过offset的长度）。\n$ aa=helloworld $ echo ${aa: -3} rld $ echo ${aa: -3:2} rl $ echo ${aa: -3:-2} r $ echo ${aa: -3:-3} $ echo ${aa: -3:-5} -bash: -5: substring expression \u0026lt; 0  搜索和替换 (1) 字符串头部的模式匹配\n从字符串头部开始匹配，如果匹配成功，就删除匹配的部分，返回剩下的部分。如果匹配不成功，则返回原始字符串。原始变量不会发生变化。\n# 如果 pattern 匹配变量 variable 的开头， # 删除最短匹配（非贪婪匹配）的部分，返回剩余部分 ${variable#pattern} # 如果 pattern 匹配变量 variable 的开头， # 删除最长匹配（贪婪匹配）的部分，返回剩余部分 ${variable##pattern}  匹配模式pattern可以使用*、?、[]等通配符。\n$ phone=\u0026quot;555-456-1414\u0026quot; $ echo ${phone#*-} 456-1414 $ echo ${phone##*-} 1414  替换匹配内容：\n${variable/#pattern/string} # 示例 $ foo=JPG.JPG $ echo ${foo/#JPG/jpg} jpg.JPG # 只有贪婪匹配替换 $ phone=\u0026quot;555-456-1414\u0026quot; $ echo ${phone/#*-/2222} 22221414  (2) 字符串尾部的模式匹配\n从字符串尾部开始匹配，如果匹配成功，就删除匹配的部分，返回剩下的部分。如果匹配不成功，则返回原始字符串。原始变量不会发生变化。\n# 如果 pattern 匹配变量 variable 的结尾， # 删除最短匹配（非贪婪匹配）的部分，返回剩余部分 ${variable%pattern} # 如果 pattern 匹配变量 variable 的结尾， # 删除最长匹配（贪婪匹配）的部分，返回剩余部分 ${variable%%pattern}  示例：\n$ phone=\u0026quot;555-456-1414\u0026quot; $ echo ${phone%-*} 555-456 $ echo ${phone%%-*} 555  替换匹配内容：\n${variable/%pattern/string} # 示例 $ foo=JPG.JPG $ echo ${foo/%JPG/jpg} JPG.jpg # 只有贪婪匹配替换 $ phone=\u0026quot;555-456-1414\u0026quot; $ echo ${phone/%-*/2222} 5552222  (3) 任意位置的模式匹配\n从字符串任意位置开始匹配，如果匹配成功，就删除匹配的部分，返回剩下的部分。如果匹配不成功，则返回原始字符串。原始变量不会发生变化。\n# 如果 pattern 匹配变量 variable 的一部分， # 最长匹配（贪婪匹配）的那部分被 string 替换，但仅替换第一个匹配 ${variable/pattern/string} # 如果 pattern 匹配变量 variable 的一部分， # 最长匹配（贪婪匹配）的那部分被 string 替换，所有匹配都替换 ${variable//pattern/string}  示例：\n$ phone=\u0026quot;555-456-1414\u0026quot; $ echo ${phone/*-} 1414 $ echo ${phone/*-/abcd} abcd1414 $ echo ${phone//*-} 1414 $ echo ${phone//*-/aaa} aaa1414 # 将分隔符从:换成换行符 $ echo -e ${PATH//:/'\\n'} /usr/local/bin /usr/bin /bin ...  改变大小写 # 转为大写 ${varname^^} # 转为小写 ${varname,,}  示例：\n$ foo=heLLo $ echo ${foo^^} HELLO $ echo ${foo,,} hello  算术运算 算术表达式 ((...))语法可以进行整数的算术运算，还会自动忽略内部的空格：\n$ ((foo = 5 + 5)) $ echo $foo 10  此语法不返回值，只要算术结果不是0，命令就算执行成功。如果算术结果为0，命令就算执行失败。\n$ ((2-5)) $ echo $? 0 $ ((2-2)) $ echo $? 1  如果要读取算术运算的结果，需要在((...))前面加上美元符号：$((...))，使其变成算术表达式，返回算术运算的值。\n$ echo $((2 + 2)) 4  支持的算术运算符:\n   运算符 说明     + 加法   - 减法   * 乘法   / 除法（整除）   % 余数   ** 指数   ++ 自增运算（前缀或后缀）   -- 自减运算（前缀或后缀）    注意，除法运算符的返回结果总是整数:\n$ echo $((5 / 2)) 2   ++或--  作为前缀是先运算后返回值 作为后缀是先返回值后运算    $ i=0 $ echo $i 0 $ echo $((i++)) 0 $ echo $i 1 $ echo $((++i)) 2 $ echo $i 2  $((...))内部可以用圆括号改变运算顺序:\n$ echo $(( (2 + 3) * 4 )) 20  数值的进制 Bash 的数值默认都是十进制，但是在算术表达式中，也可以使用其他进制:\n   语法 说明     number 没有任何特殊表示法的数字是十进制数（以10为底）。   0number 八进制数。   0xnumber 十六进制数。   base#number base进制的数。    # $(())会返回10进制的数值，16进制转10进制 $ echo $((0xff)) 255 # 2进制转10进制 $ echo $((2#11111111)) 255  位运算 $((...))支持以下的二进制位运算符：\n   运算符 说明     \u0026lt;\u0026lt; 位左移运算，把一个数字的所有位向左移动指定的位。   \u0026gt;\u0026gt; 位右移运算，把一个数字的所有位向右移动指定的位。   \u0026amp; 位的“与”运算，对两个数字的所有位执行一个AND操作。   ` `   ~ 位的“否”运算，对一个数字的所有位取反。   ^ 位的异或运算，对两个数字的所有位执行一个异或操作。    示例：\n# 右移，16的二进制 0001 0000 -\u0026gt; 0000 0100 -\u0026gt; 4 $ echo $((16\u0026gt;\u0026gt;2)) 4 # 左移，16的二进制 0001 0000 -\u0026gt; 0100 0000 -\u0026gt; 64 $ echo $((16\u0026lt;\u0026lt;2)) 64  逻辑运算 $((...))支持以下逻辑运算符：\n   运算符 说明     \u0026lt; 小于   \u0026gt; 大于   \u0026lt;= 小于或相等   \u0026gt;= 大于或相等   == 相等   != 不相等   \u0026amp;\u0026amp; 逻辑与   `    ! 逻辑否   expr1?expr2:expr3 三元条件运算符。\n若表达式expr1的计算结果为非零值（算术真），则执行表达式expr2，否则执行表达式expr3。    如果逻辑表达式为真，返回1，否则返回0。\n$ echo $((3 \u0026gt; 2)) 1 $ echo $(( (3 \u0026gt; 2) || (4 \u0026lt;= 1) )) 1 # 三元条件运算符 $ a=0 $ echo $((a\u0026lt;1 ? 1 : 0)) 1 $ echo $((a\u0026gt;1 ? 1 : 0)) 0  赋值运算 $((...))支持以下赋值运算符：\n   运算符 说明     var = value 简单赋值。   var += value 等价于var = var + value。   var -= value 等价于var = var – value。   var *= value 等价于var = var * value。   var /= value 等价于var = var / value。   var %= value 等价于var = var % value。   var \u0026lt;\u0026lt;= value 等价于var = var \u0026lt;\u0026lt; value。   var \u0026gt;\u0026gt;= value 等价于var = var \u0026gt;\u0026gt; value。   var \u0026amp;= value 等价于var = var \u0026amp; value。   `var = value`   var ^= value 等价于var = var ^ value。    示例：\n$ foo=5 $ echo $((foo*=2)) 10  求值运算 逗号,在$((...))内部是求值运算符，执行前后两个表达式，并返回后一个表达式的值。\n$ echo $((foo = 1 + 2, 3 * 4)) 12 $ echo $foo 3  expr 命令 expr命令支持算术运算，可以不使用((...))语法，但也不支持非整数运算。\n$ expr 3 + 2 5 $ a=3 $ expr $a - 7 -4 # 不支持非整数 $ expr 3.5 + 2 expr: non-integer argument   注意，expr使用运算符两边要有空格\n read 命令 read命令用于从标准输入读取数值。\n有时，脚本需要在执行过程中，由用户提供一部分数据，这时可以使用read命令。它将用户的输入存入一个变量，方便后面的代码使用。用户按下回车键，就表示输入结束。\n格式：\nread [-options] [variable...]   options是参数选项 variable是用来保存输入数值的一个或多个变量名 如果没有提供变量名，环境变量REPLY会包含用户输入的一整行数据  示例：demo.sh\n#!/bin/bash echo -n \u0026quot;输入一些文本 \u0026gt; \u0026quot; read text echo \u0026quot;你的输入：$text\u0026quot;  执行：\n$ bash demo.sh 输入一些文本 \u0026gt; 你好，世界 你的输入：你好，世界  read可以接受用户输入的多个值，多个值之间用空格分开，分别读入到相应的多个变量中，多余值都会读入到最后一个变量中：read_0.sh\n#!/usr/bin/env bash echo -n \u0026quot;输入一些文本 \u0026gt; \u0026quot; read text1 text2 echo \u0026quot;1: $text1\u0026quot; echo \u0026quot;2: $text2\u0026quot;  执行：\n$ ./read_0.sh 输入一些文本 \u0026gt; a b 1 3 1: a 2: b 1 3  还可以读取文件：\n#!/bin/bash filename=$(echo ~/py_msg.txt) while read myline;do echo \u0026quot;$myline\u0026quot; done \u0026lt; $filename  选项    选项 说明     -a array 以空格分隔顺序读取字符到数组array   -d delim 设置分隔符为delim   -e 开启tab自动补全   -i text 设置输入字符默认值为text   -n nchars 设置输入字符长度为nchars，\n如果提前遇到分隔符则返回到分隔符前的字符   -N nchars 设置输入字符长度为nchars，忽略分隔符   -p prompt 设置输入前的提示信息prompt   -r 禁止反斜杠转义任何字符   -s 在输入字符时不再屏幕上显示，对密码有用   -t timeout 设置输入字符的等待时间\n超过时间脚本将放弃等待，继续向下执行   -u fd 使用文件描述符fd作为输入    条件判断 if 语法结构：\nif commands; then commands [elif commands; then commands...] [else commands] fi  示例：\n# 可以写成两行，这时不需要分号 if true then echo 'hello world' fi  test 命令 if结构的判断条件，一般使用test命令，有三种形式:\n# 写法一 test expression # 写法二 [ expression ] # 写法三 [[ expression ]]  上面三种形式是等价的，但是第三种形式还支持正则判断，前两种不支持。\nexpression是一个表达式，如果表达式为真，test命令执行成功（返回值为0）；表达式为假，test命令执行失败（返回值为1）。\n 注意，第二种和第三种写法，[和]与内部的表达式之间必须有空格。\n 示例：判断文件是否存在\n$ test -f /etc/hosts $ echo $? 0 # 或者 $ [ -f /etc/hosts ] $ echo $? 0  文件判断    表达式 说明     [ -b file ] 如果 file 存在并且是一个块（设备）文件，则为true。   [ -c file ] 如果 file 存在并且是一个字符（设备）文件，则为true。   [ -d file ] 如果 file 存在并且是一个目录，则为true。   [ -e file ] 如果 file 存在，则为true。   [ -f file ] 如果 file 存在并且是一个普通文件，则为true。   [ -g file ] 如果 file 存在并且设置了组 ID，则为true。   [ -G file ] 如果 file 存在并且属于有效的组 ID，则为true。   [ -h file ] 如果 file 存在并且是符号链接，则为true。   [ -k file ] 如果 file 存在并且设置了它的“sticky bit”，则为true。   [ -L file ] 如果 file 存在并且是一个符号链接，则为true。   [ -N file ] 如果 file 存在并且自上次读取后已被修改，则为true。   [ -O file ] 如果 file 存在并且属于有效的用户 ID，则为true。   [ -p file ] 如果 file 存在并且是一个命名管道，则为true。   [ -r file ] 如果 file 存在并且可读（当前用户有可读权限），则为true。   [ -s file ] 如果 file 存在且其长度大于零，则为true。   [ -S file ] 如果 file 存在且是一个网络 socket，则为true。   [ -t fd ] 如果 fd 是一个文件描述符，并且重定向到终端，则为true。 这可以用来判断是否重定向了标准输入／输出／错误。   [ -u file ] 如果 file 存在并且设置了 setuid 位，则为true。   [ -w file ] 如果 file 存在并且可写（当前用户拥有可写权限），则为true。   [ -x file ] 如果 file 存在并且可执行（有效用户有执行／搜索权限），则为true。   [ file1 -nt file2 ] 如果 FILE1 比 FILE2 的更新时间最近，或者 FILE1 存在而 FILE2 不存在，则为true。   [ file1 -ot file2 ] 如果 FILE1 比 FILE2 的更新时间更旧，或者 FILE2 存在而 FILE1 不存在，则为true。   [ FILE1 -ef FILE2 ] 如果 FILE1 和 FILE2 引用相同的设备和 inode 编号，则为true。    字符串判断  [ string ]：如果string不为空（长度大于0），则判断为真。 [ -n string ]：如果字符串string的长度大于零，则判断为真。 [ -z string ]：如果字符串string的长度为零，则判断为真。 [ string1 = string2 ]：如果string1和string2相同，则判断为真。 [ string1 == string2 ]等同于[ string1 = string2 ]。 [ string1 != string2 ]：如果string1和string2不相同，则判断为真。 [ string1 '\u0026gt;' string2 ]：如果按照字典顺序string1排列在string2之后，则判断为真。 [ string1 '\u0026lt;' string2 ]：如果按照字典顺序string1排列在string2之前，则判断为真。   注意，test命令内部的\u0026gt;和\u0026lt;，必须用引号引起来（或者是用反斜杠转义）。否则，它们会被 shell 解释为重定向操作符。\n 整数判断  [ int1 -eq int2 ]：如果int1等于int2，则为true。 [ int1 -ne int2 ]：如果int1不等于int2，则为true。 [ int1 -le int2 ]：如果int1小于或等于int2，则为true。 [ int1 -lt int2 ]：如果int1小于int2，则为true。 [ int1 -ge int2 ]：如果int1大于或等于int2，则为true。 [ int1 -gt int2 ]：如果int1大于int2，则为true。  正则判断 [[ expression ]]这种判断形式，支持正则表达式。\n[[ string1 =~ regex ]]  regex是一个正则表示式，=~是正则比较运算符。\n示例：\n#!/bin/bash INT=-5 if [[ \u0026quot;$INT\u0026quot; =~ ^-?[0-9]+$ ]]; then echo \u0026quot;INT is an integer.\u0026quot; exit 0 else echo \u0026quot;INT is not an integer.\u0026quot; \u0026gt;\u0026amp;2 exit 1 fi  test 判断的逻辑运算 通过逻辑运算，可以把多个test判断表达式结合起来，创造更复杂的判断。\n三种逻辑运算AND，OR，和NOT，都有自己的专用符号。\n AND运算：符号\u0026amp;\u0026amp;，也可使用参数-a。 OR运算：符号||，也可使用参数-o。 NOT运算：符号!。  示例：\n#!/bin/bash MIN_VAL=1 MAX_VAL=100 INT=50 if [ ! \\( $INT -ge $MIN_VAL -a $INT -le $MAX_VAL \\) ]; then echo \u0026quot;$INT is outside $MIN_VAL to $MAX_VAL.\u0026quot; else echo \u0026quot;$INT is in range.\u0026quot; fi  使用否定操作符!时，最好用圆括号确定转义的范围。test命令内部使用的圆括号，必须使用引号或者转义，否则会被 Bash 解释。\n算术判断 Bash 还提供了((...))作为算术条件，进行算术运算的判断。\nif ((3 \u0026gt; 2)); then echo \u0026quot;true\u0026quot; fi  如果算术计算的结果是非零值，则表示判断成立。这一点跟命令的返回值正好相反，需要小心。\n$ if ((1)); then echo \u0026quot;It is true.\u0026quot;; fi It is true. $ if ((0)); then echo \u0026quot;It is true.\u0026quot;; else echo \u0026quot;it is false.\u0026quot;; fi It is false.  case case结构用于多值判断，可以为每个值指定对应的命令，跟包含多个elif的if结构等价，但是语义更好。它的语法如下:\ncase expression in pattern ) commands ;; pattern ) commands ;; ... esac  expression是一个表达式，pattern是表达式的值或者一个模式，可以有多条，用来匹配多个值，每条以两个分号（;）结尾。\n#!/bin/bash echo -n \u0026quot;输入一个1到3之间的数字（包含两端）\u0026gt; \u0026quot; read character case $character in 1 ) echo 1 ;; 2 ) echo 2 ;; 3 ) echo 3 ;; * ) echo 输入不符合要求 esac   case的匹配模式可以使用各种通配符: a)：匹配a。 a|b)：匹配a或b。 [[:alpha:]])：匹配单个字母。 ???)：匹配3个字符的单词。 *.txt)：匹配.txt结尾。 *)：匹配任意输入，通过作为case结构的最后一个模式。  echo -n \u0026quot;输入一个字母或数字 \u0026gt; \u0026quot; read character case $character in [[:lower:]] | [[:upper:]] ) echo \u0026quot;输入了字母 $character\u0026quot; ;; [0-9] ) echo \u0026quot;输入了数字 $character\u0026quot; ;; * ) echo \u0026quot;输入不符合要求\u0026quot; esac  Bash 4.0之前，case结构只能匹配一个条件，然后就会退出case结构。\nBash 4.0之后，允许匹配多个条件，这时可以用;;\u0026amp;终止每个条件块。\nread -n 1 -p \u0026quot;Type a character \u0026gt; \u0026quot; echo case $REPLY in [[:upper:]]) echo \u0026quot;'$REPLY' is upper case.\u0026quot; ;;\u0026amp; [[:lower:]]) echo \u0026quot;'$REPLY' is lower case.\u0026quot; ;;\u0026amp; [[:alpha:]]) echo \u0026quot;'$REPLY' is alphabetic.\u0026quot; ;;\u0026amp; [[:digit:]]) echo \u0026quot;'$REPLY' is a digit.\u0026quot; ;;\u0026amp; [[:graph:]]) echo \u0026quot;'$REPLY' is a visible character.\u0026quot; ;;\u0026amp; [[:punct:]]) echo \u0026quot;'$REPLY' is a punctuation symbol.\u0026quot; ;;\u0026amp; [[:space:]]) echo \u0026quot;'$REPLY' is a whitespace character.\u0026quot; ;;\u0026amp; [[:xdigit:]]) echo \u0026quot;'$REPLY' is a hexadecimal digit.\u0026quot; ;;\u0026amp; esac  循环 while while循环有一个判断条件，只要符合条件，就不断循环执行指定的语句。\nwhile condition; do commands done  循环条件condition可以使用test命令，跟if结构的判断条件写法一致。\nnumber=0 while [ \u0026quot;$number\u0026quot; -lt 10 ]; do echo \u0026quot;Number = $number\u0026quot; number=$((number + 1)) done  until until循环与while循环恰好相反，只要不符合判断条件（判断条件失败），就不断循环执行指定的语句。一旦符合判断条件，就退出循环。\nuntil condition; do commands done  until的条件部分也可以是一个命令，表示在这个命令执行成功之前，不断重复尝试。\nuntil cp $1 $2; do echo 'Attempt to copy failed. waiting...' sleep 5 done  for\u0026hellip;in for...in循环用于遍历列表的每一项。\nfor variable in list; do commands done  for循环会依次从list列表中取出一项，作为变量variable，然后在循环体中进行处理。\n#!/bin/bash for i in word1 word2 word3; do echo $i done  列表可以由通配符产生:\nfor i in *.png; do ls -l $i done  in list的部分可以省略，这时list默认等于脚本的所有参数$@。但是，为了可读性，最好还是不要省略，参考下面的例子:\nfor filename; do echo \u0026quot;$filename\u0026quot; done # 等同于 for filename in \u0026quot;$@\u0026quot; ; do echo \u0026quot;$filename\u0026quot; done  在函数体中也是一样的，for...in循环省略in list的部分，则list默认等于函数的所有参数。\nfor for循环还支持 C 语言的循环语法。\nfor (( expression1; expression2; expression3 )); do commands done  expression1用来初始化循环条件，expression2用来决定循环结束的条件，expression3在每次循环迭代的末尾执行，用于更新值。\n注意，循环条件放在双重圆括号之中。另外，圆括号之中使用变量，不必加上美元符号$。\nfor (( i=0; i\u0026lt;5; i=i+1 )); do echo $i done  for条件部分的三个语句，都可以省略:\nfor ((;;)) do read var if [ \u0026quot;$var\u0026quot; = \u0026quot;.\u0026quot; ]; then break fi done  上面脚本会反复读取命令行输入，直到用户输入了一个点（.）为止，才会跳出循环。\nbreak，continue break命令立即终止循环，程序继续执行循环块之后的语句，即不再执行剩下的循环。\n#!/bin/bash for number in 1 2 3 4 5 6 do echo \u0026quot;number is $number\u0026quot; if [ \u0026quot;$number\u0026quot; = \u0026quot;3\u0026quot; ]; then break fi done  上面例子只会打印3行结果。一旦变量$number等于3，就会跳出循环，不再继续执行。\ncontinue命令立即终止本轮循环，开始执行下一轮循环。\nselect select结构主要用来生成简单的菜单。它的语法与for...in循环基本一致。\nselect name [in list] do commands done  Bash 会对select依次进行下面的处理:\n select生成一个菜单，内容是列表list的每一项，并且每一项前面还有一个数字编号。 Bash 提示用户选择一项，输入它的编号。 用户输入以后，Bash 会将该项的内容存在变量name，该项的编号存入环境变量REPLY。如果用户没有输入，就按回车键，Bash 会重新输出菜单，让用户选择。 执行命令体commands。 执行结束后，回到第一步，重复这个过程。  实力：\n#!/bin/bash # select.sh select brand in Samsung Sony iphone symphony Walton do echo \u0026quot;You have chosen $brand\u0026quot; done  执行：\n$ ./select.sh 1) Samsung 2) Sony 3) iphone 4) symphony 5) Walton #?  如果用户没有输入编号，直接按回车键。Bash 就会重新输出一遍这个菜单，直到用户按下Ctrl + c，退出执行。\nselect可以与case结合，针对不同项，执行不同的命令。\n函数 函数定义的语法有两种：\n# 第一种 fn() { # codes } # 第二种 function fn() { # codes }  fn是自定义的函数名，函数代码就写在大括号之中。这两种写法是等价的。\n示例：\n#!/bin/bash # 函数体里面的$1表示函数调用时的第一个参数。 hello(){ echo \u0026quot;Hello $1\u0026quot; } hello \u0026quot;this is hello func\u0026quot;  执行：\n$ ./func_0.sh Hello this is hello func  删除一个函数，可以使用unset命令:\nunset -f functionName  参数变量 函数体内可以使用参数变量，获取函数参数。函数的参数变量，与脚本参数变量是一致的。\n $1~$9：函数的第一个到第9个的参数。 如果函数的参数多于9个，那么第10个参数可以用${10}的形式引用，以此类推。 $0：函数所在的脚本名。 $#：函数的参数总数。 $@：函数的全部参数，参数之间使用空格分隔。 $*：函数的全部参数，参数之间使用变量$IFS值的第一个字符分隔，默认为空格，但是可以自定义。  return 命令 return命令用于从函数返回一个值。函数执行到这条命令，就不再往下执行了，直接返回了。\nfn() { return 10 }  函数将返回值返回给调用者。如果命令行直接执行函数，下一个命令可以用$?拿到返回值。\nreturn后面不跟参数，只用于返回也是可以的:\nfn() { commond ... return }  全局和局部变量，local 命令 Bash 函数体内直接声明的变量，属于全局变量，整个脚本都可以读取。也可以直接修改全局变量。\n#!/bin/bash # func_1.sh fn(){ foo=1 echo \u0026quot;fn: foo = $foo\u0026quot; } fn echo \u0026quot;global: foo = $foo\u0026quot;  执行：\n$ ./func_1.sh fn: foo = 1 global: foo = 1  上面例子中，变量$foo是在函数fn内部声明的，函数体外也可以读取。\n函数里面可以用local命令声明局部变量。\n#!/bin/bash # func_2.sh fn(){ local foo foo=1 echo \u0026quot;fn: foo = $foo\u0026quot; } fn echo \u0026quot;global: foo = $foo\u0026quot;  执行：\n$ ./func_2.sh fn: foo = 1 global: foo =  上面例子中，local命令声明的$foo变量，只在函数体内有效，函数体外没有定义。\n数组 数组（array）是一个包含多个值的变量。成员的编号从0开始，数量没有上限，也没有要求成员被连续索引。\n创建数组 arr=(value1 value2 ... valueN) # 等同于 arr=( value1 value2 ... valueN ) # 等同于 arr[0]=value1 arr[1]=value2 ... arr[N-1]=valueN  arr是数组的名字，可以是任意合法的变量名。索引从0开始，是一个大于或等于零的整数，也可以是算术表达式。\n可以指定索引创建数组：\n$ array=(a b c) $ array=([2]=c [0]=a [1]=b)  可以使用通配符:\n$ mp3s=( *.mp3 )  declare -a命令声明一个数组或read -a命令则是将用户的命令行输入读入一个数组。\n$ declare -a arr1 $ read -a arr2  读取数组 # 读取单个元素 $ arr1=(a b c) $ echo ${arr1[1]} b # 如果没有指定索引，默认读取索引 0 位置的值 $ echo ${arr1} a # 读取所有成员 $ echo ${arr1[@]} a b c # 或 $ echo ${arr1[*]} a b c  读取数组索引 $ arr=([5]=a [9]=b [23]=c) $ echo ${!arr[@]} 5 9 23 $ echo ${!arr[*]} 5 9 23  利用这个语法，也可以通过for循环遍历数组:\narr=(a b c d) for i in ${!arr[@]};do echo ${arr[i]} done  遍历数组 使用for...in遍历数组。\n遍历读取数组时，放不放在双引号之中，是有差别的。\n使用*或@时，不放在双引号之中，结果都会解析双引号中的空格：\n#!/bin/bash arr1=(a b \u0026quot;cc 33\u0026quot; d \u0026quot;ee 55\u0026quot; f) for i in ${arr1[@]}; do echo $i done # 执行结果： $ ./arr_for_0.sh a b cc 33 d ee 55 f  放在双引号之中：\n#!/bin/bash arr1=(a b \u0026quot;cc 33\u0026quot; d \u0026quot;ee 55\u0026quot; f) for i in \u0026quot;${arr1[@]}\u0026quot;; do echo $i done # 执行结果： $ ./arr_for_0.sh a b cc 33 d ee 55 f  *: ${arr1[*]}放在双引号之中，所有元素就会变成单个字符串返回。\n#!/bin/bash arr1=(a b \u0026quot;cc 33\u0026quot; d \u0026quot;ee 55\u0026quot; f) for i in \u0026quot;${arr1[*]}\u0026quot;; do echo $i done # 执行结果： $ ./arr_for_0.sh a b cc 33 d ee 55 f  数组的长度 ${#array[*]} ${#array[@]}  示例：\n$ a[100]=foo $ echo ${#a[*]} 1 $ echo ${#a[@]} 1  提取数组成员 ${array[@]:position:length}\n$ arr1=(a b c d e f) $ echo ${arr1[@]:1:1} b $ echo ${arr1[@]:1:3} b c d # 省略length，则返回从指定位置开始到最后的所有成员 $ echo ${arr1[@]:3} d e f  追加数组成员 数组末尾追加成员，可以使用+=赋值运算符。它能够自动地把值追加到数组末尾。\n$ arr1=(a b c) $ arr1+=(d e) $ echo ${arr1[@]} a b c d e  删除数组成员 删除数组成员，使用unset命令。\n$ arr1=(a b c) $ unset arr1[1] $ echo ${arr1[@]} a c  将某个成员设为空值，可以从返回值中“隐藏”这个成员。“隐藏”不是删除，成员还存在，数组长度也没变，只是变为空值。\n$ arr1=(a b c) $ arr1[1]= $ echo ${arr1[@]} a c $ echo ${#arr1[@]} 3  unset ArrayName可以清空整个数组。\n$ arr1=(a b c) $ echo ${arr1[@]} a b c $ unset arr1 $ echo ${arr1[@]} $ echo ${#arr1[@]} 0  关联数组 Bash 的新版本支持关联数组。关联数组使用字符串而不是整数作为数组索引。\ndeclare -A可以声明关联数组。\n$ declare -A colors $ colors[\u0026quot;red\u0026quot;]=\u0026quot;#ff0000\u0026quot; $ colors[\u0026quot;green\u0026quot;]=\u0026quot;#00ff00\u0026quot; $ colors[\u0026quot;blue\u0026quot;]=\u0026quot;#0000ff\u0026quot; $ echo ${colors[@]} #ff0000 #00ff00 #0000ff $ echo ${#colors[@]} 3 $ echo ${colors['blue']} #0000ff  set 命令 set命令用来修改子 Shell 环境的运行参数，即定制环境。\n如果命令行下不带任何参数，直接运行set，会显示所有的环境变量和 Shell 函数。\n$ set  -u set -u：在脚本运行中遇到不存在的变量时报错并退出脚本运行。\n执行脚本时，如果遇到不存在的变量，Bash 默认忽略它：\n#!/usr/bin/env bash echo $a echo bar  上面代码中，$a是一个不存在的变量。执行结果如下：\n$ bash script.sh bar  可以看到，echo $a输出了一个空行，Bash 忽略了不存在的$a，然后继续执行echo bar。大多数情况下，这不是开发者想要的行为，遇到变量不存在，脚本应该报错，而不是一声不响地往下执行。\nset -u就用来改变这种行为。脚本在头部加上它，遇到不存在的变量就会报错，并停止执行。\n#!/usr/bin/env bash set -u echo $a echo bar  运行结果如下:\n$ bash set_0.sh set_0.sh: line 5: a: unbound variable  可以看到，脚本报错了，并且不再执行后面的语句。\n-u还有另一种写法-o nounset，两者是等价的。\nset -o nounset  -x 默认情况下，脚本执行后，只输出运行结果，没有其他内容。如果多个命令连续执行，它们的运行结果就会连续输出。有时会分不清，某一段内容是什么命令产生的。\nset -x用来在运行结果之前，先输出执行的那一行命令。\n#!/usr/bin/env bash set -x echo bar  执行上面的脚本，结果如下:\n$ bash script.sh + echo bar bar  这对于调试复杂的脚本是很有用的。\n-x还有另一种写法-o xtrace：\nset -o xtrace  脚本当中如果要关闭命令输出，可以使用set +x。\n#!/bin/bash number=1 set -x if [ $number = \u0026quot;1\u0026quot; ]; then echo \u0026quot;Number equals 1\u0026quot; else echo \u0026quot;Number does not equal 1\u0026quot; fi set +x  上面的例子中，只对特定的代码段打开命令输出。\n-e 如果脚本里面有运行失败的命令（返回值非0），Bash 默认会继续执行后面的命令。\nset -e使得脚本只要发生错误，就终止执行。\n-e打开；+e关闭。可以只对特定命令段使用，某些命令的非零返回值可能不表示失败，或者开发者希望在命令失败的情况下，脚本继续执行下去：\nset +e # 关闭 command1 command2 set -e # 打开  -e还有另一种写法-o errexit。\n-E 一旦设置了-e参数，会导致函数内的错误不会被trap命令捕获。-E参数可以纠正这个行为，使得函数也能继承trap命令。\n-o pipefail set -e有一个例外情况，就是不适用于管道命令。\nset -o pipefail用来解决这种情况，只要一个子命令失败，整个管道命令就失败，脚本就会终止执行。\n其它  set -n：等同于set -o noexec，不运行命令，只检查语法是否正确。 set -f：等同于set -o noglob，表示不对通配符进行文件名扩展。可以使用set +f关闭。 set -v：等同于set -o verbose，表示打印 Shell 接收到的每一行输入。可以使用set +v关闭。 set -o noclobber：防止使用重定向运算符\u0026gt;覆盖已经存在的文件。  总结 set命令的几个参数，一般都放在一起使用：\n# 写法一 set -Eeuxo pipefail # 写法二 set -Eeux set -o pipefail  这两种写法建议放在所有 Bash 脚本的头部。\n另一种办法是在执行 Bash 脚本的时候，从命令行传入这些参数:\n$ bash -euxo pipefail script.sh  shopt 命令 shopt命令用来调整 Shell 的参数，跟set命令的作用很类似。之所以会有这两个类似命令的主要原因是，set是从 Ksh 继承的，属于 POSIX 规范的一部分，而shopt是 Bash 特有的。\n直接输入shopt可以查看所有参数，以及它们各自打开和关闭的状态\n$ shopt  shopt命令后面跟着参数名，可以查询该参数是否打开:\n$ shopt globstar globstar off  选项：\n -s param：打开某个参数param。 -u param：关闭某个参数param。 -q param：查询某个参数是否打开，但不是直接输出查询结果，而是通过命令的执行状态（$?）表示查询结果。如果状态为0，表示该参数打开；如果为1，表示该参数关闭。主要用于脚本，供if条件结构使用。  mktemp 命令 mktemp命令是为安全创建临时文件而设计的。虽然在创建临时文件之前，它不会检查临时文件是否存在，但是它支持唯一文件名和清除机制，因此可以减轻安全攻击的风险。\n直接运行mktemp命令，就能生成一个临时文件。\n$ mktemp /tmp/tmp.1AA63DzEwn $ ls -l /tmp/tmp.1AA63DzEwn -rw------- 1 qlel qlel 0 Mar 30 16:06 /tmp/tmp.1AA63DzEwn  上面命令中，mktemp命令生成的临时文件名是随机的，而且权限是只有用户本人可读写。\n在脚本中使用mktemp命令后面最好使用 OR 运算符（||），保证创建失败时退出脚本。为了保证脚本退出时临时文件被删除，可以使用trap命令指定退出时的清除操作。\n#!/bin/bash # 遇到 EXIT 信号就执行清除命令 trap 'rm -f \u0026quot;$TMPFILE\u0026quot;' EXIT TMPFILE=$(mktemp) || exit 1 echo \u0026quot;Our temp file is $TMPFILE\u0026quot;  选项：\n-d参数可以创建一个临时目录。\n$ mktemp -d /tmp/tmp.Wcau5UjmN6  -p参数可以指定临时文件所在的目录。默认是使用$TMPDIR环境变量指定的目录，如果这个变量没设置，那么使用/tmp目录。\n$ mktemp -p /home/qlel/ /home/qlel/tmp.FOKEtvs2H3  -t参数可以指定临时文件的文件名模板，模板的末尾必须至少包含三个连续的X字符，表示随机字符，建议至少使用六个X。默认的文件名模板是tmp.后接十个随机字符。\n$ mktemp -t mytemp.XXXXXXX /tmp/mytemp.yZ1HgZV  -u仅返回一个文件名，并不会真的创建文件，可以用来生成随机数\n$ mktemp -u /tmp/tmp.VjgZMYMzMm $ mktemp -u XXX 9M4  trap 命令 trap命令用来在 Bash 脚本中响应系统信号。\ntrap命令的-l参数，可以列出所有的系统信号：\n$ trap -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX  trap的命令格式:\n$ trap [动作] [信号1] [信号2] ...  “动作”是一个 Bash 命令，“信号”常用的有以下几个:\n HUP：编号1，脚本与所在的终端脱离联系。 INT：编号2，用户按下 Ctrl + C，意图让脚本终止运行。 QUIT：编号3，用户按下 Ctrl + 斜杠，意图退出脚本。 KILL：编号9，该信号用于杀死进程。 TERM：编号15，这是kill命令发出的默认信号。 EXIT：编号0，这不是系统信号，而是 Bash 脚本特有的信号，不管什么情况，只要退出脚本就会产生。  $ trap 'rm -f \u0026quot;$TMPFILE\u0026quot;' EXIT  上面命令中，脚本遇到EXIT信号时，就会执行rm -f \u0026quot;$TMPFILE\u0026quot;。\ntrap 命令的常见使用场景，就是在 Bash 脚本中指定退出时执行的清理命令\n#!/bin/bash trap 'rm -f \u0026quot;$TMPFILE\u0026quot;' EXIT TMPFILE=$(mktemp) || exit 1 ls /etc \u0026gt; $TMPFILE if grep -qi \u0026quot;kernel\u0026quot; $TMPFILE; then echo 'find' fi  上面代码中，不管是脚本正常执行结束，还是用户按 Ctrl + C 终止，都会产生EXIT信号，从而触发删除临时文件。\n 注意，trap命令必须放在脚本的开头。否则，它上方的任何命令导致脚本退出，都不会被它捕获。\n 如果trap需要触发多条命令，可以封装一个 Bash 函数:\nfunction egress { command1 command2 command3 } trap egress EXIT ","date":"2021-04-08","permalink":"/post/linux-shell-bash/","tags":["linux","shell","bash"],"title":"Linux Shell Bash"},{"content":"systemd 是一个专用于 Linux 操作系统的系统与服务管理器。 当作为启动进程(PID=1)运行时， 它将作为初始化系统运行， 也就是启动并维护各种用户空间的服务。\n# 显示帮助信息 systemctl -h # 显示版本 systemctl --version  概念 systemd 架构图: systemd 将各种系统启动和运行相关的对象， 表示为各种不同类型的单元(Unit)， 并提供了处理不同单元之间依赖关系的能力。\n大部分单元都静态的定义在单元文件中， 但是有少部分单元则是动态自动生成的.\nsystemd 有12种不同类型的单元文件:\n   单元类型 单元文件扩展名 说明     service .service 用于封装一个后台服务进程(守护进程)。   socket .socket 监控来自于系统或网络的数据消息   target .target 用于将多个单元在逻辑上组合在一起。   device .device 用于封装一个设备文件，可用于基于设备的启动。   mount .mount 用于封装一个文件系统挂载点(也向后兼容传统的 /etc/fstab 文件)   automount .automount 用于封装一个文件系统自动挂载点。它取代了传统的 autofs 服务。   timer .timer 用于封装一个基于时间触发的动作。它取代了传统的 atd, crond 等任务计划服务。   swap .swap 用于封装一个交换分区或者交换文件。   path .path 用于根据文件系统上特定对象的变化来启动其他服务。   slice .slice 用于控制特定 CGroup 内(例如一组 service 与 scope 单元)所有进程的总体资源占用。   scope .scope 这种 Unit 文件不是用户创建的，而是 Systemd 运行时产生的，描述一些系统服务的分组信息   snapshot .snapshot 用于表示一个由 systemctl snapshot 命令创建的 Systemd Units 运行状态快照，可以切回某个快照    单元有5种不同的状态:\n   单元状态 说明     active 活动   inactive 停止   activating 启动中   deactivating 暂停中   failed 失败   可用systemctl status 某个单元, 查看某个单元的状态. 例如:     # 查看ssh服务单元状态 systemctl status ssh.service  系统管理 systemctl systemctl 是 Systemd 的主命令，用于管理系统。\n中文文档: http://www.jinbuguo.com/systemd/systemctl.html\n# 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # 关闭系统，但不切断电源, CPU停止工作 $ sudo systemctl halt # 暂停系统, 休眠到内存。 $ sudo systemctl suspend # 让系统进入冬眠状态, 休眠到硬盘。 $ sudo systemctl hibernate # 让系统进入混合休眠状态, 同时休眠到内存和硬盘。 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue  systemd-analyze 分析与调试 systemd 系统管理器\n中文文档: http://www.jinbuguo.com/systemd/systemd-analyze.html\n# 查看系统启动耗时 $ systemd-analyze # 按照每个单元花费的启动时间降序列出所有当前正处于活动(active)状态的单元。 $ systemd-analyze blame # 为指定的单元以树状形式显示时间关键链 # 显示的信息: `@时间` 表示时启动的时间点; `+时间` 表示启动完成消耗的时间 $ systemd-analyze critical-chain [UNIT…] # 输出一个svg图像, 包含每个单元的启动时刻和启动完成的消耗时间 $ systemd-analyze plot \u0026gt; abc.svg # 按照 GraphViz dot 格式输出单元间的依赖关系图。 # systemd-analyze dot | dot -Tsvg \u0026gt; systemd.svg $ systemd-analyze dot # 按照人类易读的格式输出全部单元的状态 $ systemd-analyze dump # 列出与单元相关的全部目录 $ systemd-analyze unit-paths # 打印出 systemd 守护进程当前的日志等级 $ systemd-analyze log-level # 打印出 systemd 守护进程当前的日志目标 $ systemd-analyze log-target # 校验指定的单元文件的正确性，并显示发现的错误 $ systemd-analyze verify 单元文件  hostnamectl 用于查看当前主机的信息。\nhttp://www.jinbuguo.com/systemd/hostnamectl.html\n# 显示当前的主机名及其他相关信息 $ hostnamectl $ hostnamectl status # 设置主机名 $ hostnamectl set-hostname NAME  localectl 本地化设置。\nhttp://www.jinbuguo.com/systemd/localectl.html\n# 查看本地化设置 $ localectl $ localectl status # 列出所有可用(已编译)的语言环境 $ localectl list-locales # 本地化设置, 如: localectl set-locale LANG=en_GB.utf8 $ localectl set-locale VARIABLE=LOCALE… # 列出所有可用(已编译)的键盘映射 $ localectl list-keymaps # 设置键盘映射, 设置为 `us` 即可 $ localectl set-keymap MAP  timedatectl 控制系统的时间与日期\nhttp://www.jinbuguo.com/systemd/timedatectl.html\n# 显示系统时钟与RTC的当前状态，包括时区设置以及网络时间同步服务的状态。 $ timedatectl $ timedatectl status $ timedatectl show # 以机器可读形式显示 # 列出所有可用时区, 可用于设置时区 set-timezone $ timedatectl list-timezones # 设置时区 $ timedatectl set-timezone [TIMEZONE] # 将系统时钟设为指定的时间，并同时更新RTC时间 # [TIME] 是一个形如 \u0026quot;2012-10-30 18:17:16\u0026quot; 的时间字符串 $ timedatectl set-time [TIME] # 接受一个布尔值，表示是否开启网络时间同步(若可用) $ timedatectl set-ntp [BOOL]  loginctl 控制 systemd 登录管理器\nhttp://www.jinbuguo.com/systemd/loginctl.html\nsession 会话命令:\n# 列出当前所有的会话 $ loginctl $ loginctl list-sessions # 显示简洁的会话状态信息，后跟最近的日志。 $ loginctl session-status [ID…] # 显示会话的各项属性值, 易于机器阅读形式 $ loginctl show-session [ID…] # 激活会话。也就是将处于后台的会话切换到前台 $ loginctl activate [ID] # 锁定/解锁会话 (如果会话支持屏幕锁) $ loginctl lock-session [ID…] $ loginctl unlock-session [ID…] # 锁定/解锁 所有支持屏幕锁的会话 $ loginctl lock-sessions $ loginctl unlock-sessions # 结束指定的会话。也就是杀死指定会话的所有进程、释放所有与此会话相关的资源。 $ loginctl terminate-session ID…  user 用户命令:\n# 列出当前登录的用户 $ loginctl list-users # 显示简洁的已登录用户状态信息，后跟最近的日志。 $ loginctl user-status [USER…] # 显示用户的各项属性值 $ loginctl show-user [USER…] # 启用/禁止用户逗留(相当于保持登录状态)。 $ loginctl enable-linger [USER…] $ loginctl disable-linger [USER…] # 结束指定用户的会话。这将杀死该用户的所有会话中的所有进程，同时释放与此用户有关的所有资源。 $ loginctl terminate-user USER…  seat 席位命令:\n# 列出当前本机上的所有可用席位 $ loginctl list-seats # 显示简洁的席位信息，后跟最近的日志。 $ loginctl seat-status [NAME…] # 显示席位的各项属性值 $ loginctl seat-user [NAME…] # 将指定的设备(DEVICE) 持久的连接到指定的席位(NAME)上。 # 设备可以用相对于 /sys 文件系统的设备路径表示。 # 要创建一个新席位，至少需要连接一个显卡。 # 席位名称必须以 \u0026quot;seat\u0026quot; 开头， 后跟 a–z, A–Z, 0–9, \u0026quot;-\u0026quot;, \u0026quot;_\u0026quot; 字符 $ loginctl attach NAME DEVICE… # 删除所有先前用 attach 命令连接的设备 # 同时也删除了所有先前用 attach 命令创建的席位 # 调用此命令之后，所有自动生成的席位将会被保留 # 同时所有席位设备将会连接到自动生成的席位上。 $ flush-devices # 结束指定席位的会话。这将杀死指定席位上的所有会话进程，同时释放与之关联的所有资源。 $ loginctl terminate-user NAME…  单元Unit Systemd 可以管理所有系统资源。不同的资源统称为 Unit(单元)\n前面概念说了一共12中单元, 简述为:\n Service unit：系统服务 Target unit：多个 Unit 构成的一个组 Device Unit：硬件设备 Mount Unit：文件系统的挂载点 Automount Unit：自动挂载点 Path Unit：文件或路径 Scope Unit：不是由 Systemd 启动的外部进程 Slice Unit：进程组 Snapshot Unit：Systemd 快照，可以切回某个快照 Socket Unit：进程间通信的 socket Swap Unit：swap 文件 Timer Unit：定时器  list相关 list-units\n列出相关单元信息, 可以使用相关选项过滤: --state, --type, --failed等\n# 格式 $ systemctl list-units [PATTERN…] # 已加载到内存中(正在运行)的单元 Unit $ systemctl list-units # 显示 ssh.service 相关信息 $ systemctl list-units ssh.service # 列出所有Unit $ systemctl list-units --all # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有状态为 inactive 的 Unit $ systemctl list-units --all --state=inactive # 列出所有可用的类型 $ systemctl --type=help # 列出所有可用的状态 $ systemctl --state=help   list-sockets\n列出当前已加载到内存中的套接字(socket)单元，并按照监听地址排序。\n --show-types 显示套接字类型 --all 列出所有套接字(socket)单元 --state= 列出指定状态的套接字(socket)单元  # 格式 $ systemctl list-sockets [PATTERN…] # 列出当前已加载到内存中的套接字(socket)单元，并按照监听地址排序。 $ systemctl list-sockets # 列出已加载到内存中的套接字(socket)单元, 并显示套接字类型 $ systemctl list-sockets --show-types   list-timers\n列出当前已加载到内存中的定时器(timer)单元，并按照下次执行的时间点排序。\n --all 列出所有定时器(timer)单元 --state= 列出指定状态的定时器(timer)单元  显示的信息列:\n NEXT 列 显示下次执行的时间点 LEFT 列 显示距离下次执行还剩多长时间 LAST 列 显示上次执行的时间点 PASSED 列 显示距离上次执行过去了多长时间 UNIT 列 显示定时器单元的名称 ACTIVATES 列 显示定时器单元将会启动的服务  # 格式 $ systemctl list-timers [PATTERN…] # 列出当前已加载到内存中的定时器(timer)单元，并按照下次执行的时间点排序。 $ systemctl list-timers # 列出所有定时器(timer)单元 $ systemctl list-timers --all  status 状态相关\n# 格式 $ systemctl status [PATTERN…|PID…] # 显示系统状态 $ systemctl status # 显示 bluetooth.service 状态 $ systemctl status bluetooth.service  除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。\n# 显示某个 Unit 是否正在运行 $ systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled application.service  Unit管理 # 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的专属配置文件, 例如 httpd.conf; 注意区别单元配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500  依赖关系 systemctl list-dependencies [UNIT]\n显示单元的依赖关系。\n如果没有明确指定单元的名称，那么表示显示 default.target 的依赖关系树。\n默认情况下，仅以递归方式显示 target 单元的依赖关系树，而对于其他类型的单元，仅显示一层依赖关系(不递归)。 但如果使用了 --all 选项， 那么将对所有类型的单元都强制递归的显示完整的依赖关系树。\n还可以使用 --reverse, --after, --before 选项指定 仅显示特定类型的依赖关系。\n注意， 因为此命令仅列出当前已加载的单元(并不包含未加载单元中定义的依赖关系)， 所以，此命令不能全部列出反向依赖于指定单元的完整列表。\n# 显示 default.target 的依赖关系树 $ systemctl list-dependencies # 显示 ssh.service 的依赖关系树 $ systemctl list-dependencies ssh.service # 递归显示 ssh.service 的依赖关系树 $ systemctl list-dependencies ssh.service --all  单元配置文件 每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。\nsystemd 将会从一组在编译时设定好的\u0026quot;单元目录\u0026quot;中加载单元文件(详见下面的两个表格)， 并且较先列出的目录拥有较高的优先级(细节见后文)。 也就是说，高优先级目录中的文件， 将会覆盖低优先级目录中的同名文件。\n如果设置了 $SYSTEMD_UNIT_PATH 环境变量， 那么它将会取代预设的单元目录。 如果 $SYSTEMD_UNIT_PATH 以 \u0026ldquo;:\u0026rdquo; 结尾， 那么预设的单元目录将会被添加到该变量值的末尾。\n当 systemd 以系统实例(\u0026ndash;system)运行时，加载单元的先后顺序(较前的目录优先级较高)：\n   系统单元目录 描述     /etc/systemd/system.control 通过 dbus API 创建的永久系统单元   /run/systemd/system.control 通过 dbus API 创建的临时系统单元   /run/systemd/transient 动态配置的临时单元(系统与全局用户共用)   /run/systemd/generator.early 生成的高优先级单元(系统与全局用户共用)   /etc/systemd/system 由管理员创建的系统单元   /run/systemd/system 运行时配置的系统单元   /run/systemd/generator 生成的中优先级系统单元   /usr/local/lib/systemd/system 管理员安装的系统单元   /usr/lib/systemd/system 发行版软件包安装的系统单元   /run/systemd/generator.late 生成的低优先级系统单元    当 systemd 以用户实例(\u0026ndash;user)运行时，加载单元的先后顺序(较前的目录优先级较高)：\n   用户单元目录 描述     $XDG_CONFIG_HOME/systemd/user.control 或 ~/.config/systemd/user.control 通过 dbus API 创建的永久私有用户单元(仅在未设置 $XDG_CONFIG_HOME 时才使用 ~/.config 来替代)   $XDG_RUNTIME_DIR/systemd/user.control 通过 dbus API 创建的临时私有用户单元   /run/systemd/transient 动态配置的临时单元(系统与全局用户共用)   /run/systemd/generator.early 生成的高优先级单元(系统与全局用户共用)   $XDG_CONFIG_HOME/systemd/user 或 $HOME/.config/systemd/user 用户配置的私有用户单元(仅在未设置 $XDG_CONFIG_HOME 时才使用 ~/.config 来替代)   $XDG_CONFIG_DIRS/systemd/user 或 /etc/xdg/systemd/user XDG基本目录规范指定的其他配置目录（如果设置，则使用$XDG_CONFIG_DIRS，否则使用/etc/xdg）   /etc/systemd/user 管理员创建的用户单位   $XDG_RUNTIME_DIR/systemd/user 运行时配置的私有用户单元(仅当 $XDG_RUNTIME_DIR 已被设置时有效)   /run/systemd/user 运行时配置的全局用户单元   $XDG_RUNTIME_DIR/systemd/generator 生成的中优先级私有用户单元   $XDG_DATA_HOME/systemd/user 或 $HOME/.local/share/systemd/user 软件包安装在用户家目录中的私有用户单元(仅在未设置 $XDG_DATA_HOME 时才使用 ~/.local/share 来替代)   $XDG_DATA_DIRS/systemd/user 或 /usr/local/share/systemd/user 和 /usr/share/systemd/user 由XDG基本目录规范指定的其他数据目录   $dir/systemd/user(对应 $XDG_DATA_DIRS 中的每一个目录($dir)) 额外安装的全局用户单元，对应 $XDG_DATA_DIRS(默认值=\u0026quot;/usr/local/share/:/usr/share/\u0026quot;) 中的每一个目录   /usr/local/lib/systemd/user 管理员安装的全局用户单元   /usr/lib/systemd/user 发行版软件包安装的全局用户单元   $XDG_RUNTIME_DIR/systemd/generator.late 生成的低优先级私有用户单元    可用$ systemd-analyze unit-paths查看相关单元文件路径:\n$ systemd-analyze unit-paths /etc/systemd/system.control /run/systemd/system.control /run/systemd/transient /run/systemd/generator.early /etc/systemd/system /etc/systemd/system.attached /run/systemd/system /run/systemd/system.attached /run/systemd/generator /usr/local/lib/systemd/system /lib/systemd/system /usr/lib/systemd/system /run/systemd/generator.late  Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在此目录。\n$ ls -l /etc/systemd/system total 28 drwxr-xr-x 2 root root 4096 Mar 3 21:06 bluetooth.target.wants lrwxrwxrwx 1 root root 42 Mar 3 21:08 dbus-fi.w1.wpa_supplicant1.service -\u0026gt; /lib/systemd/system/wpa_supplicant.service lrwxrwxrwx 1 root root 37 Mar 3 21:06 dbus-org.bluez.service -\u0026gt; /lib/systemd/system/bluetooth.service lrwxrwxrwx 1 root root 45 Mar 3 20:43 dbus-org.freedesktop.timesync1.service -\u0026gt; /lib/systemd/system/systemd-timesyncd.service drwxr-xr-x 2 root root 4096 Mar 3 20:43 getty.target.wants drwxr-xr-x 2 root root 4096 Mar 3 21:08 multi-user.target.wants drwxr-xr-x 2 root root 4096 Mar 3 20:43 network-online.target.wants drwxr-xr-x 2 root root 4096 Mar 3 20:45 sockets.target.wants lrwxrwxrwx 1 root root 31 Mar 3 21:08 sshd.service -\u0026gt; /lib/systemd/system/ssh.service drwxr-xr-x 2 root root 4096 Mar 3 20:46 sysinit.target.wants lrwxrwxrwx 1 root root 35 Mar 3 20:43 syslog.service -\u0026gt; /lib/systemd/system/rsyslog.service drwxr-xr-x 2 root root 4096 Mar 3 21:08 timers.target.wants  systemctl enable UNIT…|PATH…命令用于启用指定的单元, 在上面两个目录之间，建立符号链接关系。\n$ sudo systemctl enable clamd@scan.service # 等同于 $ sudo ln -s '/usr/lib/systemd/system/clamd@scan.service' '/etc/systemd/system/multi-user.target.wants/clamd@scan.service'  如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。\n与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。\n$ sudo systemctl disable clamd@scan.service  配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service。\n状态 systemctl list-unit-files [PATTERN…]\n列出所有已安装的单元配置文件及其状态.\n# 列出所有已安装的单元配置文件及其状态. $ systemctl list-unit-files # 列出指定类型的单元配置文件及其状态. $ systemctl list-unit-files --type=service  显示每个单元配置文件的状态，一共有四种。\n enabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接   注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的systemctl status命令。\n 修改单元配置文件后, 需要重新加载:\n# 注意区别 reload , reload 只是重载服务进程的专属配置, 例如 httpd.conf $ sudo systemctl daemon-reload  格式 单元配置文件就是普通的文本文件，类似于.ini风格的文件, 可以用文本编辑器打开。\n语法可查看: http://www.jinbuguo.com/systemd/systemd.syntax.html\nsystemctl cat NAME命令可以查看单元配置文件的内容。\n$ systemctl cat ssh.service # /lib/systemd/system/ssh.service [Unit] Description=OpenBSD Secure Shell server Documentation=man:sshd(8) man:sshd_config(5) After=network.target auditd.service ConditionPathExists=!/etc/ssh/sshd_not_to_be_run [Service] EnvironmentFile=-/etc/default/ssh ExecStartPre=/usr/sbin/sshd -t ExecStart=/usr/sbin/sshd -D $SSHD_OPTS ExecReload=/usr/sbin/sshd -t ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartPreventExitStatus=255 Type=notify RuntimeDirectory=sshd RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target Alias=sshd.service  从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区块名，比如[Unit]。\n 注意，配置文件的区块名和字段名，都是大小写敏感的。\n 每个区块内部是一些等号连接的键值对。\n 注意，键值对的等号两侧不能有空格。\n 空行、以 \u0026ldquo;#\u0026rdquo; 或 \u0026ldquo;;\u0026rdquo; 开头的行(用作注释) 都将被忽略。\n行尾的反斜线(\\)是续行符，表示将下一行拼接到本行末尾，同时将反斜线本身替换为一个空格。 这样可以将一个超长的行分拆为几个较短的行。\n配置文件中的布尔值可以有多种写法。 真值可以写为： 1, yes, true, on 之一，假值可以写为： 0, no, false, off 之一。\n配置文件中的时间长度可以有多种写法：不带任何后缀的一个纯数值表示秒数； 亦可在纯数值后面加上时间单位； 亦可以将多个带有时间单位后缀的时间长度使用空格连接起来，表示这几段时间长度之和。 例如： \u0026ldquo;50\u0026rdquo; 表示50秒； \u0026ldquo;2min 200ms\u0026rdquo; 表示2分200毫秒，也就是120200毫秒； 可使用的时间单位如下： \u0026ldquo;s\u0026rdquo;, \u0026ldquo;min\u0026rdquo;, \u0026ldquo;h\u0026rdquo;, \u0026ldquo;d\u0026rdquo;, \u0026ldquo;w\u0026rdquo;, \u0026ldquo;ms\u0026rdquo;, \u0026ldquo;us\u0026rdquo; 。\n[Unit] http://www.jinbuguo.com/systemd/systemd.unit.html\n[Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。常用指令:\n Description 有利于人类阅读的、对单元进行简单描述的字符串。 Documentation 文档地址. 可接受 \u0026ldquo;http://\u0026rdquo;, \u0026ldquo;https://\u0026rdquo;, \u0026ldquo;file:\u0026rdquo;, \u0026ldquo;info:\u0026rdquo;, \u0026ldquo;man:\u0026rdquo; 五种URI类型 Requires 当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败 Wants 此选项是 Requires 的弱化版。 当此单元被启动时， 所有这里列出的其他单元只是尽可能被启动。 但是，即使某些单元不存在或者未能启动成功， 也不会影响此单元的启动。 推荐使用此选项来设置单元之间的依赖关系。 BindsTo 与 Requires 类似，但是依赖性更强： 如果这里列出的任意一个单元停止运行或者崩溃，那么也会连带导致该单元自身被停止。 这就意味着该单元可能因为 这里列出的任意一个单元的 主动退出、某个设备被拔出、某个挂载点被卸载， 而被强行停止。 PartOf 与 Requires 类似， 不同之处在于：仅作用于单元的停止或重启。 其含义是，当停止或重启这里列出的某个单元时， 也会同时停止或重启该单元自身。 注意，这个依赖是单向的， 该单元自身的停止或重启并不影响这里列出的单元。 Conflicts 指定单元之间的冲突关系。 接受一个空格分隔的单元列表，表明该单元不能与列表中的任何单元共存， 也就是说：(1)当此单元启动的时候，列表中的所有单元都将被停止； (2)当列表中的某个单元启动的时候，该单元同样也将被停止。 注意，此选项与 After= 和 Before= 选项没有任何关系。 Before 假定 foo.service 单元包含 Before=bar.service 设置， 那么当两个单元都需要启动的时候， bar.service 将会一直延迟到 foo.service 启动完毕之后再启动。 注意，停止顺序与启动顺序正好相反，也就是说， 只有当 bar.service 完全停止后，才会停止 foo.service 单元。 After 假定 foo.service 单元包含 After=bar.service 设置， 那么当两个单元都需要启动的时候， foo.service 将会一直延迟到 bar.service 启动完毕之后再启动。 注意，停止顺序与启动顺序正好相反，也就是说， 只有当 foo.service 完全停止后，才会停止 bar.service 单元。 OnFailure 当该单元进入失败(\u0026ldquo;failed\u0026rdquo;)状态时， 将会启动列表中的单元。 Condition... 当前 Unit 运行必须满足的条件，否则不会运行 Assert... 当前 Unit 运行必须满足的条件，否则会报启动失败  [Install] http://www.jinbuguo.com/systemd/systemd.unit.html\n用来定义如何启动，以及是否开机启动。它的主要字段如下:\n Alias 启用时使用的别名，可以设为一个空格分隔的别名列表。 每个别名的后缀(也就是单元类型)都必须与该单元自身的后缀相同。 Also 设置此单元的附属单元， 可以设为一个空格分隔的单元列表。 表示当使用 systemctl enable 启用 或 systemctl disable 停用 此单元时， 也同时自动的启用或停用附属单元。 WantedBy RequiredBy 接受一个空格分隔的单元列表， 表示在使用 systemctl enable 启用此单元时， 将会在/etc/systemd/system目录中每个列表单元的 .wants/ 或 .requires/ 目录中创建一个指向该单元文件的软连接。 这相当于为每个列表中的单元文件添加了 Wants=此单元 或 Requires=此单元 选项。 这样当列表中的任意一个单元启动时，该单元都会被启动。  例如, 上面的ssh.service单元配置文件在/etc/systemd/system目录创建的软链接:\n$ ls -l /etc/systemd/system/multi-user.target.wants/ total 0 lrwxrwxrwx 1 root root 35 Mar 3 21:06 anacron.service -\u0026gt; /lib/systemd/system/anacron.service lrwxrwxrwx 1 root root 41 Mar 3 20:46 console-setup.service -\u0026gt; /lib/systemd/system/console-setup.service lrwxrwxrwx 1 root root 32 Mar 3 20:43 cron.service -\u0026gt; /lib/systemd/system/cron.service lrwxrwxrwx 1 root root 38 Mar 3 20:43 networking.service -\u0026gt; /lib/systemd/system/networking.service lrwxrwxrwx 1 root root 36 Mar 3 20:43 remote-fs.target -\u0026gt; /lib/systemd/system/remote-fs.target lrwxrwxrwx 1 root root 35 Mar 3 20:43 rsyslog.service -\u0026gt; /lib/systemd/system/rsyslog.service lrwxrwxrwx 1 root root 31 Mar 3 21:08 ssh.service -\u0026gt; /lib/systemd/system/ssh.service lrwxrwxrwx 1 root root 42 Mar 3 21:08 wpa_supplicant.service -\u0026gt; /lib/systemd/system/wpa_supplicant.service  [Service] http://www.jinbuguo.com/systemd/systemd.unit.html\n用于 Service 的配置，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下:\n Type：定义启动时的进程行为。它有以下几种值。  Type=simple：默认值，执行ExecStart指定的命令，启动主进程 Type=forking：以 fork 方式从父进程创建子进程，创建后父进程会立即退出 Type=oneshot：一次性进程，Systemd 会等当前服务退出，再继续往下执行 Type=dbus：当前服务通过D-Bus启动 Type=notify：当前服务启动完毕，会通知Systemd，再继续往下执行 Type=idle：若有其他任务执行完毕，当前服务才会运行   ExecStart：启动当前服务的命令 ExecStartPre：启动当前服务之前执行的命令 ExecStartPost：启动当前服务之后执行的命令 ExecReload：重启当前服务时执行的命令 ExecStop：停止当前服务时执行的命令 ExecStopPost：停止当其服务之后执行的命令 RestartSec：自动重启当前服务间隔的秒数 Restart：定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数 Environment：指定环境变量  Target 启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便。Systemd 的解决方案就是 Target。\n简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\u0026quot;状态点\u0026quot;，启动某个 Target 就好比启动到某种状态。\n传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。\n# 查看运行中的 target $ systemctl list-units --type=target # 查看所有的 target $ systemctl list-units --type=target --all # 列出已安装的target单元配置文件及其状态. $ systemctl list-unit-files --type=target # 查看某个 Target 包含的依赖 $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target  Target 与 传统 RunLevel 的对应关系如下:\nTraditional runlevel New target name Symbolically linked to... Runlevel 0 | runlevel0.target -\u0026gt; poweroff.target Runlevel 1 | runlevel1.target -\u0026gt; rescue.target Runlevel 2 | runlevel2.target -\u0026gt; multi-user.target Runlevel 3 | runlevel3.target -\u0026gt; multi-user.target Runlevel 4 | runlevel4.target -\u0026gt; multi-user.target Runlevel 5 | runlevel5.target -\u0026gt; graphical.target Runlevel 6 | runlevel6.target -\u0026gt; reboot.target  它与init进程的主要差别如下: （1）默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n（2）启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。\n（3）配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。\n日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\n# 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 实时滚动显示最新日志 $ sudo journalctl -f # 显示尾部的最新10行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 反转日志行的输出顺序，也就是显示最新的日志 $ sudo journalctl -r # 以人类易于阅读的json格式输出 $ sudo journalctl -o json-pretty # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定单元的日志 # 如: sudo journalctl -u ssh.service $ sudo journalctl -u UNIT|PATTERN # 查看属于特定用户会话单元的日志 $ sudo journalctl --user-unit=qlel # 根据日志等级过滤输出, 仅显示小于或等于此等级的日志 # 等级对应关系: \u0026quot;emerg\u0026quot; (0), \u0026quot;alert\u0026quot; (1), \u0026quot;crit\u0026quot; (2), \u0026quot;err\u0026quot; (3), # \u0026quot;warning\u0026quot; (4), \u0026quot;notice\u0026quot; (5), \u0026quot;info\u0026quot; (6), \u0026quot;debug\u0026quot; (7) $ sudo journalctl -p 6 # -S, --since= 显示晚于指定时间的日志 # -U, --until= 显示早于指定时间的日志 # 参数的格式类似 \u0026quot;2012-10-30 18:17:16\u0026quot;, # 具体看http://www.jinbuguo.com/systemd/systemd.time.html $ sudo journalctl -S '2021-03-07 12:00:00' $ sudo journalctl -S '2021-03-07 12:00:00' -U '2021-03-07 13:00:00' $ sudo journalctl -S '2 min ago' $ sudo journalctl -S yesterday # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /usr/bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 显示所有日志磁盘占用总量 $ sudo journalctl --disk-usage # 限制日志归档文件的最大磁盘使用量(可以使用 \u0026quot;K\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;G\u0026quot;, \u0026quot;T\u0026quot; 后缀) $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 # 可以使用 \u0026quot;s\u0026quot;, \u0026quot;m\u0026quot;, \u0026quot;h\u0026quot;, \u0026quot;days\u0026quot;, \u0026quot;weeks\u0026quot;, \u0026quot;months\u0026quot;, \u0026quot;years\u0026quot; 后缀 $ sudo journalctl --vacuum-time=1years # 限制日志归档文件的最大数量 $ sudo journalctl --vacuum-files=  Timer 中文文档: http://www.jinbuguo.com/systemd/systemd.timer.html\n以 \u0026ldquo;.timer\u0026rdquo; 为后缀的单元文件， 封装了一个由 systemd 管理的定时器， 以支持基于定时器的启动。\n每个定时器单元都必须有一个与其匹配的单元，用于在特定的时间启动。可以在单元配置文件中[Timer]小结通过指令 Unit= 明确指定要匹配的单元。若未指定，则默认是与该单元名称相同的 .service 单元(不算后缀)。例如 foo.timer 默认匹配 foo.service 单元。\n 注意，如果在启动时间点到来的时候，匹配的单元已经被启动， 那么将不执行任何动作，也不会启动任何新的服务实例。 因此，那些设置了 RemainAfterExit=yes(当该服务的所有进程全部退出之后，依然将此服务视为处于活动状态) 的服务单元一般不适合使用基于定时器的启动。 因为这样的单元仅会被启动一次，然后就永远处于活动(active)状态了。\n 此单元文件配置文件中有专门的[Timer]小结, 下面有一些配置指令:\n OnActiveSec 定时器生效后，多少时间开始执行任务 OnBootSec 系统启动后，多少时间开始执行任务 OnStartupSec Systemd 进程启动后，多少时间开始执行任务 OnUnitActiveSec 该单元上次执行后，等多少时间再次执行 OnUnitInactiveSec 定时器上次关闭后多少时间，再次执行 OnCalendar 基于绝对时间，而不是相对时间执行. 如果定时器单元在启动时已经超过了该指令设置的某个触发时间，那么错过就错过了，不会尝试去补救，只能等待下一个触发时间。受到 AccuracySec 选项的影响 AccuracySec 设置定时器的触发精度。如果因为各种原因，任务必须推迟执行，推迟的最大秒数，默认是60秒 RandomizedDelaySec 将此单元的定时器随机延迟一小段时间， 这一小段时间的长度 介于零到该指令设置的时间长度之间， 以均匀概率分布。 默认值是零，表示不延迟。 Unit 真正要执行的任务单元，默认是同名的带有.service后缀的单元 Persistent 此选项仅对 OnCalendar 指令定义的日历定时器有意义。 若设为\u0026quot;true\u0026quot;，则表示将匹配单元的上次触发时间永久保存在磁盘上。 这样，当定时器单元再次被启动时， 如果匹配单元本应该在定时器单元停止期间至少被启动一次， 那么将立即启动匹配单元。 这样就不会因为关机而错过必须执行的任务。 默认值为 false 在计时器单元上使用systemctl clean --what = state…从磁盘上删除此选项维护的时间戳文件。 特别是，在卸载计时器单元之前，请使用此命令。 WakeSystem 若设为\u0026quot;true\u0026quot;， 则表示当某个定时器到达触发时间点时， 唤醒正在休眠的系统并阻止系统进入休眠状态。 注意， 此选项仅确保唤醒系统， 而不关心任务执行完成之后是否需要再次休眠系统。 默认值为 false  时间格式 http://www.jinbuguo.com/systemd/systemd.time.html\n   语法 说明     usec, us, µs 微秒   msec, ms 毫秒   seconds, second, sec, s 秒   minutes, minute, min, m 分钟   hours, hour, hr, h 小时   days, day, d 天   weeks, week, w 星期   months, month, M 月[=30.44天]   years, year, y 年[=365.25天]    下面是一些有效的时长字符串实例：\n2 h 2hours 48hr 1y 12month 55s500ms 300ms20s 5day   OnUnitActiveSec=1h 表示一小时执行一次任务 OnCalendar=*-*-* 02:00:00 表示每天凌晨两点执行. 这是日历事件表达式, 类似于专用于时间戳的正则表达式 OnCalendar=Mon *-*-* 02:00:00  Service和Timer示例 自定义一个定时任务——每过30s就向msg.txt输入当前时间.\n 创建一个shell脚本: abcd.sh  $ nano abcd.sh # 查看 abcd.sh 内容 $ cat abcd.sh #!/bin/bash date \u0026gt;\u0026gt; /home/qlel/msg.txt echo 'hello abcddddddddd' # 赋予执行权限 $ chmod +x ./abcd.sh # 执行2次看看 $ ./abcd.sh # 查看是否执行成功 $ cat msg.txt Mon 08 Mar 2021 05:59:18 PM CST Mon 08 Mar 2021 05:59:23 PM CST  再创建一个python文件脚本: py_test.py:\nimport time now_time = time.strftime('%Y-%m-%d %H:%M:%S') + '\\n' with open('/home/qlel/py_msg.txt','a') as f: f.write(now_time)  执行2次看看:\n$ python3 /home/qlel/py_test.py $ python3 /home/qlel/py_test.py $ cat /home/qlel/py_msg.txt 2021-03-08 18:00:06 2021-03-08 18:00:10  创建要执行的 Service 单元  使用命令sudo systemctl edit --force --full mytimer.service会自动创建/etc/systemd/system/mytimer.service.\n --force 如果指定的单元文件不存在，那么将会强制打开一个新的空单元文件以供编辑。 --full 表示使用新编辑的单元文件完全取代原始单元文件，否则默认将新编辑的单元配置片段附加到原始单元文件的末尾  写入以下内容:\n[Unit] Description=mytimer service [Service] ExecStart=/home/qlel/abcd.sh ExecStartPost=python3 /home/qlel/py_test.py   注意, 单元文件中都要使用绝对路径, 还有使用到的脚本文件中的内容也要使用绝对路径\n 启动mytimer.service单元:  $ sudo systemctl start mytimer.service qlel@debianqlel:~$ systemctl status mytimer.service ● mytimer.service - mytimer service Loaded: loaded (/etc/systemd/system/mytimer.service; static; vendor preset: enabled) Active: inactive (dead)  查看结果和日志  ~$ cat ./msg.txt Mon 08 Mar 2021 05:59:18 PM CST Mon 08 Mar 2021 05:59:23 PM CST Mon 08 Mar 2021 06:05:49 PM CST ~$ cat ./py_msg.txt 2021-03-08 18:00:06 2021-03-08 18:00:10 2021-03-08 18:05:49 ~$ sudo journalctl -u mytimer.service -n 6 -- Logs begin at Sun 2021-03-07 17:17:01 CST, end at Mon 2021-03-08 18:08:32 CST. -- Mar 08 17:53:47 debianqlel systemd[1]: mytimer.service: Succeeded. Mar 08 17:53:47 debianqlel systemd[1]: Started mytimer service. Mar 08 18:05:49 debianqlel systemd[1]: Starting mytimer service... Mar 08 18:05:49 debianqlel abcd.sh[3927]: hello abcddddddddd Mar 08 18:05:49 debianqlel systemd[1]: mytimer.service: Succeeded. Mar 08 18:05:49 debianqlel systemd[1]: Started mytimer service.  创建 Timer 单元  使用sudo systemctl edit --force --full myytimer.timer会自动创建/etc/systemd/system/myytimer.timer\n写入以下内容:\n# /etc/systemd/system/myytimer.timer [Unit] Description=每10s运行mytimer.service单元 [Timer] OnActiveSec=1s AccuracySec=1us OnUnitActiveSec=10s Unit=mytimer.service [Install] WantedBy=multi-user.target  以上配置说明:\n OnActiveSec=1s表示定时器生效后1s执行一次mytimer.service(只在定时器生效后执行一次) AccuracySec=1us表示精度为1微秒, 默认是60秒 OnUnitActiveSec=10s表示该单元上次执行后10s执行一次(可用于循环执行)   注意, 只有OnUnitActiveSec=10s是不会执行的\n  [Install]表示当使用sudo systemctl enable...设置开机自启动 WantedBy=multi-user.target 详情请看[Install]章节  启动定时器  # 启动定时器 ~$ sudo systemctl start myytimer.timer # 查看状态 ~$ systemctl status myytimer.timer ● myytimer.timer - 每10s运行mytimer.service单元 Loaded: loaded (/etc/systemd/system/myytimer.timer; disabled; vendor preset: enabled) Active: active (waiting) since Mon 2021-03-08 21:13:48 CST; 6s ago Trigger: Mon 2021-03-08 21:13:59 CST; 4s left # 查看结果 ~$ cat py_msg.txt 2021-03-08 21:13:49 2021-03-08 21:13:59 2021-03-08 21:14:09 2021-03-08 21:14:19 2021-03-08 21:14:29 ~$ systemctl list-timers NEXT LEFT LAST PASSED UNIT ACTIVATE Mon 2021-03-08 21:15:19 CST 3s left Mon 2021-03-08 21:15:09 CST 6s ago myytimer.timer mytimer. Mon 2021-03-08 21:33:47 CST 18min left Mon 2021-03-08 20:34:21 CST 40min ago anacron.timer anacron. Tue 2021-03-09 00:00:00 CST 2h 44min left Mon 2021-03-08 00:00:38 CST 21h ago logrotate.timer logrotat Tue 2021-03-09 00:00:00 CST 2h 44min left Mon 2021-03-08 00:00:38 CST 21h ago man-db.timer man-db.s Tue 2021-03-09 06:26:32 CST 9h left Mon 2021-03-08 19:55:38 CST 1h 19min ago apt-daily.timer apt-dail Tue 2021-03-09 06:51:08 CST 9h left Mon 2021-03-08 06:08:38 CST 15h ago apt-daily-upgrade.timer apt-dail Tue 2021-03-09 13:13:38 CST 15h left Mon 2021-03-08 13:13:38 CST 8h ago systemd-tmpfiles-clean.timer systemd- 7 timers listed. Pass --all to see loaded but inactive timers, too. # 停止定时器 myytimer.timer ~$ sudo systemctl stop myytimer.timer # 状态 ~$ systemctl status myytimer.timer ● myytimer.timer - 每10s运行mytimer.service单元 Loaded: loaded (/etc/systemd/system/myytimer.timer; disabled; vendor preset: enabled) Active: inactive (dead) Trigger: n/a  如果需要设置开机自启动:\n# 设置开机自启动 ~$ sudo systemctl enable myytimer.timer [sudo] password for qlel: Created symlink /etc/systemd/system/multi-user.target.wants/myytimer.timer → /etc/systemd/system/myytimer.timer. # 取消开机自启动 ~$ sudo systemctl disable myytimer.timer Removed /etc/systemd/system/multi-user.target.wants/myytimer.timer.  如果要删除myytimer.timer定时器, 直接删除myytimer.timer单元文件即可.\n自启动测试 设置某个脚本开机自启测试。 test_sys_startup.sh脚本：\n#!/usr/bin/env bash date \u0026quot;+%Y-%m-%d %H:%M:%S\u0026quot; \u0026gt;\u0026gt; /home/qlel/my_test_sys.txt echo \u0026quot;启动测试\u0026quot; \u0026gt;\u0026gt; /home/qlel/my_test_sys.txt  切换到root用户，编写service单元文件：\n$ systemctl edit --force --full test01.service  test02.service文件：\n[Unit] Description=自启动测试 After=network.target [Service] Type=forking ExecStart=bash /home/qlel/test_sys_startup.sh User=qlel Group=qlel [Install] WantedBy=multi-user.target  如果修改了文件要重新加载：\n$ systemctl daemon-reload  启动测试是否成功：\n$ systemctl start test02.service $ systemctl status test02.service ● test02.service - 自启动测试 Loaded: loaded (/etc/systemd/system/test02.service; disabled; vendor preset: enabled) Active: inactive (dead) Jun 17 10:32:36 debianqlel systemd[1]: Starting 自启动测试... Jun 17 10:32:36 debianqlel systemd[1]: test02.service: Succeeded. Jun 17 10:32:36 debianqlel systemd[1]: Started 自启动测试  用户设置开机自启动该脚本：\n$ systemctl enable test02.service Created symlink /etc/systemd/system/multi-user.target.wants/test02.service → /etc/systemd/system/test02.service.  查看：\n$ systemctl list-unit-files --user test01* UNIT FILE STATE test01.service enabled 1 unit files listed.  重启系统测试。\n","date":"2021-04-08","permalink":"/post/linux-systemd/","tags":["linux","shell"],"title":"Linux Systemd"},{"content":"ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。\n帮助信息 如果不使用任何选项，ss将显示已建立连接的打开的非监听套接字（例如TCP/UNIX/UDP）的列表。\n -h, --help 显示帮助信息. -V, --version 显示版本信息. -H, --no-header 不显示标题头 -n, --numeric 不要尝试解析服务名称 -r, --resolve 尝试解析数字地址/端口 -a, --all 显示侦听和非侦听（对于TCP，这意味着已建立的连接）套接字。 -l, --listening 仅显示侦听套接字（默认情况下将省略这些套接字）。 -o, --options 显示计时器信息 -e, --extended 显示详细的套接字信息 -m, --memory 显示套接字内存使用情况 -p, --processes 显示使用套接字的进程 -i, --info 显示内部TCP信息 -K, --kill 尝试强行关闭套接字。 此选项显示已成功关闭的套接字，并以静默方式跳过内核不支持关闭的套接字。 它仅支持IPv4和IPv6套接字。 -s, --summary 打印摘要统计信息。此选项不解析从各种源获取摘要的套接字列表。当套接字的数量太大以至于解析/proc/net/tcp非常痛苦时，它非常有用。 -Z, --context 显示进程安全上下文 -z, --contexts 显示套接字上下文 -N NSNAME, --net=NSNAME 切换到指定的网络命名空间名称 -b, --bpf 显示套接字BPF筛选器（仅允许管理员获取这些信息） -4, --ipv4 只显示ipv4的套接字, - -f inet的别名 -6, --ipv6 只显示ipv6的套接字, - -f inet6的别名 -0, --packet 只显示PACKET的套接字, - -f link的别名 -t, --tcp 只显示TCP套接字 -u, --udp 只显示UDP套接字 -d, --dccp 只显示DCCP套接字 -w, --raw 只显示RAW套接字 -x, --unix 显示Unix域套接字, - -f unix的别名 -S, --sctp 只显示SCTP套接字 -f FAMILY, --family=FAMILY 显示指定FAMILY类型的套接字, 支持unix, inet, inet6, link, netlink -A QUERY, --query=QUERY, --socket=QUERY 要转储的套接字表的列表，用逗号分隔。支持all, inet, tcp, udp, raw, unix, packet, netlink, unix_dgram, unix_stream, unix_seqpacket, packet_raw, packet_dgram -D FILE, --diag=FILE 不显示任何内容，仅在应用过滤器后将有关TCP套接字的原始信息转储到FILE中。 如果FILE是- -使用stdout。 -F FILE, --filter=FILE 从FILE读取过滤器信息。 FILE的每一行都被解释为单个命令行选项。 如果FILE是- -使用stdin。  示例 # 显示所有TCP套接字 $ ss -t -a # 显示所有UDP套接字 $ ss -u -a # 查看已侦听原始地址端口的套接字, 可用于查看端口 $ ss -ln ","date":"2021-04-08","permalink":"/post/linux-iproute2-ss/","tags":["linux","shell","iproute2"],"title":"Linux Iproute2 Ss"},{"content":"iproute2是Linux网络工具包，它代替了net-tools（ifconfig，vconfig，route，arp等）。ip是iproute2中的一个命令之一。\nip选项 $ ip -h Usage: ip [ OPTIONS ] OBJECT { COMMAND | help } ip [ -force ] -batch filename where OBJECT := { link | address | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm | netns | l2tp | fou | macsec | tcp_metrics | token | netconf | ila | vrf | sr } OPTIONS := { -V[ersion] | -s[tatistics] | -d[etails] | -r[esolve] | -h[uman-readable] | -iec | -j[son] | -p[retty] | -f[amily] { inet | inet6 | ipx | dnet | mpls | bridge | link } | -4 | -6 | -I | -D | -M | -B | -0 | -l[oops] { maximum-addr-flush-attempts } | -br[ief] | -o[neline] | -t[imestamp] | -ts[hort] | -b[atch] [filename] | -rc[vbuf] [size] | -n[etns] name | -a[ll] | -c[olor]}  提供以下输出选项:\n -o,--oneline 用反斜杠替换每个换行符。 -br,--brief 产生简洁的，面向机器的输出。 非常适合用awk/cut进行解剖 -j,--json json输出, 可配合--pretty|-p和--brief选项  # 默认输出 $ ip addr show lo 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever # 用反斜杠替换每个换行符 $ ip -o addr show lo 1: lo inet 127.0.0.1/8 scope host lo\\ valid_lft forever preferred_lft forever 1: lo inet6 ::1/128 scope host \\ valid_lft forever preferred_lft forever # 产生简洁的，面向机器的输出 $ ip -br addr show lo lo UNKNOWN 127.0.0.1/8 ::1/128 # json输出 $ ip -j -p addr show lo [ { \u0026quot;ifindex\u0026quot;: 1, \u0026quot;ifname\u0026quot;: \u0026quot;lo\u0026quot;, \u0026quot;flags\u0026quot;: [ \u0026quot;LOOPBACK\u0026quot;,\u0026quot;UP\u0026quot;,\u0026quot;LOWER_UP\u0026quot; ], \u0026quot;mtu\u0026quot;: 65536, \u0026quot;qdisc\u0026quot;: \u0026quot;noqueue\u0026quot;, \u0026quot;operstate\u0026quot;: \u0026quot;UNKNOWN\u0026quot;, \u0026quot;group\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;txqlen\u0026quot;: 1000, \u0026quot;link_type\u0026quot;: \u0026quot;loopback\u0026quot;, \u0026quot;address\u0026quot;: \u0026quot;00:00:00:00:00:00\u0026quot;, \u0026quot;broadcast\u0026quot;: \u0026quot;00:00:00:00:00:00\u0026quot;, \u0026quot;addr_info\u0026quot;: [ { \u0026quot;family\u0026quot;: \u0026quot;inet\u0026quot;, \u0026quot;local\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;prefixlen\u0026quot;: 8, \u0026quot;scope\u0026quot;: \u0026quot;host\u0026quot;, \u0026quot;label\u0026quot;: \u0026quot;lo\u0026quot;, \u0026quot;valid_life_time\u0026quot;: 4294967295, \u0026quot;preferred_life_time\u0026quot;: 4294967295 },{ \u0026quot;family\u0026quot;: \u0026quot;inet6\u0026quot;, \u0026quot;local\u0026quot;: \u0026quot;::1\u0026quot;, \u0026quot;prefixlen\u0026quot;: 128, \u0026quot;scope\u0026quot;: \u0026quot;host\u0026quot;, \u0026quot;valid_life_time\u0026quot;: 4294967295, \u0026quot;preferred_life_time\u0026quot;: 4294967295 } ] },{} ]  其它选项:\n -V, -Version 显示版本信息 -h, -human, -human-readable 输出带有人类可读值和后缀的统计信息 -b, -batch \u0026lt;FILENAME\u0026gt; 从提供的文件或标准输入中读取命令并调用它们。第一次失败将导致ip命令终止。 -force 不以批处理方式终止执行ip命令时的错误. 如果执行命令期间出现错误将返回非0. -s, -stats, -statistics 输出更多信息。如果该选项出现两次或更多次，则信息量会增加。通常，这些信息是统计信息或一些时间值。 例如: 显示enp0s3网卡的流量  $ ip -s -h link show dev enp0s3 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 3.97M 50.5k 0 0 0 0 TX: bytes packets errors dropped carrier collsns 4.31M 33.5k 0 0 0 0 # 显示更多信息 $ ip -s -s -h link show dev enp0s3 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 3.96M 50.5k 0 0 0 0 RX errors: length crc frame fifo missed 0 0 0 0 0 TX: bytes packets errors dropped carrier collsns 4.30M 33.4k 0 0 0 0 TX errors: aborted fifo window heartbeat transns 0 0 0 0 30   -d, -details 输出更多详细信息 -l, -loops \u0026lt;COUNT\u0026gt; 指定ip addr flush命令逻辑放弃前将尝试的最大循环数。默认值为10。零（0）表示循环，直到删除所有地址。 -f, -family \u0026lt;FAMILY\u0026gt; 指定要使用的协议族。 协议族标识符可以是inet，inet6，bridge，mpls或link中的一种。 如果不存在此选项，则从其他参数中猜测协议族. -4 -family inet的简写 -6 -family inet6的简写 -4 -family inet的简写 -B -family bridge的简写 -M -family mpls的简写 -0 -family link的简写 -r, -resolve 使用系统的名称解析器来打印DNS名称而不是主机地址 -N, -Numeric 直接打印协议，范围，dsfield等的编号，而不是将其转换为人类可读的名称。 -a, -all 在所有对象上执行指定的命令，这取决于命令是否支持此选项。 -c[color][={always|auto|never} 配置颜色输出。 如果省略参数或设置参数为always，则不管标准输出状态如何，都启用颜色输出。 如果参数为auto，则在启用颜色输出之前，将stdout检查为终端。 如果参数是never，则禁用彩色输出。 如果多次指定，则最后一个优先。 如果还给出了-json，则忽略此标志。 使用的调色板会受到COLORFGBG环境变量的影响（请参阅环境）。 -t, -timestamp 使用监视器monitor选项时显示当前时间 -ts, -tshort 与-timestamp类似，但使用较短的格式 -rc, -rcvbuf\u0026lt;SIZE\u0026gt; 设置netlink套接字接收缓冲区的大小，默认为1MB。 -iec 以IEC单位打印可读速率（例如1Ki=1024）。  地址管理 显示所有地址:\n$ ip address show # 缩写 $ ip addr show  显示指定接口的地址:\n# 格式 $ ip address show ${interface name} # 示例 $ ip addr show enp0s3 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3 valid_lft 65793sec preferred_lft 65793sec inet6 fe80::a00:27ff:fe9b:e4fb/64 scope link valid_lft forever preferred_lft forever  显示正在运行的接口地址:\n$ ip address show up  显示静态或动态的接口地址:\n# 格式, 静态地址 $ ip address show [dev ${interface}] permanent # 格式, 动态地址 ip address show [dev ${interface}] dynamic # 示例 # 显示所有动态地址 $ ip addr show dynamic 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3 valid_lft 65549sec preferred_lft 65549sec # 显示 enp0s3 动态地址 $ ip addr show dev enp0s3 dynamic 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3 valid_lft 65515sec preferred_lft 65515sec  添加一个地址到接口:\n# 格式 $ ip address add ${address}/${mask} dev ${interface name} # 示例 # 添加一个ipv4地址到enp0s3 $ sudo ip address add 192.0.2.10/27 dev enp0s3 $ ip addr show enp0s3 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3 valid_lft 63847sec preferred_lft 63847sec inet 192.0.2.10/27 scope global enp0s3 valid_lft forever preferred_lft forever inet6 fe80::a00:27ff:fe9b:e4fb/64 scope link valid_lft forever preferred_lft forever # 也可以添加ipv6地址 $ sudo ip address add 2001:db8:1::/48 dev tun10   可以添加多个地址. 如果添加多个地址，则计算机将接受所有这些地址的数据包。添加的第一个地址将成为“主要地址”。默认情况下，接口的主地址用作传出数据包的源地址。设置的所有其他地址将成为辅助地址。\n 添加地址时还可以添加描述:\n# 格式, 只能在添加地址时才能添加描述 $ ip address add ${address}/${mask} dev ${interface name} label ${interface name}:${description} # 示例 $ sudo ip address add 192.0.2.11/27 dev enp0s3 label enp0s3:描述 $ ip addr show enp0s3 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3 valid_lft 63403sec preferred_lft 63403sec inet 192.0.2.10/27 scope global enp0s3 valid_lft forever preferred_lft forever inet 192.0.2.11/27 scope global secondary enp0s3:描述 valid_lft forever preferred_lft forever inet6 fe80::a00:27ff:fe9b:e4fb/64 scope link valid_lft forever preferred_lft forever  从接口删除地址:\n# 格式, delete 可以缩写为 del $ ip address delete ${address}/${mask} dev ${interface name} # 示例 # 注意, 似乎将辅助地址都删除了?? $ sudo ip addr del 192.0.2.10/27 dev enp0s3 $ ip addr show enp0s3 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:9b:e4:fb brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3 valid_lft 63025sec preferred_lft 63025sec inet6 fe80::a00:27ff:fe9b:e4fb/64 scope link valid_lft forever preferred_lft forever  清空一个接口的所有地址:\n# 格式 ip address flush dev ${interface name} # 示例 # 清空enp0s3的所有地址 $ sudo ip addr flush dev enp0s3 # 清空enp0s3的所有ipv4地址 $ sudo ip -4 addr flush dev enp0s3 # 清空enp0s3的所有ipv6地址 $ sudo ip -6 addr flush dev enp0s3  邻居(arp和ndp)表管理 arp: ipv4的地址解析协议 ndp: 包含arp的地址解析协议\n$ ip neighbor help Usage: ip neigh { add | del | change | replace } { ADDR [ lladdr LLADDR ] [ nud STATE ] | proxy ADDR } [ dev DEV ] [ router ] [ extern_learn ] ip neigh { show | flush } [ proxy ] [ to PREFIX ] [ dev DEV ] [ nud STATE ] [ vrf NAME ] STATE := { permanent | noarp | stale | reachable | none | incomplete | delay | probe | failed }  lladdr: 物理mac地址相关 nud: 状态相关 proxy: 代理相关 dev: 设备接口相关\n状态说明:\n   状态 说明     permanent 邻居条目永久有效, 只能管理员删除   noarp 邻居条目有效, 不会验证此条目, 可以在生存期过后删除   reachable 邻居条目有效, 一直到过期   stale 邻居条目有效但不能信任   none 刚添加邻居条目的伪状态, 随时可删除   incomplete 邻居条目还未验证或解决   delay 邻居条目延迟验证   probe 邻居条目正在探索   failed 邻居条目验证失败    查看邻居表:\n# neigh 是缩写 $ ip neighbor show 10.0.2.2 dev enp0s3 lladdr 52:54:00:12:35:02 DELAY # 查看 IPv4 (ARP) 邻居表 $ ip -4 neighbor show # 查看 IPv6 (NDP) 邻居表 $ ip -6 neighbor show   所有命令都可以使用-4和-6选项过滤 IPv4 (ARP) 和 IPv6 (NDP)\n 查看指定接口的邻居表:\n# 格式 $ ip neighbor show dev ${interface name} # 示例 $ ip neighbor show dev enp0s3 10.0.2.2 lladdr 52:54:00:12:35:02 REACHABLE  清空一个指定接口的邻居表:\n$ ip neighbor flush dev ${interface name} # 示例 $ ip neighbor flush dev enp0s3  添加和删除一个邻居条目:\n# 在eth0接口上为192.0.2.1添加一个永久的mac地址邻居条目 $ ip neigh add 192.0.2.1 lladdr 22:ce:e0:99:63:6f dev eth0 nud permanent # 删除 $ ip neigh del 192.0.2.1 lladdr 22:ce:e0:99:63:6f dev eth0  改变一个邻居条目状态:\n# 将状态改变为 reachable $ ip neigh change 192.0.2.1 dev eth0 nud reachable  链路管理 $ ip link help Usage: ip link add [link DEV] [ name ] NAME [ txqueuelen PACKETS ] [ address LLADDR ] [ broadcast LLADDR ] [ mtu MTU ] [index IDX ] [ numtxqueues QUEUE_COUNT ] [ numrxqueues QUEUE_COUNT ] type TYPE [ ARGS ] ip link delete { DEVICE | dev DEVICE | group DEVGROUP } type TYPE [ ARGS ] ip link set { DEVICE | dev DEVICE | group DEVGROUP } [ { up | down } ] [ type TYPE ARGS ] [ arp { on | off } ] [ dynamic { on | off } ] [ multicast { on | off } ] [ allmulticast { on | off } ] [ promisc { on | off } ] [ trailers { on | off } ] [ carrier { on | off } ] [ txqueuelen PACKETS ] [ name NEWNAME ] [ address LLADDR ] [ broadcast LLADDR ] [ mtu MTU ] [ netns { PID | NAME } ] [ link-netns NAME | link-netnsid ID ] [ alias NAME ] [ vf NUM [ mac LLADDR ] [ vlan VLANID [ qos VLAN-QOS ] [ proto VLAN-PROTO ] ] [ rate TXRATE ] [ max_tx_rate TXRATE ] [ min_tx_rate TXRATE ] [ spoofchk { on | off} ] [ query_rss { on | off} ] [ state { auto | enable | disable} ] ] [ trust { on | off} ] ] [ node_guid { eui64 } ] [ port_guid { eui64 } ] [ xdp { off | object FILE [ section NAME ] [ verbose ] | pinned FILE } ] [ master DEVICE ][ vrf NAME ] [ nomaster ] [ addrgenmode { eui64 | none | stable_secret | random } ] [ protodown { on | off } ] [ gso_max_size BYTES ] | [ gso_max_segs PACKETS ] ip link show [ DEVICE | group GROUP ] [up] [master DEV] [vrf NAME] [type TYPE] ip link xstats type TYPE [ ARGS ] ip link afstats [ dev DEVICE ] ip link help [ TYPE ] TYPE := { vlan | veth | vcan | vxcan | dummy | ifb | macvlan | macvtap | bridge | bond | team | ipoib | ip6tnl | ipip | sit | vxlan | gre | gretap | erspan | ip6gre | ip6gretap | ip6erspan | vti | nlmon | team_slave | bond_slave | bridge_slave | ipvlan | ipvtap | geneve | vrf | macsec | netdevsim | rmnet }  显示链路信息:\n# 显示所有链路信息 $ ip link show # 显示指定链路信息 ip link show dev eth0 ip link show eth0  设置链路状态:\n# 关闭 $ ip link set dev eth0 down # 打开 $ ip link set dev eth0 up  设置链路别名:\n# 设置别名 $ ip link set dev eth0 alias \u0026quot;别名\u0026quot;.  重命名设备接口:\n# 重命名eth0为lan, 需要先设置此链路状态为关闭 $ ip link set dev eth0 name lan  改变链路地址(通常是mac地址):\n# 改变 eth0 的mac地址 $ ip link set dev eth0 address 22:ce:e0:99:63:6f  改变链路的MTU(最大传输单元, 默认为1500):\n$ ip link set dev eth0 mtu 1480  删除一个链路:\n$ ip link delete dev eth0   显然，只能删除虚拟链接，例如VLAN，网桥或隧道。对于物理接口，此命令无效。\n 在接口上启用或禁用多播:(除非你真的知道你在做什么，最好不要碰这个选项。)\n# 启用多播 $ ip link set eth0 multicast on # 禁用多播 $ ip link set eth0 multicast off  在接口上启用或禁用ARP:\n# 启用ARP $ ip link set eth0 arp on # 禁用ARP $ ip link set eth0 arp off  创建一个VLAN接口:\n# 格式 $ ip link add name ${VLAN interface name} link ${parent interface name} type vlan id ${tag} # 示例 $ ip link add name eth0.110 link eth0 type vlan id 110  Linux唯一支持的VLAN类型是IEEE 802.1q VLAN。\n可以为VLAN接口使用任何名称。 以上示例中eth0.110是传统格式，但不是必需的。\n任何类似以太网的设备都可以作为VLAN接口的父级：bridge, bonding, L2 tunnels.\n 创建一个QinQ接口:\n# 格式 # 创建一个服务端标签接口 $ ip link add name ${service interface} link ${physical interface} type vlan proto 802.1ad id ${service tag} # 创建一个客户端标签接口 $ ip link add name ${client interface} link ${service interface} type vlan proto 802.1q id ${client tag} # 示例 # 创建一个服务端标签接口 $ ip link add name eth0.100 link eth0 type vlan proto 802.1ad id 100 # 创建一个客户端标签接口 $ ip link add name eth0.100.200 link eth0.100 type vlan proto 802.1q id 200  QinQ类似是一种扩展的VLAN, 也称为堆栈VLAN或双VLAN，由IEEE 802.1ad标准化。它用两层封装了VLAN标签:专用网络的内部标签和公共网络的外部标签。\n 创建一个虚拟mac地址(MACVLAN):\n# 格式 $ ip link add name ${macvlan interface name} link ${parent interface} type macvlan # 示例 $ ip link add name peth0 link eth0 type macvlan  这是一种网卡虚拟化的解决方案, 相当于一块物理网卡虚拟成多块虚拟网卡.\n 创建一个虚拟接口:\n# 格式 $ ip link add name ${dummy interface name} type dummy # 示例 $ ip link add name dummy0 type dummy  在Linux中, 由于历史原因只有一个回环接口lo, 虚拟接口类似回环接口lo, 但是虚拟接口可以有多个.\n可用于单个主机内的通信。 回环或虚拟接口也是在具有多个物理接口的路由器上分配管理地址的好地方。\n 创建一个网桥(bridge)接口:\n# 格式 $ ip link add name ${bridge name} type bridge # 示例 $ ip link add name br0 type bridge  网桥接口是虚拟以太网交换机。\n您可以使用它们将Linux机器变成慢速的L2交换机，或在虚拟机监控程序主机上的虚拟机之间启用通信。\n请注意，将Linux机器变成物理交换机并不是一个完全荒谬的想法，因为与笨拙的硬件交换机不同，它可以用作透明防火墙。\n可以将IP地址分配给网桥，并且该IP地址将在所有网桥端口中可见。\n添加网桥端口:\n# 格式 $ ip link set dev ${interface name} master ${bridge name} # 示例 $ ip link set dev eth0 master br0  添加到网桥的接口将成为虚拟交换机端口。它只在数据链路层上运行，并停止所有网络层操作。\n删除网桥端口:\n# 格式 $ ip link set dev ${interface name} nomaster # 示例 $ ip link set dev eth0 nomaster   创建一个bonding接口:\n# 格式 $ ip link add name ${name} type bond # 示例 $ ip link add name bond1 type bond  添加和删除bonding成员的方式与网桥操作一致, 都是使用master和nomaster.\n 添加一个中间功能模块接口:\n# 格式 $ ip link add ${interface name} type ifb # 示例 $ ip link add ifb10 type ifb  中间功能块设备与tc一起用于流量重定向和镜像。具体查看tc文档.\n 创建一对虚拟以太网设备:\n# 格式 $ ip link add name ${first device name} type veth peer name ${second device name} # 示例 $ ip link add name veth-host type veth peer name veth-guest   注意：虚拟以太网设备是在UP状态下创建的，创建后无需手动将其启动。\n 虚拟以太网（virtualethernet，veth）设备总是成对出现，并作为一个双向管道工作：任何进入其中一个设备的东西都会从另一个设备出来。它们与系统分区特性（如网络名称空间和容器（OpenVZ或LXC））结合使用，用于将一个分区连接到另一个分区。\n链路组管理 链路组类似于托管交换机中的端口范围。您可以将网络接口添加到编号的组中，并一次对该组中的所有接口执行操作。\n未分配给任何组的链接属于组0（“默认”）。\n将接口添加到组:\n# 格式 $ ip link set dev ${interface name} group ${group number} # 示例 $ ip link set dev eth0 group 42 $ ip link set dev eth1 group 42  从组中删除接口或分配到别的组: 可以通过将其分配给默认组0来完成。\n# 格式 $ ip link set dev ${interface name} group 0 $ ip link set dev ${interface} group default # 示例 $ ip link set dev tun10 group 0  为组指定符号名称:\n组的符号名称配置在/etc/iproute2/group文件中, 像默认组0的符号default也在此配置文件中, 可以修改或添加其它组的符号名称. 最多255组.\n按照格式:${number} ${name}写入配置文件即可.\n对组执行操作:\n# 格式 $ ip link set group ${group number} ${operation and arguments} # 示例 $ ip link set group 42 down $ ip link set group uplinks mtu 1200  查看指定组的信息:\n# 查看组42的链路信息 $ ip link show group 42 # 查看组42的地址信息 $ ip addr show group 42  路由管理 对于IPv4路由，可以使用前缀长度或点分十进制子网掩码。如192.0.2.0/24和192.0.2.0/255.255.255.0是一样的。\nLinux内核不保留下一跳无法到达的路由。如果链接断开，则将从该路由表中永久删除所有使用该链接的路由。您可能没有注意到这种现象，因为在许多情况下，当链路出现故障时，其他软件（例如NetworkManager或rp-pppoe）会负责恢复路由。\n如果要将Linux计算机用作路由器，请考虑安装路由协议套件，例如FreeRangeRouting或BIRD。 它们会跟踪链接状态，并在链接断开后又断开时恢复路由。 当然，它们还允许您使用动态路由协议，例如OSPF和BGP。\n为接口分配地址后，系统将计算其网络地址并创建到该网络的路由（这就是为什么需要子网掩码的原因）。 这样的路由称为连接路由。\n例如，如果您将203.0.113.25/24分配给eth0，则将创建到203.0.113.0/24网络的连接路由，系统将知道可以直接访问该网络中的主机。\n 查看路由表：\nip route # 或者 ip route show  查看到网络和所有子网的路由：\n# 语法，to 在命令中是可选的词 ip route show to root ${address}/${mask} # 查看网络192.168.0.0/24下的所有子网， # 会包括(如果有)如192.168.0.0/25、192.168.0.128/25等子网 ip route show to root 192.168.0.0/24  查看到网络和所有超网的路由：\n# 语法，to 在命令中是可选的词 ip route show to match ${address}/${mask} # 示例 ip route show to match 10.0.2.0/24  查看到精确子网的路由：\n# 语法，to 在命令中是可选的词 ip route show to exact ${address}/${mask} # 查看网络192.168.0.0/24的子网 # 不会会包括(如果有)如192.168.0.0/25、192.168.0.128/25等子网 ip route show to exact 192.168.0.0/24  仅查看内核实际当前使用的路由：\n# 语法 ip route get ${address}/${mask} # 示例 ip route get 192.168.0.0/24   通过网关添加路由：\n# 语法 ip route add ${address}/${mask} via ${next hop} # 示例 ip route add 192.0.2.128/25 via 192.0.2.1 ip route add 2001:db8:1::/48 via 2001:db8:1::1  通过接口添加路由：\n# 语法 ip route add ${address}/${mask} dev ${interface name} # 示例 ip route add 192.0.2.0/25 dev enp0s3  接口路由通常与点对点接口（例如PPP隧道）一起使用，而不需要下一跳地址。\n添加默认路由：\n# 语法，快捷方式 ip route add default via ${address}/${mask} ip route add default dev ${interface name} # 等价于 ip route add 0.0.0.0/0 via ${address}/${mask} ip route add 0.0.0.0/0 dev ${interface name} # 对于ipv6，default等价于::/0 ip -6 route add default via 2001:db8::1   改变或替换路由：\nip route change 192.168.2.0/24 via 10.0.0.1 ip route replace 192.168.2.0/24 via 10.0.0.1 ip route change 192.0.2.1/27 dev tun0 ip route replace 192.0.2.1/27 dev tun0  它们之间的区别在于，如果您尝试更改不存在的路由，则change命令将产生错误。 如果该命令尚不存在，则replace命令将创建一条路由。\n 删除路由：\n# 语法 ip route delete ${route specifier} # 示例 ip route delete 10.0.1.0/25 via 10.0.0.1 ip route delete default dev ppp0   黑洞路由：\n# 语法 ip route add blackhole ${address}/${mask} # 示例 ip route add blackhole 192.0.2.1/32  与黑洞路径匹配的目的地的流量将被自动静默丢弃。\n黑洞路由有两种用例。\n首先，它们可以用作非常快速的出站流量过滤器，例如，使已知的僵尸网络控制器无法访问或保护网络内的服务器免受传入的DDoS攻击。\n其次，如果您只有到其部分的真实路由，但希望将其汇总发布，则可以使用它们来欺骗路由协议守护程序，使其认为您具有到网络的路由。\n 其它特殊路由：\nip route add unreachable ${address}/${mask} ip route add prohibit ${address}/${mask} ip route add throw ${address}/${mask}  这些路由使系统丢弃数据包，并以ICMP错误消息答复发件人。\n unreachable：发送 \u0026ldquo;host unreachable\u0026rdquo; 主机不可达 prohibit：发送 \u0026ldquo;administratively prohibited\u0026rdquo; 管理上禁止 throw：发送 \u0026ldquo;net unreachable\u0026rdquo; 网络不可达  与黑洞路由不同，不建议使用这些路由来阻止不必要的流量（例如DDoS），因为它们会为每个丢弃的数据包生成一个回复数据包，从而产生更大的流量。 它们可以很好地实施内部访问策略，但是通常使用防火墙是一个更好的主意。\n 路由的度量(metric)设置：\n# 语法 ip route add ${address}/${mask} via ${gateway} metric ${number} # 示例 ip route add 192.168.2.0/24 via 10.0.1.1 metric 5 ip route add 192.168.2.0 dev ppp0 metric 10  如果有多个通往同一网络的度量值不同的路由，则内核会首选度量值最低的路由。\n此功能通常用于实现到重要目标的备份连接。\n 多路径路由：\n# 语法 ip route add ${addresss}/${mask} nexthop via ${gateway 1} weight ${number} nexthop via ${gateway 2} weight ${number} # 示例 ip route add default nexthop via 192.168.1.1 weight 1 nexthop dev ppp0 weight 10  多路径路由使系统根据权重在多个链路上平衡数据包（首选更高的权重，因此权重为2的网关/接口将获得比权重为1的另一个网关/接口大约多两倍的流量）。您可以拥有任意数量的网关，并且可以混合使用网关和接口路由。\n 警告：这种类型的负载平衡的不利之处在于，不能保证数据包将通过它们进入的同一链路发送回去。这称为“非对称路由”。 对于只转发数据包而不进行任何本地流量处理的路由器，通常很好，在某些情况下甚至是不可避免的。\n 策略路由 Linux中基于策略的路由（Policy-based routing，PBR）的设计方法如下：首先创建自定义路由表，然后创建规则来告诉内核哪些表用于哪些数据包。\n","date":"2021-04-08","permalink":"/post/linux-iproute2-ip/","tags":["linux","shell","iproute2"],"title":"Linux Iproute2 Ip"},{"content":"Linux 的日期时间管理\n以给定的格式显示当前时间，或设置系统日期。\ndate参数    参数 说明     -d STRING 显示由STRING描述的时间   -I[FMT] 显示ISO8601格式时间。FMT精度：\ndate(默认)、hours、minutes、seconds、ns   -R 以RFC5322格式输出日期和时间   -r FILE 显示文件最后修改时间   -u 显示UTC时间   -s STRING 设置STRING描述的时间    日期格式 %H 小时，24小时制（00~23） %I 小时，12小时制（01~12） %k 小时，24小时制（0~23） %l 小时，12小时制（1~12） %M 分（00～59） %p 显示出上午或下午 %r 时间，12小时制 %s 从1970年1月1日0点到目前经历的秒数 %S 秒（00～59） %T 时间（24小时制）（hh:mm:ss） %X 显示时间的格式（％H时％M分％S秒） %Z 按字母表排序的时区缩写 %a 星期名缩写 %A 星期名全称 %b 月名缩写 %B 月名全称 %c 日期和时间 %d 按月计的日期（01～31） %D 日期（mm/dd/yy） %h 和%b选项相同 %j 一年的第几天（001~366） %m 月份（01～12） %w 一个星期的第几天（0代表星期天） %W 一年的第几个星期（00～53，星期一为第一天） %x 显示日期的格式（mm/dd/yy） %y 年份的最后两个数字（1999则是99） %Y 年份（比如1970、1996等） %C 世纪，通常为省略当前年份的后两位数字 %U 一年中的第几周，以周日为每星期第一天 %e 按月计的日期，添加空格，等于%_d  示例 默认显示时间：\n$ date Fri 26 Mar 2021 08:32:49 PM CST  格式化输出：\n$ date +'%Y %m %d' 2021 03 26 $ date +'日期：%Y %m %d' 日期：2021 03 26 $ date +'%Y-%m-%d %H:%M:%S' 2021-03-26 20:46:30  显示自己指定的时间：\n# 显示今天23点 $ date -d \u0026quot;23\u0026quot; +\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot; 2021-03-26 23:00:00 # 显示1天前日期 $ date -d \u0026quot;1 day ago\u0026quot; +\u0026quot;%Y-%m-%d\u0026quot; 2021-03-25 # 显示2小时后日期 $ date -d \u0026quot;2 hour\u0026quot; +\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot; 2021-03-26 22:59:02 # 显示2分钟后日期 $ date -d \u0026quot;2 min\u0026quot; +\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot; 2021-03-26 21:03:15 # 显示指定时间 $ date -d \u0026quot;2020-12-05 12:12:02\u0026quot; +\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot; 2020-12-05 12:12:02  加减操作：\n# 明天 $ date -d '+1 day' +'%Y-%m-%d' 2021-03-27 # 昨天 $ date -d '-1 day' +'%Y-%m-%d' 2021-03-25 # 下个月 $ date -d '+1 month' +'%Y-%m-%d' 2021-04-26 # 上个月 $ date -d '-1 month' +'%Y-%m-%d' 2021-02-26 # 2年后 $ date -d '+2 year' +'%Y-%m-%d' 2023-03-26 # 2年前 $ date -d '-2 year' +'%Y-%m-%d' 2019-03-26  设置时间：\ndate -s 20120523 //设置成20120523，这样会把具体时间设置成空00:00:00 date -s 01:01:01 //设置具体时间，不会对日期做更改 date -s \u0026quot;01:01:01 2012-05-23\u0026quot; //这样可以设置全部时间 date -s \u0026quot;01:01:01 20120523\u0026quot; //这样可以设置全部时间 date -s \u0026quot;2012-05-23 01:01:01\u0026quot; //这样可以设置全部时间 date -s \u0026quot;20120523 01:01:01\u0026quot; //这样可以设置全部时间 ","date":"2021-04-08","permalink":"/post/linux-date%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4/","tags":["linux","shell"],"title":"Linux Date日期时间"},{"content":"Linux定时任务。crontab提交和管理用户的需要周期性执行的任务\nLinux下的任务调度分为两类： 系统任务调度 和 用户任务调度 。\n系统任务调度： 系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。/etc/crontab文件是系统任务调度的配置文件。\n用户任务调度： 用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab文件都被保存在/var/spool/cron/crontabs目录中，其文件名与用户名一致。\n使用者权限文件如下：\n/etc/cron.deny 该文件中所列用户不允许使用crontab命令 /etc/cron.allow 该文件中所列用户允许使用crontab命令 /var/spool/cron/ 所有用户crontab文件存放的目录,以用户名命名  查看 crontab 的状态：\n$ systemctl status cron.service ● cron.service - Regular background program processing daemon Loaded: loaded (/lib/systemd/system/cron.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2021-03-20 22:27:35 CST; 6 days ago Docs: man:cron(8) Main PID: 382 (cron) Tasks: 1 (limit: 1147) Memory: 2.1M CGroup: /system.slice/cron.service └─382 /usr/sbin/cron -f  参数 -e : 编辑用户的crontab定时任务 -l : 列出用户的crontab定时任务 -r : 删除用户的crontab定时任务 -u user : 指定要设定crontab任务的用户名称。  内容格式 crontab配置5个*代表5个部分，分别代表分钟，小时，天，月，周，如下:\n┌───────────── 分钟(0 - 59) 一小时当中的第几分钟 │ ┌───────────── 小时(0 - 23) 一天当中的第几小时 │ │ ┌───────────── 天 (1 - 31) 一个月当中的第几天 │ │ │ ┌───────────── 月 (1 - 12) 一年当中的第几个月 │ │ │ │ ┌───────────── 周几 (0 - 6) (周日到周一，有的系统里面7表示周日) │ │ │ │ │ 一周当中的星期几 │ │ │ │ │ │ │ │ │ │ * * * * * command   *: 表示任意值。如第一个*就表示一小时中的每分钟都执行一次 ,：表示多个值。如：0 8,12,16 * * * 命令，表示在每天的08:00,12:00,16:00都执行一次命令 -：表示连续的时间范围。如：0 5 * * 1-6 命令，表示在周一到周六的凌晨05:00执行命令 */n：表示每隔多久执行一次。如：*/10 * * * * 命令，表示每隔10分钟就执行一次命令 command：表示要执行的命令或脚本。  示例 执行crontab -e会使用默认编辑器打开/var/spool/cron/crontabs/\u0026lt;用户名\u0026gt;的文件，可以在里面编写定时任务，如：\n*/1 * * * * date -Iseconds \u0026gt;\u0026gt; ~/test_cron.txt  表示每分钟执行一次命令。\n","date":"2021-04-08","permalink":"/post/crontab/","tags":["linux","shell"],"title":"Crontab"},{"content":"Linux sed命令, 用于处理文本\nsed的选项：\n -e \u0026ndash; 多项编辑，在使用多个sed命令时使用 -n \u0026ndash; 取消默认的输出，使用安静(silent)模式。在一般 sed 的用法中，所有来自stdin的资料一般都会被列出到屏幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来 -f \u0026ndash; 指定脚本文件名 -i \u0026ndash; 直接修改读取的文件内容，而不是由屏幕输出 -r \u0026ndash; sed支持延伸型正则表达式的语法，加-r后 可以换掉不用\\  sed的功能：\n   参数 说明     a 插入，当前行后添加一行或多行。多行需在每行最后加“\\”   c 替换，把当前行中的文本替换成符号后的新文本。多行需在每行最后加“\\”   s 替换，用一个字符串替换另一个。通常和正则表达式搭配使用：5s/旧命令/新命令/g ，5表示行数，默认全行，g是全局   g 全局替换   d 删除行   i 插入，在当前行之前插入文本，多行需在每行最后加“\\”   p 打印行   q 结束，退出sed   r 从文件中读取输入行   w 将所选的行追加写入文件末尾   x 交换暂存缓冲区与模式空间的内容   ! 取反，对所选行以外的行生效命令   y 将字符替换成另一字符（不支持正则）   h copy模板块的内容粘贴到内存中的缓冲区   l 列出非打印字符   n 直接读下一行，并从下一条命令处理     操作的示例文件：con.txt\nUSSR 8649 275 Asia Canada 3852 25 North America China 3705 1032 Asia USA 3615 237 North America Brazil 3286 134 South America India 1267 746 Asia Mexico 762 78 North America France 211 55 Europe Japan 144 120 Asia Germany 96 61 Europe England 94 56 Europe   语法1：  sed [options] {sed-commands} {input-file} # -n表示取消默认输出,p表示打印行 # 打印所有行 sed -n 'p' con.txt # 打印第3行 sed -n '3p' con.txt # 打印第2到第5行的所有行 sed -n '2,5p' con.txt    语法2：将sed命令写入到一个文件中，通过-f执行这个文件  sed [options] -f {sed-commands-in-a-file} {input-file} # -f sed的脚本文件 cat sed_con.txt /^China/ p /^Japan/ p # 打印以China和Japan开头的行 sed -n -f sed_con.txt con.txt    语法3：  sed [options] -e {sed-command-1} -e {sed-command-2} {input-file} # 打印以China和Japan开头的行 sed -n -e '/^China/ p' -e '/^Japan/ p' con.txt # 或者 sed -n \\ -e '/^China/ p' \\ -e '/^Japan/ p' \\ con.txt    语法4：  sed [options] '{ sed-command-1 sed-command-2 }' input-file # 打印以China和Japan开头的行 [~/awk_sed]$ sed -n '{ quote\u0026gt; /^China/ p quote\u0026gt; /^Japan/ p quote\u0026gt; }' con.txt China 3705 1032 Asia Japan 144 120 Asia  基本示例 示例文件：test_sed.txt\n101,Ian Bicking,Mozilla 102,Hakim El Hattab,Whim 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware  范围 # 从第 1 行开始，每隔 2 行读取行 [~/awk_sed]$ sed -n '1~2 p' test_sed.txt 101,Ian Bicking,Mozilla 103,Paul Irish,Google 105,Chris Wanstrath,Github 107,Ask Solem Hoel,VMware # 从第 2 行开始，每隔 3 行读取行 [~/awk_sed]$ sed -n '2~3 p' test_sed.txt 102,Hakim El Hattab,Whim 105,Chris Wanstrath,Github  模式匹配 # 寻找包含Paul的行 [~/awk_sed]$ sed -n '/Paul/ p' test_sed.txt 103,Paul Irish,Google # 从第一行开始到第五行, 从找到开始打印到第五行 [~/awk_sed]$ sed -n '/Paul/,5 p' test_sed.txt 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github # 从匹配Paul行打印达匹配Addy的行 [~/awk_sed]$ sed -n '/Paul/,/Addy/ p' test_sed.txt 103,Paul Irish,Google 104,Addy Osmani,Google # 匹配Paul行再多输出2行 [~/awk_sed]$ sed -n '/Paul/,+2 p' test_sed.txt 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github  删除行  注意：如果没有加-i参数，默认是不会修改源文件的。\n # 删除所有行 [~/awk_sed]$ sed 'd' test_sed.txt # 只删除第二行 [~/awk_sed]$ sed '2 d' test_sed.txt 101,Ian Bicking,Mozilla 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 删除第一到第四行 [~/awk_sed]$ sed '1,4 d' test_sed.txt 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 从第 1 行开始，每隔 2 行删除行 [~/awk_sed]$ sed '1~2 d' test_sed.txt 102,Hakim El Hattab,Whim 104,Addy Osmani,Google 106,Mattt Thompson,Heroku # 删除符合Paul到Addy的行 [~/awk_sed]$ sed '/Paul/,/Addy/ d' test_sed.txt 101,Ian Bicking,Mozilla 102,Hakim El Hattab,Whim 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 删除空行 [~/awk_sed]$ sed '/^$/ d' test_sed.txt 101,Ian Bicking,Mozilla 102,Hakim El Hattab,Whim 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware  重定向 # 将source.txt内容重定向写到output.txt $sed 'w output.txt' source.txt # 和上面一样,但是没有在终端显示 $sed -n 'w output.txt' source.txt # 只写第二行 $ sed -n '2 w output.txt' source.txt # 写一到四行到output.txt $sed -n '1,4 w output.txt' # 写匹配Ask的行到结尾行到output.txt $sed -n '/Ask/,$ w output.txt'  替换 格式：\n$sed '[匹配模式] s/原str/替str/[标志位]' 文件  示例：\n# 替换Google为Github $sed 's/Google/Github/' test_sed.txt 101,Ian Bicking,Mozilla 102,Hakim El Hattab,Whim 103,Paul Irish,Github 104,Addy Osmani,Github 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 替换匹配Addy的行里面的Google为Github $sed '/Addy/s/Google/Github/' test_sed.txt 101,Ian Bicking,Mozilla 102,Hakim El Hattab,Whim 103,Paul Irish,Google 104,Addy Osmani,Github 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 默认s只会替换第1行中的第1个匹配项 $sed '1s/a/A/' test_sed.txt | head -1 101,IAn Bicking,Mozilla # 替换第2行中的第3个匹配项 $ sed '2s/a/A/3' sed_test.txt 101,Ian Bicking,Mozilla 102,Hakim El HattAb,Whim 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 加标志位 g 可以替换每行的全部符合 $sed '1s/a/A/g' test_sed.txt | head -1 101,IAn Bicking,MozillA # 可以直接指定想要替换的第N个匹配项,这里是第 2 个 $sed '1s/a/A/2' test_sed.txt | head -1 101,Ian Bicking,MozillA # 使用w将能够替换的行重定向写到output.txt $sed -n 's/Mozilla/Github/w output.txt' test_sed.txt $cat output.txt 101,Ian Bicking,Github # 使用 i 忽略匹配的大小写 $sed '1s/ian/IAN/i' test_sed.txt | head -1 101,IAN Bicking,Mozilla # sed分隔符不只可以使用'/' $sed 's|/usr/local/bin|/usr/bin|' path.txt $sed 's^/usr/local/bin^/usr/bin^' path.txt $sed 's@/usr/local/bin@/usr/bin@' path.txt # 此处有一个新文件 $cat files.txt /etc/passwd /etc/group # 给每行前和后都添加点字符 $sed 's/\\(.*\\)/ls -l \\1/' files.txt ls -l /etc/passwd ls -l /etc/group # \\1 表示前前面第1个括号中匹配的内容，以此类推 # 替换覆盖 sed '{ s/Google/Github/ s/Git/git/ }' source.txt 101,Ian Bicking,Mozilla 102,Hakim El Hattab,Whim 103,Paul Irish,github 104,Addy Osmani,github 105,Chris Wanstrath,github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # \u0026amp; 表示已匹配的字符串标记 $sed 's/[0-9][0-9][0-9]/[\u0026amp;]/' test_sed.txt [101],Ian Bicking,Mozilla [102],Hakim El Hattab,Whim [103],Paul Irish,Google [104],Addy Osmani,Google [105],Chris Wanstrath,Github [106],Mattt Thompson,Heroku [107],Ask Solem Hoel,VMware   插入行与修改行 # 行后插入 a # 在第2行后插入 $sed '2 a 108,test test,test' test_sed.txt 101,Ian Bicking,Mozilla 102,Hakim El Hattab,Whim 108,test test,test 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 行前插入 i # 在第2行前插入 $sed '2 i 108,test test,test' test_sed.txt 101,Ian Bicking,Mozilla 108,test test,test 102,Hakim El Hattab,Whim 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware # 修改第2行 c $sed '2 c 108,test test,test' test_sed.txt 101,Ian Bicking,Mozilla 108,test test,test 103,Paul Irish,Google 104,Addy Osmani,Google 105,Chris Wanstrath,Github 106,Mattt Thompson,Heroku 107,Ask Solem Hoel,VMware   其它 # = 可以显示行号 $sed = test_sed.txt 1 101,Ian Bicking,Mozilla 2 102,Hakim El Hattab,Whim 3 103,Paul Irish,Google 4 104,Addy Osmani,Google 5 105,Chris Wanstrath,Github 6 106,Mattt Thompson,Heroku 7 107,Ask Solem Hoel,VMware   高级 示例文件：t2.txt\nIan Bicking Mozilla Hakim El Hattab Whim Paul Irish Google Chris Wanstrath Github Mattt Thompson Heroku\t 运行模式 当处理数据时，Sed 从输入源一次读入一行，并将它保存到所谓的模式空间(pattern space)中。所有 Sed 的变换都发生在模式空间。变换都是由命令行上或外部 Sed 脚本文件提供的单字母命令来描述的。大多数 Sed 命令都可以由一个地址或一个地址范围作为前导来限制它们的作用范围。\n默认情况下，Sed 在结束每个处理循环后输出模式空间中的内容，也就是说，输出发生在输入的下一个行覆盖模式空间之前。我们可以将这种运行模式总结如下：\n 尝试将下一个行读入到模式空间中 如果读取成功：  按脚本中的顺序将所有命令应用到与那个地址匹配的当前输入行上 如果 sed 没有以静默模式（-n）运行，那么将输出模式空间中的所有内容（可能会是修改过的）。 重新回到 1。    因此，在每个行被处理完毕之后，模式空间中的内容将被丢弃，它并不适合长时间保存内容。基于这种目的，Sed 有第二个缓冲区：保持空间(hold space)。除非你显式地要求它将数据置入到保持空间、或从保持空间中取得数据，否则 Sed 从不清除保持空间的内容。\n","date":"2021-02-28","permalink":"/post/sed%E5%91%BD%E4%BB%A4/","tags":["shell","linux","sed"],"title":"Sed命令"},{"content":"venv 是python自带的虚拟环境.\n虚拟环境是用于依赖项管理和项目隔离的python工具，它可以将python程序和pip包管理工具安装在本地的隔离目录中（非全局安装）。\n在实际开发中，不同项目可能需要的python版本和项目的第三方依赖包的版本不同，因此需要使用到虚拟环境来管理不同的项目。\n创建虚拟环境 python -m venv \u0026lt;ENV_DIR\u0026gt;\n查看帮助: python -m venv -h\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear] [--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps] ENV_DIR [ENV_DIR ...] 在一个或多个目标目录中创建虚拟Python环境 位置参数: ENV_DIR 要在其中创建环境的目录 可选参数: -h, --help 显示帮助信息并退出 --system-site-packages 授予虚拟环境访问系统已安装软件包目录的权限。 --symlinks 当符号链接不是平台的默认值时，请尝试使用符号链接而不是副本。 --copies 即使符号链接是平台的默认设置，也请尝试使用副本而不是符号链接。 --clear 创建环境之前，删除环境目录的内容（如果已经存在）。 --upgrade 假设Python已升级，升级环境目录以使用此版本的Python。 --without-pip 跳过在虚拟环境中安装或升级pip（默认情况下，pip是引导的） --prompt PROMPT 为此环境提供另一个提示前缀。 --upgrade-deps 升级核心依赖项：将pip setuptools升级到PyPI中的最新版本 创建环境后，您可能希望激活它，例如 通过在其bin目录中获取激活脚本。  示例说明:\n在flask_venv目录创建虚拟环境:\npython -m venv .\\flask_venv\n./flask_venv ├── Include ├── Lib ├── pyvenv.cfg └── Scripts  pyvenv.cfg文件包含相关环境的信息.\nScripts目录(在POSIX中为bin目录), 包含 Python 二进制文件的副本或符号链接\n创建虚拟环境后，可以使用虚拟环境的二进制目录中的脚本来“激活”该环境。不同平台调用的脚本是不同的:\n   平台 Shell 用于激活虚拟环境的命令     POSIX bash/zsh \u0026lt;venv\u0026gt;/bin/activate    fish \u0026lt;venv\u0026gt;/bin/activate.fish    csh/tcsh \u0026lt;venv\u0026gt;/bin/activate.csh    PowerShell Core \u0026lt;venv\u0026gt;/bin/Activate.ps1   Windows cmd.exe \u0026lt;venv\u0026gt;\\Scripts\\activate.bat    PowerShell \u0026lt;venv\u0026gt;\\Scripts\\Activate.ps1    当一个虚拟环境被激活时，VIRTUAL_ENV 环境变量会被设为该虚拟环境的路径。 这可被用来检测程序是否运行在虚拟环境中。\n 注意: 激活环境不是 必须 的，激活只是将虚拟环境的二进制目录(bin或者Script)添加到搜索路径中，这样 \u0026ldquo;python\u0026rdquo; 命令将调用虚拟环境的 Python 解释器，可以运行其中已安装的脚本，而不必输入其完整路径。但是，安装在虚拟环境中的所有脚本都应在不激活的情况下可运行，并自动与虚拟环境的 Python 一起运行。\n 激活后, 要退出虚拟环境使用: deactivate 命令.\n","date":"2021-02-09","permalink":"/post/python-venv%E6%A8%A1%E5%9D%97/","tags":["python"],"title":"Python Venv模块"},{"content":"subprocess 子进程管理\n生成新的进程，连接它们的输入、输出、错误管道，并且获取它们的返回码。\nrun() subprocess 模块首先推荐使用的是它的 run 方法，更高级的用法可以直接使用底层的 Popen 接口。\nsubprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, capture_output=False, shell=False, cwd=None, timeout=None, check=False, encoding=None, errors=None, text=None, env=None, universal_newlines=None, **other_popen_kwargs)\n运行被 args 描述的指令。等待指令完成，然后返回一个 CompletedProcess 实例。\n args可以是一个字符串或者列表序列 stdin,stdout,stderr: 执行程序命令的标准输入、输出和错误。 其值可以是 subprocess.PIPE、subprocess.DEVNULL、一个已经存在的文件描述符、已经打开的文件对象或者 None。subprocess.PIPE 表示为子进程创建新的管道。subprocess.DEVNULL 表示使用 os.devnull。默认使用的是 None，表示什么都不做。另外，stderr 可以合并到 stdout 里一起输出。 capture_output: stderr和stdout的合并, 如果设置为True, stdout 和 stderr 将会被捕获, 即:stdout=subprocess.PIPE,stderr=subprocess.PIPE timeout: 设置命令超时时间。如果命令执行时间超时，子进程将被杀死，并弹出 TimeoutExpired 异常。 check: 如果该参数设置为 True，并且进程退出状态码returncode不是 0，则弹 出 CalledProcessError 异常。 text: 如果为True, 则 stdin、stdout 和 stderr 可以接收字符串数据, 否则只接收 bytes 类型的数据。 shell: 如果该参数为 True，将通过操作系统的 shell 执行指定的命令。在win10中必须设置为True才会执行命令. 在 Windows，使用 shell=True，环境变量 COMSPEC 指定了默认 shell。在 Windows 你唯一需要指定 shell=True 的情况是你想要执行内置在 shell 中的命令（例如 dir 或者 copy）。在运行一个批处理文件或者基于控制台的可执行文件时，不需要 shell=True。 cwd: 在执行子进程前会将当前工作目录改为 cwd。 cwd 可以是一个字符串、字节串或 路径类对象 env: 用于指定子进程的环境变量。如果 env = None，子进程的环境变量将从父进程中继承。字典.  返回的CompletedProcess实例属性和方法有:\n args: 运行的指令 returncode: 子进程的退出状态码. 通常来说, 一个为 0 的退出码表示进程运行正常. 一个负值 -N 表示子进程被信号 N 中断 (仅 POSIX). stdout, stderr: 从子进程捕获到的标准输出, 错误. 一个字节序列. 如果 run() 是设置了 encoding, errors 或者 text=True 来运行的, 则可以是字符串 如果未有捕获, 则为 None. check_returncode(): 为实例方法, 如果 returncode 非零, 抛出 CalledProcessError.  示例:\n\u0026gt;\u0026gt;\u0026gt; subprocess.run(args='ls', shell=True) CompletedProcess(args='ls', returncode=1) \u0026gt;\u0026gt;\u0026gt; subprocess.run(args='ls', shell=True, capture_output=True) CompletedProcess(args='ls', returncode=1, stdout=b'', stderr=b\u0026quot;'ls' \\xb2\\xbb\\xca\\xc7\\xc4\\xda\\xb2\\xbf\\xbb\\xf2\\xcd\\xe2\\xb2\\xbf\\xc3\\xfc\\xc1\\xee\\xa3\\xac\\xd2\\xb2\\xb2\\xbb\\xca\\xc7\\xbf\\xc9\\xd4\\xcb\\xd0\\xd0\\xb5\\xc4\\xb3\\xcc\\xd0\\xf2\\r\\n\\xbb\\xf2\\xc5\\xfa\\xb4\\xa6\\xc0\\xed\\xce\\xc4\\xbc\\xfe\\xa1\\xa3\\r\\n\u0026quot;) # text=True 会转化输出为字符串类型, win10中的dos没有ls命令 \u0026gt;\u0026gt;\u0026gt; subprocess.run(args='ls', shell=True, capture_output=True, text=True) CompletedProcess(args='ls', returncode=1, stdout='', stderr=\u0026quot;'ls' 不是内部或外部命令，也不是可运行的程序\\n或批处理文件。\\n\u0026quot;) \u0026gt;\u0026gt;\u0026gt; subprocess.run(args=['echo',r'你好'], shell=True, capture_output=True, text=True) CompletedProcess(args=['echo', '你好'], returncode=0, stdout='你好\\n', stderr='')  Popen() subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=None, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), *, group=None, extra_groups=None, user=None, umask=-1, encoding=None, errors=None, text=None)\n在一个新的进程中执行子程序。返回Popen实例.\n在 POSIX，此类使用类似于 os.execvp() 的行为来执行子程序。\n在 Windows，此类使用了 Windows CreateProcess() 函数\n参数与run()类似. 还有些其它参数\n bufsize: 缓冲区大小。当创建标准流的管道对象时使用，默认-1。 0表示不使用缓冲区. 1表示行缓冲，仅当universal_newlines=True时可用，也就是文本模式 正数：表示缓冲区大小 负数：表示使用系统默认的缓冲区大小。 preexec_fn：只在 Unix 平台下有效，用于指定一个可执行对象（callable object），它将在子进程运行之前被调用  Popen 对象支持通过 with 语句作为上下文管理器，在退出时关闭文件描述符并等待进程:\nwith Popen([\u0026quot;ifconfig\u0026quot;], stdout=PIPE) as proc: log.write(proc.stdout.read())  Popen实例对象方法:\n poll() 检查进程是否终止，如果终止返回 returncode，否则返回 None。 wait(timeout=None) 等待子进程被终止。 communicate(input=None, timeout=None) 和子进程交互，发送和读取数据。 send_signal(signal) 将信号 signal 发送给子进程 terminate() 停止子进程。 在 POSIX 操作系统上，此方法会发送 SIGTERM 给子进程。 在 Windows 上则会调用 Win32 API 函数 TerminateProcess() 来停止子进程。 kill() 杀死子进程。 在 POSIX 操作系统上，此函数会发送 SIGKILL 给子进程。 在 Windows 上 kill() 则是 terminate() 的别名。  Popen实例对象属性:\n args: 指令 stdin, stdout, stderr: 如果 stdin 或 stdout 或 stderr 参数为 PIPE，此属性是一个类似 open() 返回的可写的流对象。如果 encoding 或 errors 参数被指定或者 universal_newlines 参数为 True，则此流是一个文本流，否则是字节流。如果 stdin 参数非 PIPE， 此属性为 None。 pid 子进程的进程号。 returncode 子进程的退出码 ","date":"2021-02-09","permalink":"/post/python-subprocess%E6%A8%A1%E5%9D%97/","tags":["python"],"title":"Python Subprocess模块"},{"content":"显示、设置或删除分配给文件或目录的属性。 如果在没有参数的情况下使用，则attrib将显示当前目录中所有文件的属性。\n参数    参数 描述     {+|-}r 设置（+）或清除（-）只读文件属性。   {+|-}a 设置（+）或清除（-）存档文件属性。 此属性集用于标记自上次备份以来发生更改的文件。请注意， xcopy命令使用存档属性。   {+|-}s 设置（+）或清除（-）系统文件属性。 如果文件使用此属性集，则必须清除该属性，然后才能更改文件的任何其他属性。   {+|-}h 设置（+）或清除（-）隐藏文件属性。 如果文件使用此属性集，则必须清除该属性，然后才能更改文件的任何其他属性。   {+|-}i 设置（+）或清除（-） \u0026ldquo;非内容索引文件\u0026rdquo; 属性。   [\u0026lt;drive\u0026gt;:][\u0026lt;path\u0026gt;][\u0026lt;filename\u0026gt;] 指定要显示或更改属性的目录、文件或文件组的位置和名称。您可以使用 ？ 和 * filename参数中的通配符，以显示或更改一组文件的属性。   /s 将attrib和任何命令行选项应用于当前目录及其所有子目录中的匹配文件。   /d 将attrib和任何命令行选项应用于目录。   /l 将attrib和任何命令行选项应用于符号链接，而不是符号链接的目标。   /? 在命令提示符下显示帮助。     示例 若要显示位于当前目录中名为 News86 的文件的属性，请键入：\nattrib news86  若要将只读属性分配给名为 test.txt 的文件，请键入：\nattrib +r report.txt  若要从位于驱动器 b：中的磁盘上的公共目录及其子目录中删除只读属性，请键入：\nattrib -r b:\\public\\*.* /s  若要为驱动器 a 上的所有文件设置 Archive 属性，然后清除扩展名为 .bak 的文件的 Archive 属性，请键入：\nattrib +a a:*.* \u0026amp; attrib -a a:*.bak   参考链接\n","date":"2021-01-31","permalink":"/post/dos%E5%91%BD%E4%BB%A4attrib/","tags":["dos"],"title":"DOS命令attrib"},{"content":"Fetch API 提供了一个获取资源的接口（包括跨域请求）。是XMLHttpRequest的一种替代方案。\nfetch不是ajax的进一步封装，而是原生js。\najax与fetch的使用对比 ajax  使用步骤  创建XmlHttpRequest对象 调用open方法设置基本请求信息 设置发送的数据，发送请求 注册监听的回调函数 拿到返回值，对页面进行更新    //1.创建Ajax对象 if(window.XMLHttpRequest){ var oAjax=new XMLHttpRequest(); }else{ var oAjax=new ActiveXObject(\u0026quot;Microsoft.XMLHTTP\u0026quot;); } //2.连接服务器（打开和服务器的连接） oAjax.open('GET', url, true); //3.发送 oAjax.send(); //4.接收 oAjax.onreadystatechange=function (){ if(oAjax.readyState==4){ if(oAjax.status==200){ //alert('成功了：'+oAjax.responseText); fnSucc(oAjax.responseText); }else{ //alert('失败了'); if(fnFaild){ fnFaild(); } } } };  fetch Fetch 提供了对 Request 和 Response （以及其他与网络请求有关的）对象的通用定义。\n它同时还为有关联性的概念，例如CORS和HTTP原生头信息，提供一种新的定义，取代它们原来那种分离的定义。\nfetch() 必须接受一个参数——资源的路径。无论请求成功与否，它都返回一个 Promise 对象，resolve 对应请求的 Response。你也可以传一个可选的第二个参数 init（参见 Request）。\nlet btn1 = document.querySelector('#btn1'); btn1.onclick = ()=\u0026gt;{ let form_data = new FormData(); form_data.append('id',233); form_data.append('name','qlel'); form_data.append('msg','this is fetch post test 测试'); fetch('file2.php',{ method:'POST', body: form_data }) .then((response)=\u0026gt;{ return response.json() // .then(data=\u0026gt;console.log(data)) }) .then(data=\u0026gt;console.log(data)) .catch((error)=\u0026gt;console.log(error)) }  fetch和ajax 的主要区别  fetch()返回的promise将不会拒绝http的错误状态，即使响应是一个HTTP 404或者500 在默认情况下 fetch不会接受或者发送cookies   fetch支持的请求参数 fetch(input[,init]) fetch() 接受第一个参数为URL，也可以是一个Request 对象； fetch() 接受第二个可选参数，一个可以控制不同配置的 init 对象：\n method :请求使用的方法，如GET,POST; headers: 请求的头信息，形式为 Headers 的对象或包含 ByteString 值的对象字面量。 body: 请求的 body 信息：可能是一个 Blob、BufferSource、FormData、URLSearchParams 或者 USVString 对象。注意 GET 或 HEAD 方法的请求不能包含 body 信息。 mode: 请求的模式，如 cors、 no-cors 或者 same-origin。 credentials: 请求的 credentials，如 omit、same-origin 或者 include。为了在当前域名内自动发送 cookie ， 必须提供这个选项， 从 Chrome 50 开始， 这个属性也可以接受FederatedCredential 实例或是一个 PasswordCredential 实例。 cache: 请求的 cache 模式: default 、 no-store 、 reload 、 no-cache 、 force-cache 或者 only-if-cached 。 redirect: 可用的 redirect 模式: follow (自动重定向), error (如果产生重定向将自动终止并且抛出一个错误), 或者 manual (手动处理重定向). 在Chrome中，Chrome 47之前的默认值是 follow，从 Chrome 47开始是 manual。 referrer: 一个 USVString 可以是 no-referrer、``client或一个 URL。默认是 client。 referrerPolicy: 指定了HTTP头部referer字段的值。可能为以下值之一： no-referrer、 no-referrer-when-downgrade、 origin、 origin-when-cross-origin、 unsafe-url 。 integrity: 包括请求的 subresource integrity 值 （ 例如： sha256-BpfBw7ivV8q2jLiT13fxDYAe2tJllusRSZ273h2nFSE=）。  Body 类定义了以下方法（这些方法都被 Request 和Response所实现）以获取 body 内容。这些方法都会返回一个被解析后的Promise对象和数据。\n arrayBuffer() blob() json() text() formData()   一些示例 上传文件 var formData = new FormData(); var fileField = document.querySelector(\u0026quot;input[type='file']\u0026quot;); formData.append('username', 'abc123'); formData.append('avatar', fileField.files[0]); fetch('https://example.com/profile/avatar', { method: 'PUT', body: formData }) .then(response =\u0026gt; response.json()) .catch(error =\u0026gt; console.error('Error:', error)) .then(response =\u0026gt; console.log('Success:', response)); ","date":"2021-01-31","permalink":"/post/js-fetch/","tags":["js","web"],"title":"JS Fetch"},{"content":"作用： Clear-RecycleBin cmdlet删除计算机回收站中的内容。\n此操作类似于使用Windows清空回收站。\n参数  -Confirm 运行cmdlet之前提示用户确认。  即使未指定-Confirm参数，也会提示用户进行确认。\n  -DriveLetter 指定要清除单个驱动器号或驱动器号阵列的回收站。    -Force 指定不提示用户确认清除回收站。    -WhatIf 显示如果运行Clear-RecycleBin将发生什么。 该cmdlet没有运行。   示例 清除所有回收站 PS\u0026gt; Clear-RecycleBin Confirm Are you sure you want to perform this action? Performing the operation \u0026quot;Clear-RecycleBin\u0026quot; on target \u0026quot;All of the contents of the Recycle Bin\u0026quot;. [Y] Yes [A] Yes to All [N] No [L] No to All [S] Suspend [?] Help (default is \u0026quot;Y\u0026quot;):   清除指定的回收站 PS\u0026gt; Clear-RecycleBin -DriveLetter C  Clear-RecycleBin使用DriveLetter参数在C卷上指定回收站。 提示用户确认运行命令。\n 不需要确认清空所有回收站 PS\u0026gt; Clear-RecycleBin -Force  Clear-RecycleBin使用Force参数，并且不会提示用户进行确认以清除本地计算机上的所有回收站。\n一种替代方法是将-Force替换为-Confirm：$false。\n","date":"2020-07-28","permalink":"/post/powershell%E5%91%BD%E4%BB%A4clear-recyclebin/","tags":["powershell"],"title":"PowerShell命令Clear-RecycleBin"},{"content":"获取资源（例如文件或注册表项）的安全描述符。\n权限相关。\n描述 Get-Acl 获取代表文件或资源的安全描述符的对象。\n安全描述符包含资源的访问控制列表（ACL）。\nACL指定用户和用户组访问资源所必须具有的权限。\n参数    参数列表 说明     -Audit 从系统访问控制列表（SACL）获取安全描述符的审核数据。   -Exclude 忽略指定的项目。   -Filter 用提供程序的格式或语言指定一个过滤器。   -Include 只获取指定的项目。   -InputObject 获取指定对象的安全描述符。   -LiteralPath 指定资源的路径。   -Path 指定资源的路径。     -Exclude 忽略指定的项目。 此参数的值限定Path参数。 输入路径元素或模式，例如*.txt。 允许使用通配符。\n -Filter 用提供程序的格式或语言指定一个过滤器。 过滤器的语法（包括通配符的使用）取决于提供程序。 过滤器比其他参数更有效率，因为提供程序在获取对象时会应用它们，而不是让PowerShell在检索对象后对其进行过滤。 此参数的值限定Path参数。\n -Include 只获取指定的项目。 此参数的值限定Path参数。 输入路径元素或模式，例如*.txt。 允许使用通配符。\n -InputObject 获取指定对象的安全描述符。 输入包含该对象的变量或获取该对象的命令。 你不能将除路径以外的对象通过管道传递到Get-Acl。 而是在命令中显式使用InputObject参数。\n -LiteralPath 指定资源的路径。 指定资源的路径时，所有的特殊字符被视为路径片段。 与Path不同的是，LiteralPath参数的值是按照键入时的样子使用的。 没有字符被解释为通配符。 如果路径包括转义字符，请用单引号括起来。单引号告诉PowerShell不要将任何字符解释为转义序列。\n如：Get-ChildItem 默认的参数为-Path。假如你当前文件夹下有个文件名为.\\a[0].txt，因为方括号是PowerShell中的特殊字符，会解释器被解析。为了能正确获取到.\\a[0].txt的文件信息，此时可以使用-LiteralPath参数，它会把你传进来的值当作纯文本。\nPS\u0026gt; Get-ChildItem .\\a[0].txt PS\u0026gt; Get-ChildItem -Path .\\a[0].txt PS\u0026gt; Get-ChildItem -LiteralPath .\\a[0].txt Directory: C:\\Users\\mosser Mode LastWriteTime Length Name ---- ------------- ------ ---- -a--- 2014/1/2 14:04 80370 a[0].txt   -Path 指定资源的路径。 Get-Acl获取路径指示的资源的安全描述符。允许使用通配符。 如果省略Path参数，则Get-Acl将获取当前目录的安全描述符。\n 示例 获取一个目录的ACL PS\u0026gt; Get-Acl C:\\Windows Directory: C:\\ Path Owner Access ---- ----- ------ Windows NT SERVICE\\TrustedInstaller CREATOR OWNER Allow 268435456…  获取ACL的详细信息 PS\u0026gt; Get-Acl C:\\Windows | Format-List Path : Microsoft.PowerShell.Core\\FileSystem::C:\\Windows Owner : NT SERVICE\\TrustedInstaller Group : NT SERVICE\\TrustedInstaller Access : CREATOR OWNER Allow 268435456 NT AUTHORITY\\SYSTEM Allow 268435456 NT AUTHORITY\\SYSTEM Allow Modify, Synchronize BUILTIN\\Administrators Allow 268435456 BUILTIN\\Administrators Allow Modify, Synchronize BUILTIN\\Users Allow -1610612736 BUILTIN\\Users Allow ReadAndExecute, Synchronize NT SERVICE\\TrustedInstaller Allow 268435456 NT SERVICE\\TrustedInstaller Allow FullControl APPLICATION PACKAGE AUTHORITY\\ALL APPLICATION PACKAGES Allow ReadAndExecute, Synchronize APPLICATION PACKAGE AUTHORITY\\ALL APPLICATION PACKAGES Allow -1610612736 APPLICATION PACKAGE AUTHORITY\\所有受限制的应用程序包 Allow ReadAndExecute, Synchronize APPLICATION PACKAGE AUTHORITY\\所有受限制的应用程序包 Allow -1610612736 Audit : Sddl : O:S-1-5-80-956008885-3418522649-1831038044-1853292631-2271478464G:S-1-5-80-956008885-3418522649-1831038044-185 3292631-2271478464D:PAI(A;OICIIO;GA;;;CO)(A;OICIIO;GA;;;SY)(A;;0x1301bf;;;SY)(A;OICIIO;GA;;;BA)(A;;0x1301bf;;; BA)(A;OICIIO;GXGR;;;BU)(A;;0x1200a9;;;BU)(A;CIIO;GA;;;S-1-5-80-956008885-3418522649-1831038044-1853292631-2271 478464)(A;;FA;;;S-1-5-80-956008885-3418522649-1831038044-1853292631-2271478464)(A;;0x1200a9;;;AC)(A;OICIIO;GXG R;;;AC)(A;;0x1200a9;;;S-1-15-2-2)(A;OICIIO;GXGR;;;S-1-15-2-2)  使用通配符获取目录的ACL PS\u0026gt; Get-Acl C:\\Windows\\s*.log | Format-List -Property PSPath, Sddl PSPath : Microsoft.PowerShell.Core\\FileSystem::C:\\Windows\\setuperr.log Sddl : O:SYG:SYD:AI(A;ID;FA;;;SY)(A;ID;FA;;;BA)(A;ID;0x1200a9;;;BU)(A;ID;0x1200a9;;;AC)(A;ID;0x1200a9;;;S-1-15-2-2)  获取注册表项的ACL Get-Acl -Path HKLM:\\System\\CurrentControlSet\\Control | Format-List ","date":"2020-07-28","permalink":"/post/powershell%E5%91%BD%E4%BB%A4get-acl/","tags":["powershell"],"title":"PowerShell命令Get-Acl"}]